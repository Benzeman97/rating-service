<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>How to fix .NET Core’s ‘Unable to obtain lock file access’ error on Red Hat OpenShift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/DzipgvGkzFE/" /><category term=".NET" /><category term="C#" /><category term="Containers" /><category term="Kubernetes" /><category term=".NET Core" /><category term=".NET Core error" /><category term="C# error" /><category term="dotnet run" /><category term="openshift" /><author><name>Don Schenck</name></author><id>https://developers.redhat.com/blog/?p=731737</id><updated>2020-07-30T07:00:39Z</updated><published>2020-07-30T07:00:39Z</published><content type="html">&lt;p&gt;Well, it finally happened. Despite the added assurances of working with &lt;a href="https://developers.redhat.com/topics/containers"&gt;containers&lt;/a&gt; and &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;, the old &amp;#8220;It works on my machine&amp;#8221; scenario reared its ugly head in my &lt;a href="https://developers.redhat.com/products/dotnet/overview"&gt;.NET Core&lt;/a&gt; (C#) code. The image that I created worked fine on my local PC—a Fedora 32 machine—but it crashed when I tried running it in my &lt;a href="https://developers.redhat.com/products/openshift/getting-started"&gt;Red Hat OpenShift&lt;/a&gt; cluster.&lt;/p&gt; &lt;p&gt;The error was &amp;#8220;Unable to obtain lock file access on /tmp/NuGetScratch.&amp;#8221; Let&amp;#8217;s take a quick look at what happened, and then I&amp;#8217;ll explain how I fixed it.&lt;/p&gt; &lt;h2&gt;Identity issues&lt;/h2&gt; &lt;p&gt;After a lot of web searching and a discussion with a Red Hat .NET Core engineer, I discovered the underlying problem. It turns out that within a container, the identity used to initially run the program (using the &lt;code&gt;dotnet run&lt;/code&gt; command) must be the same for subsequent users.&lt;/p&gt; &lt;p&gt;The problem might be easy to understand, but what&amp;#8217;s the solution?&lt;/p&gt; &lt;p&gt;&lt;span id="more-731737"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;A temporary problem&lt;/h2&gt; &lt;p&gt;The solution was not only simple, but it was the right way to do things. Consider the initial Dockerfile that I used to build the image:&lt;/p&gt; &lt;pre&gt;FROM registry.access.redhat.com/ubi8/dotnet-31:3.1 USER 1001 RUN mkdir qotd-csharp WORKDIR qotd-csharp ADD . . RUN dotnet publish -c Release EXPOSE 10000 CMD ["dotnet", "run", "/bin/Release/netcoreapp3.1/publish/qotd-csharp.dll"] &lt;/pre&gt; &lt;p&gt;Notice the last line, which is the command that is called when you run the image:&lt;/p&gt; &lt;pre&gt;CMD ["dotnet", "run", "./bin/Release/netcoreapp3.0/publish/qotd-csharp.dll"] &lt;/pre&gt; &lt;p&gt;Because I was using &lt;code&gt;dotnet run&lt;/code&gt;, the .NET Core framework was attempting to access the temporary directory &lt;code&gt;/tmp/NuGetScratch&lt;/code&gt;. Because the user that built the image and the user attempting to run it were not the same, it failed inside of the Kubernetes cluster. The .NET runtime did not have permission to access this directory.&lt;/p&gt; &lt;h2&gt;Update the Dockerfile (hint: don&amp;#8217;t run)&lt;/h2&gt; &lt;p&gt;The solution was simple: I just used the following Dockerfile. Once again, notice the final line:&lt;/p&gt; &lt;pre&gt;FROM registry.access.redhat.com/ubi8/dotnet-31:3.1 USER 1001 RUN mkdir qotd-csharp WORKDIR qotd-csharp ADD . . RUN dotnet publish -c Release EXPOSE 10000 CMD ["dotnet", "./bin/Release/netcoreapp3.0/publish/qotd-csharp.dll"] &lt;/pre&gt; &lt;p&gt;The updated file not only worked, but it worked better.&lt;/p&gt; &lt;p&gt;Because the library (&lt;code&gt;qotd-csharp.dll&lt;/code&gt;) is already built, there&amp;#8217;s no need to use the &lt;code&gt;dotnet run&lt;/code&gt; command when a simple &lt;code&gt;dotnet &amp;#60;path-to-dll&amp;#62;&lt;/code&gt; is correct. As an added benefit, &lt;em&gt;it starts hundreds of times faster&lt;/em&gt;.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Even working with containerized applications on Kubernetes, the &amp;#8220;it works on my machine&amp;#8221; problem can still arise from time to time, especially in scenarios involving permissions. In this instance, not only did a workaround exist, but it was the right way to run the image. Chalk this up to a PEBKAC error—that is, a problem that exists between the keyboard and the chair. I learned my lesson.&lt;/p&gt; &lt;p&gt;You can read more in the &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/solutions/5142731"&gt;Red Hat Knowledgebase article&lt;/a&gt; for this error.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F30%2Fhow-to-fix-net-cores-unable-to-obtain-lock-file-access-error-on-red-hat-openshift%2F&amp;#38;linkname=How%20to%20fix%20.NET%20Core%E2%80%99s%20%E2%80%98Unable%20to%20obtain%20lock%20file%20access%E2%80%99%20error%20on%20Red%20Hat%20OpenShift" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F30%2Fhow-to-fix-net-cores-unable-to-obtain-lock-file-access-error-on-red-hat-openshift%2F&amp;#38;linkname=How%20to%20fix%20.NET%20Core%E2%80%99s%20%E2%80%98Unable%20to%20obtain%20lock%20file%20access%E2%80%99%20error%20on%20Red%20Hat%20OpenShift" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F30%2Fhow-to-fix-net-cores-unable-to-obtain-lock-file-access-error-on-red-hat-openshift%2F&amp;#38;linkname=How%20to%20fix%20.NET%20Core%E2%80%99s%20%E2%80%98Unable%20to%20obtain%20lock%20file%20access%E2%80%99%20error%20on%20Red%20Hat%20OpenShift" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F30%2Fhow-to-fix-net-cores-unable-to-obtain-lock-file-access-error-on-red-hat-openshift%2F&amp;#38;linkname=How%20to%20fix%20.NET%20Core%E2%80%99s%20%E2%80%98Unable%20to%20obtain%20lock%20file%20access%E2%80%99%20error%20on%20Red%20Hat%20OpenShift" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F30%2Fhow-to-fix-net-cores-unable-to-obtain-lock-file-access-error-on-red-hat-openshift%2F&amp;#38;linkname=How%20to%20fix%20.NET%20Core%E2%80%99s%20%E2%80%98Unable%20to%20obtain%20lock%20file%20access%E2%80%99%20error%20on%20Red%20Hat%20OpenShift" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F30%2Fhow-to-fix-net-cores-unable-to-obtain-lock-file-access-error-on-red-hat-openshift%2F&amp;#38;linkname=How%20to%20fix%20.NET%20Core%E2%80%99s%20%E2%80%98Unable%20to%20obtain%20lock%20file%20access%E2%80%99%20error%20on%20Red%20Hat%20OpenShift" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F30%2Fhow-to-fix-net-cores-unable-to-obtain-lock-file-access-error-on-red-hat-openshift%2F&amp;#38;linkname=How%20to%20fix%20.NET%20Core%E2%80%99s%20%E2%80%98Unable%20to%20obtain%20lock%20file%20access%E2%80%99%20error%20on%20Red%20Hat%20OpenShift" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F30%2Fhow-to-fix-net-cores-unable-to-obtain-lock-file-access-error-on-red-hat-openshift%2F&amp;#038;title=How%20to%20fix%20.NET%20Core%E2%80%99s%20%E2%80%98Unable%20to%20obtain%20lock%20file%20access%E2%80%99%20error%20on%20Red%20Hat%20OpenShift" data-a2a-url="https://developers.redhat.com/blog/2020/07/30/how-to-fix-net-cores-unable-to-obtain-lock-file-access-error-on-red-hat-openshift/" data-a2a-title="How to fix .NET Core’s ‘Unable to obtain lock file access’ error on Red Hat OpenShift"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/07/30/how-to-fix-net-cores-unable-to-obtain-lock-file-access-error-on-red-hat-openshift/"&gt;How to fix .NET Core&amp;#8217;s &amp;#8216;Unable to obtain lock file access&amp;#8217; error on Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/DzipgvGkzFE" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Well, it finally happened. Despite the added assurances of working with containers and Kubernetes, the old &amp;#8220;It works on my machine&amp;#8221; scenario reared its ugly head in my .NET Core (C#) code. The image that I created worked fine on my local PC—a Fedora 32 machine—but it crashed when I tried running it in my [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/07/30/how-to-fix-net-cores-unable-to-obtain-lock-file-access-error-on-red-hat-openshift/"&gt;How to fix .NET Core&amp;#8217;s &amp;#8216;Unable to obtain lock file access&amp;#8217; error on Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">731737</post-id><dc:creator>Don Schenck</dc:creator><dc:date>2020-07-30T07:00:39Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/07/30/how-to-fix-net-cores-unable-to-obtain-lock-file-access-error-on-red-hat-openshift/</feedburner:origLink></entry><entry><title>What is Application Performance Monitoring (APM)?</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/eda93DbS0Ds/what-is-application-performance.html" /><category term="feed_group_name_fusesource" scheme="searchisko:content:tags" /><category term="feed_name_ofbizian" scheme="searchisko:content:tags" /><category term="monitoring" scheme="searchisko:content:tags" /><category term="observability" scheme="searchisko:content:tags" /><author><name>Bilgin Ibryam</name></author><id>searchisko:content:id:jbossorg_blog-what_is_application_performance_monitoring_apm</id><updated>2020-07-30T06:49:30Z</updated><published>2020-07-30T06:49:00Z</published><content type="html">&lt;div&gt;&lt;i&gt;This is a guest post by &lt;/i&gt;&lt;span data-tooltip-position="top" data-tooltip=""&gt;&lt;i&gt;freelance editor and copywriter Laila Mahran. &lt;/i&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span data-tooltip-position="top" data-tooltip=""&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;When using Application Performance Monitoring, you’re able to monitor key app performance metrics about the performance of a web application in production. APM is often thought of as a ‘second wave’ of performance monitoring techniques, which was preceded by traditional host-based monitoring. Let’s dive in more. &lt;/div&gt;Host-based monitoring focuses on indicators such as:&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;Storage&lt;/li&gt;&lt;li&gt;Memory&lt;/li&gt;&lt;li&gt;CPU&lt;/li&gt;&lt;li&gt;Network utilization&lt;/li&gt;&lt;/ul&gt;Application monitoring goes a step further and focuses on the actual “end-user” metrics of an application in real-time such as:&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;Code-level errors&lt;/li&gt;&lt;li&gt;Slowdowns in response times&lt;/li&gt;&lt;li&gt;Error rates&lt;/li&gt;&lt;/ul&gt;&lt;h3 style="text-align: left;"&gt;How does this APM magic work?&lt;/h3&gt;There are multiple different ways Application Performance Monitoring tools can function. Let’s look at the most common ways APM is used. &lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;An agent process that is deployed alongside a web application that hooks into the application runtime to collect telemetry data from the process&lt;/li&gt;&lt;li&gt;Specialized web appliances that inspect Layer 7 traffic to generate telemetry&lt;/li&gt;&lt;/ul&gt;When combined with the monitoring mechanism, an external application generates synthetic traffic which is then sent to the application to monitor performance at predefined throughput intervals. When looking at &lt;a href="https://nordicapis.com/10-api-monitoring-tools/" target="_blank"&gt;APM tools&lt;/a&gt; and other monitoring types, the main difference to highlight is that the telemetry data is generated by inspecting the application runtime, and the performance metrics that it exposes.&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;Can APM help me?&lt;/h3&gt;Traditional host monitoring can make you feel stuck with no step closer to an answer. Application Performance Monitoring is designed to answer questions that you can’t get an answer to. While understanding the raw resource utilization of your application is useful, it doesn’t give you a lot of information when you’re trying to track down why a specific request has high latency, why a particular transaction against your database is failing, or how your application performs under load. &lt;br /&gt;Let’s take a look at common questions asked on a daily basis.&lt;br /&gt;&lt;ol style="text-align: left;"&gt;&lt;li&gt;What are the implications of this issue on user experience for end users?&amp;nbsp; &lt;/li&gt;&lt;li&gt;Where is this high latency coming from?&lt;/li&gt;&lt;li&gt;What caused that outage?&lt;/li&gt;&lt;li&gt;Why are we getting an error here?&lt;/li&gt;&lt;li&gt;Why is this transaction failing?&lt;/li&gt;&lt;li&gt;Can we find the root cause of this substandard user experience?&lt;/li&gt;&lt;/ol&gt;Have you asked yourself these questions before? If you’re nodding your head furiously, you can look to APM to provide the answer. &lt;br /&gt;&lt;h3 style="text-align: left;"&gt;Monitoring vs. Management: What’s the difference?&lt;/h3&gt;Application Performance Management applies to a suite of applications while Application Performance Monitoring applies to a single application. An application performance management tool is able to aggregate and compare multiple types of metrics across multiple applications and services in order to pinpoint performance issues and regressions in your suite of applications. On the other hand, Application Performance Monitoring looks at the code-level to ensure each step is monitored thoroughly. &lt;br /&gt;&lt;h3 style="text-align: left;"&gt;Is Network Monitoring different?&lt;/h3&gt;Network monitoring focuses on routers in order to detect issues with an application or collecting telemetry from network devices such as switches. If you’re looking to get a complete picture, networking monitoring requires stitching together information from each line. This approach doesn’t provide sufficient resolution or information for modern applications, however, especially when the application itself may be running behind a variety of proxies or service routers which themselves are running on virtualized networking equipment.&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;APM vs. Observability: What’s the difference?&lt;/h3&gt;You’ve heard the hype of observability, but how is it different from APM? &lt;a href="https://www.ingeniumweb.com/blog/post/what-is-observability-and-how-is-it-connected-to-marketing-and-sales/5032/" target="_blank"&gt;Observability&lt;/a&gt; is a holistic approach to fully understanding your application performance as well as a shared set of practices and terminology to help communicate performance across your organization. While observability helps you navigate from effect to cause, &lt;a href="https://lightstep.com/blog/apm-is-dying-and-thats-okay/" target="_blank"&gt;APM falls short&lt;/a&gt; of being able to answer “unknown unknowns,” questions that you didn’t think to ask ahead of time. This is the reason behind APM currently being eclipsed by observability. &lt;br /&gt;Observability is unique due to the capability of answering questions about modern, microservice-based application architectures where you will often contend with serverless components, polyglot services, and container-based deployments running on &lt;a href="https://www.influxdata.com/solutions/kubernetes-monitoring-solution/" target="_blank"&gt;Kubernetes&lt;/a&gt;. Circling back, observability provides a shared language to standardize communication around performance. This way you’re able to focus on the measurement of service level objectives and service level indicators that are more broadly applicable and interpretable to your unique application architecture than simple throughput or health checks.&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;Is Application Performance Monitoring worth it?&lt;/h3&gt;Instead of depending on the second or third order metrics about host or network utilization to understand your application’s performance, APM collects real-time performance data from the perspective of an end-user. Another bonus: real-time results of database queries and page load times are provided with APM in a way that’s not possible with host-based monitoring. This information can be invaluable in understanding how your application performs under load or while trying to track down bugs in your software. APM solutions provide alerting systems to IT Operations, Site Reliability Engineers, DevOps, and more to quickly troubleshoot performance issues and slowdowns.&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/eda93DbS0Ds" height="1" width="1" alt=""/&gt;</content><summary>This is a guest post by freelance editor and copywriter Laila Mahran. When using Application Performance Monitoring, you’re able to monitor key app performance metrics about the performance of a web application in production. APM is often thought of as a ‘second wave’ of performance monitoring techniques, which was preceded by traditional host-based monitoring. Let’s dive in more. Host-based monit...</summary><dc:creator>Bilgin Ibryam</dc:creator><dc:date>2020-07-30T06:49:00Z</dc:date><feedburner:origLink>http://www.ofbizian.com/2020/07/what-is-application-performance.html</feedburner:origLink></entry><entry><title>From notebooks to pipelines: Using Open Data Hub and Kubeflow on OpenShift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/JVsWm6aK5Rg/" /><category term="Big Data" /><category term="CI/CD" /><category term="DevOps" /><category term="Machine Learning" /><category term="AI/ML" /><category term="data model" /><category term="Kubeflow" /><category term="Open Data Hub" /><category term="openshift" /><author><name>Juana Nakfour</name></author><id>https://developers.redhat.com/blog/?p=733947</id><updated>2020-07-29T07:00:36Z</updated><published>2020-07-29T07:00:36Z</published><content type="html">&lt;p&gt;Data scientists often use notebooks to explore data and create and experiment with models. At the end of this exploratory phase is the product-delivery phase, which is basically getting the final model to production. Serving a model in production is not a one-step final process, however. It is a continuous phase of training, development, and data monitoring that is best captured or automated using pipelines. This brings us to a dilemma: How do you move code from notebooks to containers orchestrated in a pipeline, and schedule the pipeline to run after specific triggers like time of day, new batch data, and monitoring metrics?&lt;/p&gt; &lt;p&gt;Today there are multiple current tools and proposed methods for moving code from notebooks to pipelines. For example, the tool &lt;a target="_blank" rel="nofollow" href="https://github.com/nachlass-tools/nachlass"&gt;nachlass&lt;/a&gt; uses the source-to-image (S2I) method to convert notebooks ultimately into containers. In this article and &lt;a href="https://developers.redhat.com/devnation/tech-talks/kubeflow-kubernetes/?sc_cid=7013a000002gW1BAAU"&gt;in my original DevNation presentation&lt;/a&gt;, we explore a new Kubeflow-proposed tool for converting notebooks to Kubeflow pipelines: Kale. Kale is a &lt;a href="https://developers.redhat.com/blog/2020/02/10/installing-kubeflow-v0-7-on-openshift-4-2/"&gt;Kubeflow&lt;/a&gt; extension that is integrated with &lt;a target="_blank" rel="nofollow" href="https://jupyterlab.readthedocs.io/en/stable/"&gt;JupyterLab&lt;/a&gt;&amp;#8216;s user interface (UI). It offers data scientists a UI-driven way to convert notebooks to Kubeflow pipelines and run the pipelines in an experiment.&lt;/p&gt; &lt;p&gt;We run these tools as part of the Open Data Hub installation on &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;. Open Data Hub is composed of multiple open source tools that are packaged in the ODH Operator. When you install ODH you can specify which tools you want to install, such as Airflow, Argo, Seldon, Jupyterhub, and Spark.&lt;/p&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;p&gt;To run this demo, you will need access to an OpenShift 4.x cluster with cluster-admin rights to install a cluster-wide Open Data Hub Operator.&lt;/p&gt; &lt;h2&gt;Install Kubeflow on OpenShift&lt;/h2&gt; &lt;p&gt;We can use the Open Data Hub Operator to install Kubeflow on OpenShift. From the OpenShift portal, go to the OperatorHub and search for &lt;b&gt;Open Data Hub&lt;/b&gt;, as shown in Figure 1.&lt;/p&gt; &lt;div id="attachment_733957" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-3.25.19-PM.png"&gt;&lt;img aria-describedby="caption-attachment-733957" class="wp-image-733957" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-3.25.19-PM-300x243.png" alt="A screenshot of the OperatorHub with the Open Data Hub Operator selected and installed." width="640" height="518" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-3.25.19-PM-300x243.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-3.25.19-PM-768x622.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-3.25.19-PM.png 916w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-733957" class="wp-caption-text"&gt;Figure 1: Installing Open Data Hub from the OpenShift OperatorHub.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Click &lt;b&gt;Install&lt;/b&gt; and move to the next screen. Currently, Open Data Hub offers two channels for installation: beta and legacy. The beta channel is for the new Open Data Hub releases that include Kubeflow. Keep the default settings on that channel, and click &lt;b&gt;Subscribe&lt;/b&gt;, as shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_733967" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-3.30.39-PM.png"&gt;&lt;img aria-describedby="caption-attachment-733967" class="wp-image-733967" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-3.30.39-PM-300x292.png" alt="A screenshot of the subscription page with the option to choose the beta update channel." width="640" height="623" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-3.30.39-PM-300x292.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-3.30.39-PM.png 682w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-733967" class="wp-caption-text"&gt;Figure 2: Create a subscription to the Open Data Hub Operator using the beta update channel.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;After you subscribe, the Open Data Hub Operator will be installed in the &lt;code&gt;openshift-operators&lt;/code&gt; namespace, where it is available cluster-wide.&lt;/p&gt; &lt;p&gt;Next, create a new namespace called &lt;code&gt;kubeflow&lt;/code&gt;. From there, go to &lt;b&gt;Installed Operators&lt;/b&gt;, click on the Open Data Hub Operator, and create a new instance of the &lt;code&gt;kfdef&lt;/code&gt; resource. The default is an example &lt;code&gt;kfdef&lt;/code&gt; instance (a YAML file) that installs Open Data Hub components such as Prometheus, Grafana, JupyterHub, Argo, and Seldon. To install Kubeflow, you will need to replace the example &lt;code&gt;kfdef&lt;/code&gt; instance with the one from Kubeflow. Replace the example file with &lt;a target="_blank" rel="nofollow" href="https://raw.githubusercontent.com/opendatahub-io/manifests/v0.7-branch-openshift/kfdef/kfctl_openshift_apiv1.yaml"&gt;this one&lt;/a&gt;, then click &lt;b&gt;Create&lt;/b&gt;. You will see the file shown in Figure 3.&lt;/p&gt; &lt;div id="attachment_733977" style="width: 577px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-3.37.33-PM.png"&gt;&lt;img aria-describedby="caption-attachment-733977" class="wp-image-733977 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-3.37.33-PM.png" alt="A screenshot of the new kfdef resource file for Kubeflow." width="567" height="787" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-3.37.33-PM.png 567w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-3.37.33-PM-216x300.png 216w" sizes="(max-width: 567px) 100vw, 567px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-733977" class="wp-caption-text"&gt;Figure 3: Create the kfdef resource for Kubeflow.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;That is all it takes to install Kubeflow on OpenShift. Watch the pods install in the namespace and wait until all of the pods are running before starting on the next steps&lt;/p&gt; &lt;h2&gt;Notebooks to pipeline&lt;/h2&gt; &lt;p&gt;After the installation has successfully completed, the next step is to create a notebook server in your development namespace, then create a notebook that includes tasks for creating and validating models. To get to the Kubeflow portal, head over to the &lt;b&gt;istio-system&lt;/b&gt; namespace and click on the &lt;b&gt;istio-ingressgateway&lt;/b&gt; route. This route brings you to the main Kubeflow portal, where you must create a new profile and a working namespace. From the left side of the menu bar in the main menu, head over to &lt;b&gt;Notebook Server&lt;/b&gt; and click on &lt;b&gt;New Server&lt;/b&gt;. A new form will open, where you can create a notebook server to host your notebooks. Be sure that the namespace that you just created is selected in the drop-down menu.&lt;/p&gt; &lt;p&gt;In this form, you must specify a custom image that &lt;a target="_blank" rel="nofollow" href="https://medium.com/kubeflow/an-end-to-end-ml-workflow-from-notebook-to-kubeflow-pipelines-with-minikf-kale-72244d245d53"&gt;includes the Kale component&lt;/a&gt;. Specify the custom image: &lt;b&gt;gcr.io/arrikto-public/tensorflow-1.14.0-notebook-cpu:kubecon-workshop&lt;/b&gt;.&lt;/p&gt; &lt;p&gt;Add a new data volume, as shown in Figure 4, then hit &lt;b&gt;Launch&lt;/b&gt;.&lt;/p&gt; &lt;div id="attachment_733987" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-3.50.01-PM.png"&gt;&lt;img aria-describedby="caption-attachment-733987" class="wp-image-733987" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-3.50.01-PM-300x253.png" alt="A screenshot of the setup page for the custom image." width="640" height="539" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-3.50.01-PM-300x253.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-3.50.01-PM-768x647.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-3.50.01-PM.png 912w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-733987" class="wp-caption-text"&gt;Figure 4: Launching a new notebook server.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Once it is ready, you can connect to the notebook server that you just created. The new notebook server gets you to the main JupyterLab portal, which includes Kubeflow&amp;#8217;s Kale extension.&lt;/p&gt; &lt;h2&gt;An example notebook&lt;/h2&gt; &lt;p&gt;We will use a very simple notebook based on &lt;a target="_blank" rel="nofollow" href="https://github.com/josephlee94/intuitive-deep-learning"&gt;this example&lt;/a&gt;. The notebook predicts whether a house value is below or above average house values. For this demonstration, we simplified the notebook and prepared it for a pipeline. You can &lt;a target="_blank" rel="nofollow" href="https://github.com/nakfour/DevnationJune202"&gt;download the converted notebook from GitHub&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Tasks in this notebook include downloading the house-prediction data, preparing the data, and creating a neural network with three layers that can predict the value of a given house. At this point, the example notebook looks like a normal notebook, and you can run the cells to ensure that they are working.&lt;/p&gt; &lt;p&gt;To enable Kale in the notebook, click on the Kubeflow icon on the left-side menu bar and click &lt;b&gt;Enable&lt;/b&gt;. You should see something similar to the screenshot in Figure 5.&lt;/p&gt; &lt;div id="attachment_733997" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-3.56.11-PM.png"&gt;&lt;img aria-describedby="caption-attachment-733997" class="wp-image-733997 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-3.56.11-PM-1024x889.png" alt="A screenshot of the Kale deployment panel and details." width="640" height="556" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-3.56.11-PM-1024x889.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-3.56.11-PM-300x261.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-3.56.11-PM-768x667.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-3.56.11-PM.png 1087w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-733997" class="wp-caption-text"&gt;Figure 5: Click the Kubeflow icon on the left-side menu bar and enable Kale.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;You can specify the role for each cell by clicking the &lt;b&gt;Edit&lt;/b&gt; button on the top-right corner of each cell. As shown in Figure 5, we have an &lt;b&gt;imports&lt;/b&gt; section and a &lt;b&gt;prepdata&lt;/b&gt; pipeline step, as well as a &lt;b&gt;trainmodel&lt;/b&gt; pipeline step (not shown) that depends on &lt;b&gt;prepdata&lt;/b&gt; step. Name the experiment and the pipeline, then click &lt;b&gt;Compile and Upload&lt;/b&gt;.&lt;/p&gt; &lt;p&gt;For now, we will just create the pipeline and defer running it until later. When you get an &lt;b&gt;Okay&lt;/b&gt; message, head over to the main Kubeflow portal and select &lt;b&gt;Pipelines&lt;/b&gt;. The first pipeline listed is the Kale-generated pipeline. If you click on it, you should see the pipeline details shown in Figure 6.&lt;/p&gt; &lt;div id="attachment_734007" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-4.00.43-PM.png"&gt;&lt;img aria-describedby="caption-attachment-734007" class="wp-image-734007" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-4.00.43-PM-300x250.png" alt="A diagram of the Kale-generated pipeline, showing the steps in the pipeline's flow." width="640" height="533" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-4.00.43-PM-300x250.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-4.00.43-PM.png 691w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-734007" class="wp-caption-text"&gt;Figure 6: Exploring the Kale-generated pipeline.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Adjusting the pipeline&lt;/h2&gt; &lt;p&gt;You can explore the code and see the different steps in the pipeline. This is a generated pipeline that assumes the underlying Argo is using a docker container. As a result, this pipeline will not run on OpenShift, which uses a CRI-O container engine and the &lt;code&gt;k8sapi&lt;/code&gt; executor for Argo.&lt;/p&gt; &lt;p&gt;Also, note that the container image that is used for each step requires root permissions, so we had to give root privileges to the service account running the workflow (&lt;code&gt;oc adm policy add-role-to-user admin system:serviceaccount:namespace:default-editor&lt;/code&gt;). Obviously, this method of running containers on OpenShift is not advised. In the future, we hope to change the container so that it does not require root privileges.&lt;/p&gt; &lt;p&gt;You can &lt;a target="_blank" rel="nofollow" href="https://github.com/nakfour/DevnationJune202"&gt;download the adjusted pipeline and a volume YAML resource&lt;/a&gt; from GitHub. Create the volume before uploading and running the adjusted pipeline, which is shown in Figure 7.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: This adjustment does not change the containers themselves. Instead, the pipeline structure, permissions, and added volumes were changed.&lt;/p&gt; &lt;div id="attachment_734027" style="width: 598px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-4.07.36-PM.png"&gt;&lt;img aria-describedby="caption-attachment-734027" class="wp-image-734027 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-4.07.36-PM.png" alt="A screenshot of the Kale-generated pipeline with the adjustments for OpenShift." width="588" height="456" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-4.07.36-PM.png 588w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-06-11-at-4.07.36-PM-300x233.png 300w" sizes="(max-width: 588px) 100vw, 588px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-734027" class="wp-caption-text"&gt;Figure 7: The adjusted pipeline.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In this article, you learned how to install Kubeflow on OpenShift using the Open Data Hub Operator, and we explored using Kubeflow&amp;#8217;s Kale extension to convert notebooks to pipelines. Moving code from notebooks to pipelines is a critical step in the artificial intelligence and machine learning (AI/ML) end-to-end workflow, and there are multiple technologies addressing this issue. While these conversion tools might be immature and in development, we see great potential and room for improvement. Please join our &lt;a target="_blank" rel="nofollow" href="https://opendatahub.io/community.html"&gt;Open Data Hub community&lt;/a&gt; and contribute to developing AI/ML end-to-end technologies on OpenShift.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F29%2Ffrom-notebooks-to-pipelines-using-open-data-hub-and-kubeflow-on-openshift%2F&amp;#38;linkname=From%20notebooks%20to%20pipelines%3A%20Using%20Open%20Data%20Hub%20and%20Kubeflow%20on%20OpenShift" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F29%2Ffrom-notebooks-to-pipelines-using-open-data-hub-and-kubeflow-on-openshift%2F&amp;#38;linkname=From%20notebooks%20to%20pipelines%3A%20Using%20Open%20Data%20Hub%20and%20Kubeflow%20on%20OpenShift" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F29%2Ffrom-notebooks-to-pipelines-using-open-data-hub-and-kubeflow-on-openshift%2F&amp;#38;linkname=From%20notebooks%20to%20pipelines%3A%20Using%20Open%20Data%20Hub%20and%20Kubeflow%20on%20OpenShift" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F29%2Ffrom-notebooks-to-pipelines-using-open-data-hub-and-kubeflow-on-openshift%2F&amp;#38;linkname=From%20notebooks%20to%20pipelines%3A%20Using%20Open%20Data%20Hub%20and%20Kubeflow%20on%20OpenShift" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F29%2Ffrom-notebooks-to-pipelines-using-open-data-hub-and-kubeflow-on-openshift%2F&amp;#38;linkname=From%20notebooks%20to%20pipelines%3A%20Using%20Open%20Data%20Hub%20and%20Kubeflow%20on%20OpenShift" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F29%2Ffrom-notebooks-to-pipelines-using-open-data-hub-and-kubeflow-on-openshift%2F&amp;#38;linkname=From%20notebooks%20to%20pipelines%3A%20Using%20Open%20Data%20Hub%20and%20Kubeflow%20on%20OpenShift" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F29%2Ffrom-notebooks-to-pipelines-using-open-data-hub-and-kubeflow-on-openshift%2F&amp;#38;linkname=From%20notebooks%20to%20pipelines%3A%20Using%20Open%20Data%20Hub%20and%20Kubeflow%20on%20OpenShift" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F29%2Ffrom-notebooks-to-pipelines-using-open-data-hub-and-kubeflow-on-openshift%2F&amp;#038;title=From%20notebooks%20to%20pipelines%3A%20Using%20Open%20Data%20Hub%20and%20Kubeflow%20on%20OpenShift" data-a2a-url="https://developers.redhat.com/blog/2020/07/29/from-notebooks-to-pipelines-using-open-data-hub-and-kubeflow-on-openshift/" data-a2a-title="From notebooks to pipelines: Using Open Data Hub and Kubeflow on OpenShift"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/07/29/from-notebooks-to-pipelines-using-open-data-hub-and-kubeflow-on-openshift/"&gt;From notebooks to pipelines: Using Open Data Hub and Kubeflow on OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/JVsWm6aK5Rg" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Data scientists often use notebooks to explore data and create and experiment with models. At the end of this exploratory phase is the product-delivery phase, which is basically getting the final model to production. Serving a model in production is not a one-step final process, however. It is a continuous phase of training, development, and [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/07/29/from-notebooks-to-pipelines-using-open-data-hub-and-kubeflow-on-openshift/"&gt;From notebooks to pipelines: Using Open Data Hub and Kubeflow on OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">733947</post-id><dc:creator>Juana Nakfour</dc:creator><dc:date>2020-07-29T07:00:36Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/07/29/from-notebooks-to-pipelines-using-open-data-hub-and-kubeflow-on-openshift/</feedburner:origLink></entry><entry><title>What the Dev? - Best practices for Agile integration with Red Hat's Eric Schabell - Episode 44</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/_2wXE8cGS_s/what-the-dev-podcast-episode-44-agile-integration.html" /><category term="AppDev" scheme="searchisko:content:tags" /><category term="best practices" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="FUSE" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="JBossAMQ" scheme="searchisko:content:tags" /><category term="video" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-what_the_dev_best_practices_for_agile_integration_with_red_hat_s_eric_schabell_episode_44</id><updated>2020-07-29T08:32:06Z</updated><published>2020-07-29T05:00:00Z</published><content type="html">&lt;div class="separator"&gt;&lt;div class="separator" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em; text-align: center;"&gt;&lt;a href="http://whatthedev.buzzsprout.com/673192/4750094-best-practices-for-agile-integration-with-red-hat-s-eric-schabell-episode-44" target="_blank"&gt;&lt;img border="0" data-original-height="1365" data-original-width="2048" src="https://1.bp.blogspot.com/-TtIkRfU01t0/XyEy_JXjPoI/AAAAAAAAxUY/0XkiB8FE6hQBlpIp2-eWetzeUcCQs6s2ACNcBGAsYHQ/s320/podcast.jpg" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;Funny enough, in all my years of writing, speaking, and recording video content on all matter of topics from baseball to technology... I've never been on a single podcast.&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;That all changed last week when I got the chance to join&amp;nbsp;David Rubinstein, editor in chief of SD Times, for a quick chat on his podcast called &lt;i&gt;&lt;a href="http://whatthedev.buzzsprout.com/673192" target="_blank"&gt;What the Dev?&lt;/a&gt;&amp;nbsp;&lt;/i&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;This is&amp;nbsp;a podcast by the SD Times editorial team, covering the biggest and newest topics in software and technology.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;In this episode 44 we had a running conversation about agile integration, microservices, agile, cloud-native development, container platforms, hybrid cloud, and more.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Find out why so many struggle with their transition to these new concepts and technologies. Listen in to a few of the pitfalls that you can avoid as you scale out your development organization to effectively deliver and maintain microservice integration projects.&lt;/div&gt;&lt;span&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;/span&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3 style="text-align: left;"&gt;&lt;a href="http://whatthedev.buzzsprout.com/673192/4750094-best-practices-for-agile-integration-with-red-hat-s-eric-schabell-episode-44" target="_blank"&gt;Best practices for Agile integration with Red Hat's Eric Schabell - Episode 44&lt;/a&gt;&lt;/h3&gt;&lt;div&gt;&lt;i&gt;This week, we spoke to Eric Schabell, the portfolio architect director at Red Hat, about Agile integration. A lot of enterprises are moving in the direction of Agile teams all with an eye on the digital transformation story where they're headed towards delivering things in a cloud native fashion. You'll hear some of the best ways in which to achieve that Agile integration.&amp;nbsp;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-C0KaSeoREGE/XyEzpeDA6nI/AAAAAAAAxUg/TNLzemz0L58QtTG4-rko9NKtuOfgrnnaACNcBGAsYHQ/s1400/what-the-dev.jpg" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img border="0" data-original-height="1400" data-original-width="1400" height="200" src="https://1.bp.blogspot.com/-C0KaSeoREGE/XyEzpeDA6nI/AAAAAAAAxUg/TNLzemz0L58QtTG4-rko9NKtuOfgrnnaACNcBGAsYHQ/w200-h200/what-the-dev.jpg" width="200" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;/i&gt;&lt;/div&gt;&lt;div&gt;&lt;i&gt;&lt;br /&gt;&lt;/i&gt;&lt;/div&gt;&lt;div&gt;It's just a little over 16 minutes, something you can catch on your next coffee break. Hope you enjoy listening to our conversation and if you have any comments, just reach out to me as I'm always happy to hear from you.&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=B4kyhf-k9J4:y-3qQW1NPDY:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=B4kyhf-k9J4:y-3qQW1NPDY:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=B4kyhf-k9J4:y-3qQW1NPDY:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=B4kyhf-k9J4:y-3qQW1NPDY:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=B4kyhf-k9J4:y-3qQW1NPDY:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=B4kyhf-k9J4:y-3qQW1NPDY:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=B4kyhf-k9J4:y-3qQW1NPDY:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=B4kyhf-k9J4:y-3qQW1NPDY:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=B4kyhf-k9J4:y-3qQW1NPDY:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=B4kyhf-k9J4:y-3qQW1NPDY:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=B4kyhf-k9J4:y-3qQW1NPDY:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/B4kyhf-k9J4" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/_2wXE8cGS_s" height="1" width="1" alt=""/&gt;</content><summary>Funny enough, in all my years of writing, speaking, and recording video content on all matter of topics from baseball to technology... I've never been on a single podcast. That all changed last week when I got the chance to join David Rubinstein, editor in chief of SD Times, for a quick chat on his podcast called What the Dev?  This is a podcast by the SD Times editorial team, covering the biggest...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2020-07-29T05:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/B4kyhf-k9J4/what-the-dev-podcast-episode-44-agile-integration.html</feedburner:origLink></entry><entry><title>Creating event sources in the OpenShift 4.5 web console</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/WqreFkHs49k/" /><category term="Event-Driven" /><category term="Kubernetes" /><category term="Microservices" /><category term="Serverless" /><category term="event driven microservices" /><category term="kafka event" /><category term="kafka microservices" /><category term="knative tutorial" /><category term="openshift" /><author><name>Brian Tannous</name></author><id>https://developers.redhat.com/blog/?p=756407</id><updated>2020-07-28T07:00:08Z</updated><published>2020-07-28T07:00:08Z</published><content type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/blog/2020/07/16/whats-new-in-the-openshift-4-5-console-developer-experience/"&gt;Red Hat OpenShift 4.5&lt;/a&gt; makes it easier than ever to deploy and run &lt;a href="https://developers.redhat.com/topics/event-driven"&gt;event-driven applications&lt;/a&gt; that react to real-time information via event notifications. Empowered by &lt;a href="https://developers.redhat.com/blog/2020/04/30/serverless-applications-made-faster-and-simpler-with-openshift-serverless-ga/"&gt;OpenShift Serverless&lt;/a&gt;, applications come to life through events, scaling up resources as needed (or up to a pre-configured limit), and then scaling back to zero after the resource burst is over.&lt;/p&gt; &lt;p&gt;In this article, I briefly introduce the OpenShift Serverless features for developing event-driven applications in OpenShift 4.5. I also demonstrate these features with an example featuring &lt;a href="https://developers.redhat.com/topics/serverless-architecture"&gt;Knative services&lt;/a&gt; and a Kafka event source.&lt;/p&gt; &lt;h2&gt;Event-driven application architecture&lt;/h2&gt; &lt;p&gt;Events provide a simple mechanism for applications to subscribe to a variety of event sources, including your own applications, cloud services from multiple providers, Software-as-a-Service (SaaS) systems, and Red Hat services such as &lt;a href="https://developers.redhat.com/products/amq/getting-started"&gt;AMQ Streams&lt;/a&gt;. The new &lt;a href="https://developers.redhat.com/blog/2020/07/16/improved-navigation-in-the-openshift-4-5-developer-perspective/"&gt;Developer perspective&lt;/a&gt; in the OpenShift 4.5 web console makes it even easier to deploy event-driven applications without relying on YAML.&lt;/p&gt; &lt;h2&gt;Serverless eventing in OpenShift 4.5&lt;/h2&gt; &lt;p&gt;OpenShift Serverless provides several mechanisms for building event-driven applications:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Direct connections&lt;/li&gt; &lt;li&gt;Channels and subscriptions&lt;/li&gt; &lt;li&gt;Event filtering with brokers and triggers&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The best method to use depends on the needs of the service.&lt;/p&gt; &lt;h3&gt;Direct connections&lt;/h3&gt; &lt;p&gt;The most simple event-driven architecture is a direct connection. Figure 1 shows the architecture for directly connecting a Knative service to an event source. Later in the article, I will show you how to use the new OpenShift Developer perspective to create a direct connection.&lt;/p&gt; &lt;div id="attachment_756657" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/07/1-event-direct.png"&gt;&lt;img aria-describedby="caption-attachment-756657" class="wp-image-756657 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/07/1-event-direct-1024x153.png" alt="A diagram of the event-driven application architecture for a direct connection." width="640" height="96" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/07/1-event-direct-1024x153.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/1-event-direct-300x45.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/1-event-direct-768x114.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/1-event-direct.png 1148w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-756657" class="wp-caption-text"&gt;Figure 1: The event-driven application architecture for a direct connection.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Directly connecting sources to services works well, but what if you need to group multiple sources? What if multiple services need to subscribe to those groups?&lt;/p&gt; &lt;h3&gt;Channels and subscriptions&lt;/h3&gt; &lt;p&gt;Multiple sources and sinks can work together via OpenShift Serverless channels and subscriptions. Figure 2 shows the architecture of channels and subscriptions in an event-driven application.&lt;/p&gt; &lt;div id="attachment_756667" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/07/2-event-channel.png"&gt;&lt;img aria-describedby="caption-attachment-756667" class="wp-image-756667 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/07/2-event-channel-1024x188.png" alt="A diagram of the event-driven application architecture for channels and subscriptions." width="640" height="118" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/07/2-event-channel-1024x188.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/2-event-channel-300x55.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/2-event-channel-768x141.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/2-event-channel.png 1229w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-756667" class="wp-caption-text"&gt;Figure 2: The event-driven application architecture for channels and subscriptions.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Event channels make groups of event sources easy to reuse. Subscriptions offer a simple way to tie events to &lt;a href="https://developers.redhat.com/coderland/serverless"&gt;Knative services&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Event brokers and triggers&lt;/h3&gt; &lt;p&gt;OpenShift Serverless lets us quickly group and reuse events, but what about filtering event notifications? One option would be to add a function to the application code to only process certain kinds of events. While this approach might work, it risks notifying services about events that they don&amp;#8217;t need and will just throw out. Another method is to use filtering notifications, which will only notify the service when it is necessary.&lt;/p&gt; &lt;p&gt;The OpenShift Serverless event broker and trigger build on event sources to filter events before notifying the service, as shown in Figure 3.&lt;/p&gt; &lt;div id="attachment_756677" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/07/3-event-broker.png"&gt;&lt;img aria-describedby="caption-attachment-756677" class="wp-image-756677 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/07/3-event-broker-1024x273.png" alt="A diagram of the event-driven application architecture for brokers and triggers." width="640" height="171" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/07/3-event-broker-1024x273.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/3-event-broker-300x80.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/3-event-broker-768x205.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/3-event-broker.png 1083w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-756677" class="wp-caption-text"&gt;Figure 3: The event-driven application architecture for brokers and triggers.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Creating Knative services&lt;/h2&gt; &lt;p&gt;Since &lt;a href="https://developers.redhat.com/blog/2020/04/30/serverless-applications-made-faster-and-simpler-with-openshift-serverless-ga/"&gt;OpenShift 4.4&lt;/a&gt;, it has been possible to select a &lt;strong&gt;Knative Service&lt;/strong&gt; resource type when adding a new application to a project. Adding a &lt;strong&gt;Knative Service&lt;/strong&gt; resource type instantly allows any application to benefit from the power of OpenShift Serverless, as demonstrated in Figure 4.&lt;/p&gt; &lt;div id="attachment_756737" style="width: 560px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/07/4-ksvc0-1.gif"&gt;&lt;img aria-describedby="caption-attachment-756737" class="wp-image-756737 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/07/4-ksvc0-1.gif" alt="A demonstrating of creating a Knative service in OpenShift." width="550" height="499" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-756737" class="wp-caption-text"&gt;Figure 4: Creating a Knative service in OpenShift.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Binding an event source to a Knative service&lt;/h3&gt; &lt;p&gt;You can now use the OpenShift Developer perspective to create and bind event sources to Knative services. As demonstrated in Figure 5, you just drag the event source connector (arrow icon) out of an existing Knative service and select &lt;strong&gt;Event Source&lt;/strong&gt;. Then, you configure the event source (in this case, a Kafka event source) with the event type that should trigger the application.&lt;/p&gt; &lt;div id="attachment_756717" style="width: 510px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/07/5-event-source0-1.gif"&gt;&lt;img aria-describedby="caption-attachment-756717" class="wp-image-756717 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/07/5-event-source0-1.gif" alt="A demonstration of binding a Kafka event source to a Knative service in the OpenShift Developer perspective." width="500" height="454" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-756717" class="wp-caption-text"&gt;Figure 5: Binding a Kafka event source to a Knative service in the OpenShift Developer perspective.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Notice that the OpenShift Developer perspective provides a simple slide-out so that you can quickly see all of the resources related to the newly created event source.&lt;/p&gt; &lt;h3&gt;Validating the event-driven application&lt;/h3&gt; &lt;p&gt;The last step in building an event-driven application is to validate that the service is receiving notifications. The demo in Figure 6 shows the Kafka event source using two different Kafka topics to trigger the Knative service.&lt;/p&gt; &lt;div id="attachment_756747" style="width: 560px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/07/6-events0.gif"&gt;&lt;img aria-describedby="caption-attachment-756747" class="wp-image-756747 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/07/6-events0.gif" alt="A demonstration of coding event notifications from a Kafka event source." width="550" height="502" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-756747" class="wp-caption-text"&gt;Figure 6: Event notifications from a Kafka event source.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Give us your feedback!&lt;/h2&gt; &lt;p&gt;A huge part of the OpenShift developer experience process is receiving feedback and collaborating with our community and customers. We&amp;#8217;d love to hear from you. We hope you will share your thoughts on the &lt;a target="_blank" rel="nofollow" href="https://forms.gle/zDd4tuWvjndCRVMD8"&gt;OpenShift 4.5 Developer Experience feedback page&lt;/a&gt;. You can also join our &lt;a target="_blank" rel="nofollow" href="https://groups.google.com/forum/#!forum/openshift-dev-users"&gt;OpenShift Developer Experience Google Group&lt;/a&gt; to participate in discussions and learn about our Office Hours sessions, where you can collaborate with us and provide feedback about your experience using the OpenShift web console.&lt;/p&gt; &lt;h2&gt;Get started with OpenShift 4.5&lt;/h2&gt; &lt;p&gt;Are you ready to get started with the new OpenShift 4.5 web console? &lt;a target="_blank" rel="nofollow" href="http://www.openshift.com/try"&gt;Try OpenShift 4.5 today&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F28%2Fcreating-event-sources-in-the-openshift-4-5-web-console%2F&amp;#38;linkname=Creating%20event%20sources%20in%20the%20OpenShift%204.5%20web%20console" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F28%2Fcreating-event-sources-in-the-openshift-4-5-web-console%2F&amp;#38;linkname=Creating%20event%20sources%20in%20the%20OpenShift%204.5%20web%20console" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F28%2Fcreating-event-sources-in-the-openshift-4-5-web-console%2F&amp;#38;linkname=Creating%20event%20sources%20in%20the%20OpenShift%204.5%20web%20console" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F28%2Fcreating-event-sources-in-the-openshift-4-5-web-console%2F&amp;#38;linkname=Creating%20event%20sources%20in%20the%20OpenShift%204.5%20web%20console" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F28%2Fcreating-event-sources-in-the-openshift-4-5-web-console%2F&amp;#38;linkname=Creating%20event%20sources%20in%20the%20OpenShift%204.5%20web%20console" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F28%2Fcreating-event-sources-in-the-openshift-4-5-web-console%2F&amp;#38;linkname=Creating%20event%20sources%20in%20the%20OpenShift%204.5%20web%20console" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F28%2Fcreating-event-sources-in-the-openshift-4-5-web-console%2F&amp;#38;linkname=Creating%20event%20sources%20in%20the%20OpenShift%204.5%20web%20console" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F28%2Fcreating-event-sources-in-the-openshift-4-5-web-console%2F&amp;#038;title=Creating%20event%20sources%20in%20the%20OpenShift%204.5%20web%20console" data-a2a-url="https://developers.redhat.com/blog/2020/07/28/creating-event-sources-in-the-openshift-4-5-web-console/" data-a2a-title="Creating event sources in the OpenShift 4.5 web console"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/07/28/creating-event-sources-in-the-openshift-4-5-web-console/"&gt;Creating event sources in the OpenShift 4.5 web console&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/WqreFkHs49k" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Red Hat OpenShift 4.5 makes it easier than ever to deploy and run event-driven applications that react to real-time information via event notifications. Empowered by OpenShift Serverless, applications come to life through events, scaling up resources as needed (or up to a pre-configured limit), and then scaling back to zero after the resource burst is [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/07/28/creating-event-sources-in-the-openshift-4-5-web-console/"&gt;Creating event sources in the OpenShift 4.5 web console&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2020/07/28/creating-event-sources-in-the-openshift-4-5-web-console/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">756407</post-id><dc:creator>Brian Tannous</dc:creator><dc:date>2020-07-28T07:00:08Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/07/28/creating-event-sources-in-the-openshift-4-5-web-console/</feedburner:origLink></entry><entry><title>BarcelonaJUG talk on Tuesday July 28th about Camel 3 in the era of Kubernetes and Serverless</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/LAbzjH4FsYk/barcelonajug-talk-on-tuesday-july-28th.html" /><category term="apache camel" scheme="searchisko:content:tags" /><category term="camelk" scheme="searchisko:content:tags" /><category term="feed_group_name_fusesource" scheme="searchisko:content:tags" /><category term="feed_name_clausibsen" scheme="searchisko:content:tags" /><category term="Presentation" scheme="searchisko:content:tags" /><author><name>Claus Ibsen</name></author><id>searchisko:content:id:jbossorg_blog-barcelonajug_talk_on_tuesday_july_28th_about_camel_3_in_the_era_of_kubernetes_and_serverless</id><updated>2020-07-27T14:39:19Z</updated><published>2020-07-27T14:39:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;Just back from PTO and myself and Andrea Cosentino are on the spot tomorrow where we have been invited by Barcelona JUG to give a talk about the Camel 3 and its latest innovation around Kubernetes and Serverless (and Kafka).&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-n-qFXEoQCPU/Xx7mxK1FBjI/AAAAAAAACOc/MfwGlrxLrBkhtZPWrHQBjhHgF1sOtHdCgCLcBGAsYHQ/s1600/barca-jug.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="133" data-original-width="200" src="https://1.bp.blogspot.com/-n-qFXEoQCPU/Xx7mxK1FBjI/AAAAAAAACOc/MfwGlrxLrBkhtZPWrHQBjhHgF1sOtHdCgCLcBGAsYHQ/s1600/barca-jug.jpg" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;It's a free and online event, in English, tomorrow Tuesday 28th at 19.00 CEST&lt;br /&gt;&lt;a href="https://www.meetup.com/es-ES/BarcelonaJUG/events/271746564/"&gt;https://www.meetup.com/es-ES/BarcelonaJUG/events/271746564/&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;The session runs for 45 min with Q and A at the end.&lt;br /&gt;&lt;br /&gt;PS: Just updated my platform to use latest Camel K 1.1.0 release, so hope the demo gods are on our side tomorrow.&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=Ct3TZtJAMn0:vLs3M2RPYeY:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=Ct3TZtJAMn0:vLs3M2RPYeY:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=Ct3TZtJAMn0:vLs3M2RPYeY:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=Ct3TZtJAMn0:vLs3M2RPYeY:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=Ct3TZtJAMn0:vLs3M2RPYeY:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=Ct3TZtJAMn0:vLs3M2RPYeY:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=Ct3TZtJAMn0:vLs3M2RPYeY:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/ApacheCamel/~4/Ct3TZtJAMn0" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/LAbzjH4FsYk" height="1" width="1" alt=""/&gt;</content><summary>Just back from PTO and myself and Andrea Cosentino are on the spot tomorrow where we have been invited by Barcelona JUG to give a talk about the Camel 3 and its latest innovation around Kubernetes and Serverless (and Kafka). It's a free and online event, in English, tomorrow Tuesday 28th at 19.00 CEST https://www.meetup.com/es-ES/BarcelonaJUG/events/271746564/ The session runs for 45 min with Q an...</summary><dc:creator>Claus Ibsen</dc:creator><dc:date>2020-07-27T14:39:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/ApacheCamel/~3/Ct3TZtJAMn0/barcelonajug-talk-on-tuesday-july-28th.html</feedburner:origLink></entry><entry><title>Infinispan 12.0.0.Dev01</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/22Sly3ElP2c/" /><category term="Development" scheme="searchisko:content:tags" /><category term="feed_group_name_infinispan" scheme="searchisko:content:tags" /><category term="feed_name_infinispan" scheme="searchisko:content:tags" /><category term="release" scheme="searchisko:content:tags" /><author><name>Tristan Tarrant</name></author><id>searchisko:content:id:jbossorg_blog-infinispan_12_0_0_dev01</id><updated>2020-07-27T12:42:34Z</updated><published>2020-07-27T12:00:00Z</published><content type="html">&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Dear Infinispan community,&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The first of our development releases of Infinispan 12 is here and it features our upgrade to &lt;a href="https://hibernate.org/search/"&gt;Hibernate Search 6&lt;/a&gt; which finally allows us to upgrade to &lt;a href="https://lucene.apache.org/"&gt;Lucene 8.x&lt;/a&gt;. We’ve had to change a few things in our query implementation to accommodate the latest and greatest and to make the feature simpler to use. As expected, being a development release, there are some rough edges and we’d really love &lt;strong&gt;YOUR&lt;/strong&gt; help in making sure that we get everything right for the final release later this year.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;You can look at the &lt;a href="https://issues.redhat.com/secure/ReleaseNote.jspa?projectId=12310799&amp;amp;version=12346555"&gt;release notes&lt;/a&gt; to see what has changed.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;We’re hard at work on new features, improvements and fixes, so watch this space for more announcements!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_get_it_use_it_ask_us"&gt;&lt;a class="anchor" href="#_get_it_use_it_ask_us" /&gt;Get it, Use it, Ask us!&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Please &lt;a href="https://infinispan.org/download/"&gt;download&lt;/a&gt;, &lt;a href="https://issues.redhat.com/projects/ISPN"&gt;report bugs&lt;/a&gt;, &lt;a href="https://infinispan.zulipchat.com/"&gt;chat with us&lt;/a&gt;, ask questions on &lt;a href="https://stackoverflow.com/questions/tagged/?tagnames=infinispan&amp;amp;sort=newest"&gt;StackOverflow&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/22Sly3ElP2c" height="1" width="1" alt=""/&gt;</content><summary>Dear Infinispan community, The first of our development releases of Infinispan 12 is here and it features our upgrade to Hibernate Search 6 which finally allows us to upgrade to Lucene 8.x. We’ve had to change a few things in our query implementation to accommodate the latest and greatest and to make the feature simpler to use. As expected, being a development release, there are some rough edges a...</summary><dc:creator>Tristan Tarrant</dc:creator><dc:date>2020-07-27T12:00:00Z</dc:date><feedburner:origLink>http://infinispan.org/blog/2020/07/27/infinispan-12/</feedburner:origLink></entry><entry><title>Deploy your Java web application into the cloud using Eclipse JKube</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/T9JxkRZHv7U/" /><category term="Developer Tools" /><category term="Java" /><category term="Kubernetes" /><category term="apache maven" /><category term="deploy war" /><category term="fabric8" /><category term="openshift" /><category term="Spring Web MVC" /><author><name>Marc Nuri</name></author><id>https://developers.redhat.com/blog/?p=728897</id><updated>2020-07-27T07:00:54Z</updated><published>2020-07-27T07:00:54Z</published><content type="html">&lt;p&gt;Before we had &lt;a href="https://developers.redhat.com/topics/spring-boot"&gt;Spring Boot&lt;/a&gt; and similar frameworks, a web app container was the main requirement for deploying &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java web applications&lt;/a&gt;. We now live in the age of &lt;a href="https://developers.redhat.com/topics/microservices"&gt;microservices&lt;/a&gt;, and many Java applications are developed on top of &lt;a href="https://developers.redhat.com/products/quarkus/getting-started"&gt;Quarkus&lt;/a&gt;, &lt;a target="_blank" rel="nofollow" href="https://thorntail.io/"&gt;Thorntail&lt;/a&gt;, or Spring Boot. But some use cases still require an old-school web application.&lt;/p&gt; &lt;p&gt;In this article, you will learn how to deploy a Java web application (WAR) into a &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; or &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; cluster using &lt;a href="https://developers.redhat.com/blog/2020/01/28/introduction-to-eclipse-jkube-java-tooling-for-kubernetes-and-red-hat-openshift/"&gt;Eclipse JKube&lt;/a&gt;. I&amp;#8217;ll show you how easy it is to make a monolithic Java web application cloud-native, just by adding &lt;a target="_blank" rel="nofollow" href="https://www.eclipse.org/jkube"&gt;Eclipse JKube&lt;/a&gt; Maven plugins.&lt;/p&gt; &lt;h2&gt;The example web application&lt;/h2&gt; &lt;p&gt;For the purpose of this article, we&amp;#8217;ll work with a very simple &lt;a target="_blank" rel="nofollow" href="https://docs.spring.io/spring-framework/docs/5.2.7.RELEASE/spring-framework-reference/web.html#spring-web"&gt;Spring Web MVC&lt;/a&gt; application. The following sample shows the most relevant parts of the Maven project&amp;#8217;s &lt;a target="_blank" rel="nofollow" href="https://github.com/marcnuri-demo/eclipse-jkube-webapp/blob/v0.0.0-tomcat/pom.xml"&gt;pom.xml&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&amp;#60;!-- ... --&amp;#62; &amp;#60;packaging&amp;#62;war&amp;#60;/packaging&amp;#62; &amp;#60;!-- ... --&amp;#62; &amp;#60;properties&amp;#62; &amp;#60;maven.compiler.source&amp;#62;11&amp;#60;/maven.compiler.source&amp;#62; &amp;#60;maven.compiler.target&amp;#62;11&amp;#60;/maven.compiler.target&amp;#62; &amp;#60;failOnMissingWebXml&amp;#62;false&amp;#60;/failOnMissingWebXml&amp;#62; &amp;#60;!-- ... --&amp;#62; &amp;#60;jkube.enricher.jkube-service.type&amp;#62;NodePort&amp;#60;/jkube.enricher.jkube-service.type&amp;#62; &amp;#60;/properties&amp;#62; &amp;#60;dependencies&amp;#62; &amp;#60;dependency&amp;#62; &amp;#60;groupId&amp;#62;org.springframework&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;spring-webmvc&amp;#60;/artifactId&amp;#62; &amp;#60;version&amp;#62;${version.spring}&amp;#60;/version&amp;#62; &amp;#60;/dependency&amp;#62; &amp;#60;dependency&amp;#62; &amp;#60;groupId&amp;#62;javax.servlet&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;javax.servlet-api&amp;#60;/artifactId&amp;#62; &amp;#60;version&amp;#62;4.0.1&amp;#60;/version&amp;#62; &amp;#60;scope&amp;#62;provided&amp;#60;/scope&amp;#62; &amp;#60;/dependency&amp;#62; &amp;#60;/dependencies&amp;#62; &amp;#60;build&amp;#62; &amp;#60;plugins&amp;#62; &amp;#60;plugin&amp;#62; &amp;#60;groupId&amp;#62;org.eclipse.jkube&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;kubernetes-maven-plugin&amp;#60;/artifactId&amp;#62; &amp;#60;version&amp;#62;${version.jkube}&amp;#60;/version&amp;#62; &amp;#60;/plugin&amp;#62; &amp;#60;!-- ... --&amp;#62; &amp;#60;/plugins&amp;#62; &amp;#60;/build&amp;#62; &lt;/pre&gt; &lt;p&gt;First, notice the &lt;code&gt;packaging&lt;/code&gt; element, which indicates that the resulting artifact should be packaged as a &lt;code&gt;war&lt;/code&gt; file, which is the usual format for Java web applications.&lt;/p&gt; &lt;p&gt;In the properties section, notice that the project is configured for Java 11. We&amp;#8217;ll need a compatible JDK to build the project. We use the &lt;a target="_blank" rel="nofollow" href="https://maven.apache.org/plugins/maven-war-plugin/war-mojo.html#failOnMissingWebXml"&gt;failOnMissingWebXml&lt;/a&gt; option to configure the &lt;a target="_blank" rel="nofollow" href="https://maven.apache.org/plugins/maven-war-plugin/"&gt;maven-war-plugin&lt;/a&gt; so that it won&amp;#8217;t fail due to a missing &lt;code&gt;web.xml&lt;/code&gt; file. (You will see soon what we&amp;#8217;re using instead.) Finally, there&amp;#8217;s a JKube-specific property, &lt;code&gt;jkube.enricher.jkube-service.type&lt;/code&gt;. This property configures JKube to create a service-resource manifest using &lt;code&gt;NodePort&lt;/code&gt; as the &lt;code&gt;spec.type&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;In the dependencies section, we find just two dependencies. The &lt;code&gt;spring-webmvc&lt;/code&gt; dependency lets us use the Spring Web MVC framework. The &lt;code&gt;javax.servlet-api&lt;/code&gt; dependency provides compile-time support for the Java Servlet API, which is provided by the web application container at runtime.&lt;/p&gt; &lt;p&gt;Finally, in the plugins section, we&amp;#8217;ve configured the Eclipse JKube dependency. Note that we can use either the &lt;code&gt;kubernetes-maven-plugin&lt;/code&gt; or the &lt;code&gt;openshift-maven-plugin&lt;/code&gt;. The choice of plugin depends on the cluster we want to target, but we only need one of them.&lt;/p&gt; &lt;p&gt;The configuration is simple and straightforward. The only thing different from a typical, old-school Java web application is the Eclipse JKube plugin dependency.&lt;/p&gt; &lt;h3&gt;Java classes in the example project&lt;/h3&gt; &lt;p&gt;The example project contains three Java classes: &lt;code&gt;ExampleInitializer&lt;/code&gt;, &lt;code&gt;ExampleConfiguration&lt;/code&gt;, and &lt;code&gt;ExampleResource&lt;/code&gt;. First, &lt;a target="_blank" rel="nofollow" href="https://github.com/marcnuri-demo/eclipse-jkube-webapp/blob/v0.0.0-tomcat/src/main/java/com/marcnuri/demo/jkube/ExampleInitializer.java"&gt;ExampleInitializer&lt;/a&gt; is a &lt;code&gt;WebApplicationInitializer&lt;/code&gt; implementation. We&amp;#8217;re using it instead of the standard &lt;code&gt;WEB-INF/web.xml&lt;/code&gt; deployment descriptor to configure the &lt;a target="_blank" rel="nofollow" href="https://docs.oracle.com/javaee/7/api/javax/servlet/ServletContext.html?is-external=true"&gt;ServletContext&lt;/a&gt; programmatically.&lt;/p&gt; &lt;p&gt;The following code shows how &lt;code&gt;ExampleInitializer&lt;/code&gt; lets us register Spring&amp;#8217;s &lt;code&gt;DispatcherServlet&lt;/code&gt; without any additional XML configuration:&lt;/p&gt; &lt;pre&gt;final AnnotationConfigWebApplicationContext context = new AnnotationConfigWebApplicationContext(); context.register(ExampleConfiguration.class); context.setServletContext(servletContext); final ServletRegistration.Dynamic dsr = servletContext.addServlet("dispatcher", new DispatcherServlet(context)); dsr.setLoadOnStartup(1); dsr.addMapping("/"); &lt;/pre&gt; &lt;p&gt;The &lt;a target="_blank" rel="nofollow" href="https://github.com/marcnuri-demo/eclipse-jkube-webapp/blob/v0.0.0-tomcat/src/main/java/com/marcnuri/demo/jkube/ExampleConfiguration.java"&gt;ExampleConfiguration&lt;/a&gt; class is a Spring-specific configuration enabling Spring MVC.&lt;/p&gt; &lt;p&gt;Finally, &lt;a target="_blank" rel="nofollow" href="https://github.com/marcnuri-demo/eclipse-jkube-webapp/blob/v0.0.0-tomcat/src/main/java/com/marcnuri/demo/jkube/ExampleResource.java"&gt;ExampleResource&lt;/a&gt; is a standard Spring @&lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/web/bind/annotation/RestController.html"&gt;RestController&lt;/a&gt;&lt;/code&gt;. It has a single request mapping that responds &lt;b&gt;Hello!!!&lt;/b&gt; to any &lt;code&gt;GET&lt;/code&gt; request.&lt;/p&gt; &lt;h2&gt;Deploy the web application into Kubernetes&lt;/h2&gt; &lt;p&gt;We&amp;#8217;ll start by deploying the example web application into Kubernetes; then, I&amp;#8217;ll show you how to make a couple of adjustments and deploy it into OpenShift.&lt;/p&gt; &lt;h3&gt;Step 1: Build the application&lt;/h3&gt; &lt;p&gt;The first step is to build the project just as we would build any other Maven web application project. Running &lt;code&gt;mvn clean package&lt;/code&gt; generates a new &lt;code&gt;war&lt;/code&gt; artifact in the target directory of &lt;code&gt;target/example-0.0.0-SNAPSHOT.war&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;For the purpose of this example, we&amp;#8217;ll use &lt;a target="_blank" rel="nofollow" href="https://kubernetes.io/docs/setup/learning-environment/minikube/"&gt;Minikube&lt;/a&gt;. So that we can pull the image from the cluster without having to push it to a shared registry, we&amp;#8217;ll use Minikube&amp;#8217;s &lt;code&gt;docker&lt;/code&gt; daemon, &lt;code&gt;eval $(minikube docker-env)&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;We can now issue the &lt;code&gt;mvn k8s:build&lt;/code&gt; command to build the docker image for our application, as shown in Figure 1.&lt;/p&gt; &lt;div id="attachment_734397" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/k8s-build.png"&gt;&lt;img aria-describedby="caption-attachment-734397" class="wp-image-734397" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/k8s-build.png" alt="A screenshot of the console showing the mvn k8s:build command and build output." width="640" height="276" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/k8s-build.png 971w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/k8s-build-300x129.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/k8s-build-768x331.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-734397" class="wp-caption-text"&gt;Figure 1: Build the docker image for the application.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;A new docker image will be tagged as &lt;code&gt;webapp/example:latest&lt;/code&gt; in our docker registry.&lt;/p&gt; &lt;h3&gt;Step 2: Create the cluster configuration&lt;/h3&gt; &lt;p&gt;Next, we create the required cluster configuration resource manifests and apply them to the &lt;code&gt;kubectl&lt;/code&gt;&amp;#8211; configured cluster, as shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_734417" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/k8s-resource-apply.png"&gt;&lt;img aria-describedby="caption-attachment-734417" class="wp-image-734417" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/k8s-resource-apply.png" alt="A screenshot of the console showing mvn k8s:resource and k8s:apply commands and output." width="640" height="359" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/k8s-resource-apply.png 969w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/k8s-resource-apply-300x168.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/k8s-resource-apply-768x431.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-734417" class="wp-caption-text"&gt;Figure 2: Create and deploy the cluster configuration.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The previous commands will generate the Kubernetes configuration manifests in &lt;code&gt;target/classes/META-INF/jkube/kubernetes.yml&lt;/code&gt;, and will apply them to the cluster.&lt;/p&gt; &lt;h3&gt;Step 3: Verify that the application is running&lt;/h3&gt; &lt;p&gt;Finally, we verify that everything is running by entering the commands shown in Figure 3.&lt;/p&gt; &lt;div id="attachment_734447" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/verify-deployments.png"&gt;&lt;img aria-describedby="caption-attachment-734447" class="wp-image-734447" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/verify-deployments.png" alt="A screenshot of the console showing the kubectl get pod command and output." width="640" height="115" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/verify-deployments.png 967w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/verify-deployments-300x54.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/verify-deployments-768x138.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-734447" class="wp-caption-text"&gt;Figure 3: Verify that the application is running.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Deploy the web application into OpenShift&lt;/h2&gt; &lt;p&gt;Following similar steps to those in the previous section, we can seamlessly deploy the example web application to an OpenShift cluster, just by using the &lt;code&gt;openshift-maven-plugin&lt;/code&gt; instead of the &lt;code&gt;kubernetes-maven-plugin&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&amp;#60;build&amp;#62; &amp;#60;plugins&amp;#62; &amp;#60;plugin&amp;#62; &amp;#60;groupId&amp;#62;org.eclipse.jkube&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;openshift-maven-plugin&amp;#60;/artifactId&amp;#62; &amp;#60;version&amp;#62;${version.jkube}&amp;#60;/version&amp;#62; &amp;#60;/plugin&amp;#62; &amp;#60;/plugins&amp;#62; &amp;#60;/build&amp;#62; &lt;/pre&gt; &lt;p&gt;In this case, the plugin prefix is &lt;code&gt;oc&lt;/code&gt; instead of &lt;code&gt;k8s&lt;/code&gt;, but the goals to be run are the same. Note that in this case, the build step uses S2I instead of docker to perform the build.&lt;/p&gt; &lt;div id="attachment_734467" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/oc-build.png"&gt;&lt;img aria-describedby="caption-attachment-734467" class="wp-image-734467" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/oc-build.png" alt="A screenshot of the console showing mvn oc:build command and output." width="640" height="669" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/oc-build.png 966w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/oc-build-287x300.png 287w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/oc-build-768x803.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-734467" class="wp-caption-text"&gt;Figure 4: Build the container image using S2I binary build strategy for the application.&lt;/p&gt;&lt;/div&gt; &lt;div id="attachment_734477" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/oc-resource-apply-verify.png"&gt;&lt;img aria-describedby="caption-attachment-734477" class="wp-image-734477" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/oc-resource-apply-verify.png" alt="A screenshot of the console showing mvn oc:resource and oc:apply commands and output." width="640" height="492" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/oc-resource-apply-verify.png 968w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/oc-resource-apply-verify-300x231.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/oc-resource-apply-verify-768x590.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-734477" class="wp-caption-text"&gt;Figure 5: Create and deploy the cluster OpenShift specific configuration.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;The developer experience&lt;/h2&gt; &lt;p&gt;You&amp;#8217;ve seen how Eclipse JKube lets us easily deploy a web application to the cloud. It also has other features to ease our lives as developers. Let&amp;#8217;s look at how Eclipse JKube enhances a typical log retrieval.&lt;/p&gt; &lt;h3&gt;Log retrieval&lt;/h3&gt; &lt;p&gt;If we want to print the logs for the web application that we just deployed, we can simply run &lt;code&gt;mvn k8s:log&lt;/code&gt;. The logs will be printed and followed (or tailed) in the current console, as shown in Figure 6.&lt;/p&gt; &lt;div id="attachment_734497" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/k8s-log.png"&gt;&lt;img aria-describedby="caption-attachment-734497" class="wp-image-734497 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/k8s-log-1024x532.png" alt="A screenshot of the mvn k8s:log command and output." width="640" height="333" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/k8s-log-1024x532.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/k8s-log-300x156.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/k8s-log-768x399.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-734497" class="wp-caption-text"&gt;Figure 6: Logs for the Kubernetes application deployment.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The screenshot in Figure 6 shows the log for the application we&amp;#8217;ve just deployed on Kubernetes. You can see that the Apache Tomcat web application container was started and that the web application was deployed into the ROOT context.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: By default, Eclipse JKube uses &lt;a target="_blank" rel="nofollow" href="https://tomcat.apache.org/"&gt;Apache Tomcat&lt;/a&gt; as its web application container, via the &lt;a target="_blank" rel="nofollow" href="https://quay.io/repository/jkube/jkube-tomcat9-binary-s2i"&gt;jkube/jkube-tomcat9-binary-s2i&lt;/a&gt; base image. In a follow-up article, I will show you how to use different web application containers (such as &lt;a target="_blank" rel="nofollow" href="https://www.eclipse.org/jetty/"&gt;Jetty&lt;/a&gt;), just by adding container-specific files.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In this article, you&amp;#8217;ve seen how easy it is to convert an old-school Java web application into a full-fledged cloud-native application, just by adding the Eclipse JKube plugin dependency to your Maven POM. The complete source code for the examples is available on &lt;a target="_blank" rel="nofollow" href="https://github.com/marcnuri-demo/eclipse-jkube-webapp/tree/v0.0.0-tomcat"&gt;GitHub&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;If you&amp;#8217;re interested in learning more about Eclipse JKube, you can visit our main &lt;a target="_blank" rel="nofollow" href="https://github.com/eclipse/jkube"&gt;GitHub repository&lt;/a&gt;, &lt;a target="_blank" rel="nofollow" href="https://www.eclipse.org/jkube/"&gt;website&lt;/a&gt;, or &lt;a target="_blank" rel="nofollow" href="https://gitter.im/eclipse/jkube"&gt;Gitter channel&lt;/a&gt;. And don&amp;#8217;t forget to follow us on &lt;a target="_blank" rel="nofollow" href="https://twitter.com/jkubeio"&gt;Twitter&lt;/a&gt;!&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F27%2Fdeploy-your-java-web-application-into-the-cloud-using-eclipse-jkube%2F&amp;#38;linkname=Deploy%20your%20Java%20web%20application%20into%20the%20cloud%20using%20Eclipse%20JKube" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F27%2Fdeploy-your-java-web-application-into-the-cloud-using-eclipse-jkube%2F&amp;#38;linkname=Deploy%20your%20Java%20web%20application%20into%20the%20cloud%20using%20Eclipse%20JKube" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F27%2Fdeploy-your-java-web-application-into-the-cloud-using-eclipse-jkube%2F&amp;#38;linkname=Deploy%20your%20Java%20web%20application%20into%20the%20cloud%20using%20Eclipse%20JKube" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F27%2Fdeploy-your-java-web-application-into-the-cloud-using-eclipse-jkube%2F&amp;#38;linkname=Deploy%20your%20Java%20web%20application%20into%20the%20cloud%20using%20Eclipse%20JKube" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F27%2Fdeploy-your-java-web-application-into-the-cloud-using-eclipse-jkube%2F&amp;#38;linkname=Deploy%20your%20Java%20web%20application%20into%20the%20cloud%20using%20Eclipse%20JKube" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F27%2Fdeploy-your-java-web-application-into-the-cloud-using-eclipse-jkube%2F&amp;#38;linkname=Deploy%20your%20Java%20web%20application%20into%20the%20cloud%20using%20Eclipse%20JKube" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F27%2Fdeploy-your-java-web-application-into-the-cloud-using-eclipse-jkube%2F&amp;#38;linkname=Deploy%20your%20Java%20web%20application%20into%20the%20cloud%20using%20Eclipse%20JKube" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F27%2Fdeploy-your-java-web-application-into-the-cloud-using-eclipse-jkube%2F&amp;#038;title=Deploy%20your%20Java%20web%20application%20into%20the%20cloud%20using%20Eclipse%20JKube" data-a2a-url="https://developers.redhat.com/blog/2020/07/27/deploy-your-java-web-application-into-the-cloud-using-eclipse-jkube/" data-a2a-title="Deploy your Java web application into the cloud using Eclipse JKube"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/07/27/deploy-your-java-web-application-into-the-cloud-using-eclipse-jkube/"&gt;Deploy your Java web application into the cloud using Eclipse JKube&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/T9JxkRZHv7U" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Before we had Spring Boot and similar frameworks, a web app container was the main requirement for deploying Java web applications. We now live in the age of microservices, and many Java applications are developed on top of Quarkus, Thorntail, or Spring Boot. But some use cases still require an old-school web application. In this [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/07/27/deploy-your-java-web-application-into-the-cloud-using-eclipse-jkube/"&gt;Deploy your Java web application into the cloud using Eclipse JKube&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">728897</post-id><dc:creator>Marc Nuri</dc:creator><dc:date>2020-07-27T07:00:54Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/07/27/deploy-your-java-web-application-into-the-cloud-using-eclipse-jkube/</feedburner:origLink></entry><entry><title>How to Install Red Hat Process Automation Manager 7.7</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/6NMS8BoMsxg/how-to-install-rhpam-77.html" /><category term="AppDev" scheme="searchisko:content:tags" /><category term="Automate" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="Process Automation Manager" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-how_to_install_red_hat_process_automation_manager_7_7</id><updated>2020-07-27T05:00:00Z</updated><published>2020-07-27T05:00:00Z</published><content type="html">&lt;div&gt;&lt;p style="margin: 0px;"&gt;In the past&amp;nbsp;&lt;a data-blogger-escaped-style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;" href="https://1.bp.blogspot.com/-XtYIWE6HERs/XhNb1fqEqwI/AAAAAAAAw2A/SymJTAO25ts4tEjkEWGMA4dJl09Vi3HQwCNcBGAsYHQ/s1600/rhpam-login.png" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"&gt;&lt;img alt="red hat process automation manager" border="0" data-blogger-escaped-data-original-height="927" data-blogger-escaped-data-original-width="1600" height="185" src="https://1.bp.blogspot.com/-XtYIWE6HERs/XhNb1fqEqwI/AAAAAAAAw2A/SymJTAO25ts4tEjkEWGMA4dJl09Vi3HQwCNcBGAsYHQ/s320/rhpam-login.png" style="cursor: move;" title="" width="320" /&gt;&lt;/a&gt;I've kept you up to date on installing Red Hat Process Automation Manager with my easy install project.&amp;nbsp;&lt;/p&gt;&lt;p style="margin: 0px;"&gt;&lt;br /&gt;&lt;/p&gt;&lt;p style="margin: 0px;"&gt;Well here's an update that installs the latest process automation tooling for your development projects in just minutes on your very own machine.&lt;/p&gt;&lt;p style="margin: 0px;"&gt;&lt;br /&gt;&lt;/p&gt;&lt;p style="margin: 0px;"&gt;Not only that, it's done in just three easy steps, so let's take a closer look and see if I'm pulling your leg or telling the truth about how easy this installation can be.&lt;/p&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;p style="margin: 0px;"&gt;&lt;br /&gt;&lt;/p&gt;&lt;p style="margin: 0px;"&gt;Just three easy steps to a fully installed and configured Red Hat Process Automation manager.&lt;/p&gt;&lt;h2 data-blogger-escaped-data-sourcepos="6:1-8:122" dir="auto"&gt;Install on your machine&lt;/h2&gt;&lt;p style="margin: 0px;"&gt;&lt;a data-blogger-escaped-style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;" href="https://1.bp.blogspot.com/-2AAONrobo6Y/XhNbzlLbFYI/AAAAAAAAw18/UBkTqMie9dY-dEyUGSzMQLkFvFfRW_EZACNcBGAsYHQ/s1600/rhpam-business-central.png" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="red hat process automation manager" border="0" data-blogger-escaped-data-original-height="935" data-blogger-escaped-data-original-width="1600" height="186" src="https://1.bp.blogspot.com/-2AAONrobo6Y/XhNbzlLbFYI/AAAAAAAAw18/UBkTqMie9dY-dEyUGSzMQLkFvFfRW_EZACNcBGAsYHQ/s320/rhpam-business-central.png" style="cursor: move;" title="" width="320" /&gt;&lt;/a&gt;There are a few component you'll need to download for free from the provided developers site, then obtain the project linked below, add the&amp;nbsp; downloads, and run the installation script.&lt;/p&gt;&lt;p style="margin: 0px;"&gt;&lt;br /&gt;&lt;/p&gt;&lt;p style="margin: 0px;"&gt;Watch the installation unfold before your eyes, with configuration, settings, and user creation all detailed in the script output so you can learn from the installation.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;p style="margin: 0px;"&gt;Give it a try with these three steps:&lt;/p&gt;&lt;ol data-blogger-escaped-data-sourcepos="8:1-17:0" data-blogger-escaped-style="text-align: left;"&gt;&lt;li data-blogger-escaped-data-sourcepos="8:1-9:0"&gt;&lt;div data-blogger-escaped-data-sourcepos="8:4-8:122"&gt;&lt;p style="margin: 0px;"&gt;&lt;a href="https://gitlab.com/bpmworkshop/rhpam-install-demo/-/archive/master/rhpam-install-demo-master.zip"&gt;Download and unzip.&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;div data-blogger-escaped-data-sourcepos="8:4-8:122"&gt;&lt;p style="margin: 0px;"&gt;&lt;br /&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li data-blogger-escaped-data-sourcepos="10:1-11:0"&gt;&lt;div data-blogger-escaped-data-sourcepos="10:4-10:81"&gt;&lt;p style="margin: 0px;"&gt;Add products to installs directory, see installs/README for details and links.&lt;/p&gt;&lt;/div&gt;&lt;div data-blogger-escaped-data-sourcepos="10:4-10:81"&gt;&lt;p style="margin: 0px;"&gt;&lt;br /&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li data-blogger-escaped-data-sourcepos="14:1-15:0"&gt;&lt;div data-blogger-escaped-data-sourcepos="12:4-12:92"&gt;&lt;p style="margin: 0px;"&gt;Run 'init.sh' or 'init.bat' file. 'init.bat' must be run with Administrative privileges.&lt;/p&gt;&lt;/div&gt;&lt;div data-blogger-escaped-data-sourcepos="12:4-12:92"&gt;&lt;p style="margin: 0px;"&gt;&lt;br /&gt;&lt;/p&gt;&lt;/div&gt;&amp;nbsp;Login to&amp;nbsp;&lt;a data-blogger-escaped-target="_blank" href="http://localhost:8080/business-central" rel="nofollow noreferrer noopener"&gt;http://localhost:8080/business-central&lt;/a&gt;&amp;nbsp;(u:erics / p:redhatpam1!)&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;&lt;p style="margin: 0px;"&gt;That's it, not it's time to enjoy your installed and configured Red Hat Process Automation Manager.&lt;/p&gt;&lt;div&gt;&lt;p style="margin: 0px;"&gt;&lt;br /&gt;&lt;/p&gt;&lt;p style="margin: 0px;"&gt;Not sure how to get started with process automation? Try the&amp;nbsp;&lt;a href="https://bpmworkshop.gitlab.io/rhdm/index.html" rel="noreferrer noopener" target="_blank"&gt;online workshop&lt;/a&gt;&amp;nbsp;to get started building a first process automation project from scratch.&lt;/p&gt;&lt;p style="margin: 0px;"&gt;&lt;br /&gt;&lt;/p&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=A5Tb9wnN75w:v1UwBoupQvY:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=A5Tb9wnN75w:v1UwBoupQvY:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=A5Tb9wnN75w:v1UwBoupQvY:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=A5Tb9wnN75w:v1UwBoupQvY:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=A5Tb9wnN75w:v1UwBoupQvY:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=A5Tb9wnN75w:v1UwBoupQvY:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=A5Tb9wnN75w:v1UwBoupQvY:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=A5Tb9wnN75w:v1UwBoupQvY:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=A5Tb9wnN75w:v1UwBoupQvY:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=A5Tb9wnN75w:v1UwBoupQvY:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=A5Tb9wnN75w:v1UwBoupQvY:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/A5Tb9wnN75w" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/6NMS8BoMsxg" height="1" width="1" alt=""/&gt;</content><summary>In the past I've kept you up to date on installing Red Hat Process Automation Manager with my easy install project.  Well here's an update that installs the latest process automation tooling for your development projects in just minutes on your very own machine. Not only that, it's done in just three easy steps, so let's take a closer look and see if I'm pulling your leg or telling the truth about...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2020-07-27T05:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/A5Tb9wnN75w/how-to-install-rhpam-77.html</feedburner:origLink></entry><entry><title>Installing Red Hat Advanced Cluster Management (ACM) for Kubernetes</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/UOe3AZ4AIes/" /><category term="CI/CD" /><category term="DevOps" /><category term="Kubernetes" /><category term="Operator" /><category term="cluster management" /><category term="kubernetes container storage" /><category term="manage cluster" /><category term="openshift" /><category term="openshift container storage" /><author><name>Bryant Son</name></author><id>https://developers.redhat.com/blog/?p=725337</id><updated>2020-07-23T07:00:43Z</updated><published>2020-07-23T07:00:43Z</published><content type="html">&lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/resources/advanced-cluster-management-kubernetes-faq"&gt;Red Hat Advanced Cluster Management (ACM) for Kubernetes&lt;/a&gt; offers end-to-end visibility and control for managing your cluster and application lifecycle. Among other features, it ensures security and compliance for your entire &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; domain across multiple data centers and public clouds.&lt;/p&gt; &lt;p&gt;This article guides you through setting up your &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift 4&lt;/a&gt; environment for an ACM installation and then installing ACM. For reasons that I will explain, we&amp;#8217;ll use the command line interface (CLI) to set up the installation environment. Once the environment is set up, I will show you how to complete the installation using either the CLI or the OpenShift web console, with examples for both methods.&lt;/p&gt; &lt;p&gt;Note that I will not demonstrate how to install ACM in a restricted environment. Also, my examples are based on &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/blog/red-hat-introduces-advanced-cluster-management-kubernetes"&gt;Advanced Cluster Management for Kubernetes 1.0. Tech Preview&lt;/a&gt;. You might need to update some of the installation steps for a newer version of ACM.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: See &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/resources/advanced-cluster-management-kubernetes-datasheet"&gt;&lt;i&gt;Red Hat Advanced Cluster Management for Kubernetes&lt;/i&gt;&lt;/a&gt; for more about the features and benefits of ACM.&lt;/p&gt; &lt;h2&gt;ACM installation overview&lt;/h2&gt; &lt;p&gt;You can use either the OpenShift 4 web console&amp;#8217;s built-in &lt;a href="https://developers.redhat.com/topics/kubernetes/operators"&gt;OperatorHub&lt;/a&gt; or the OpenShift CLI to install ACM. The installation breaks down to six steps:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Prepare the environment for the ACM installation.&lt;/li&gt; &lt;li&gt;Create a new OpenShift project and namespace.&lt;/li&gt; &lt;li&gt;Create an image-pull secret.&lt;/li&gt; &lt;li&gt;Install ACM and subscribe to the ACM &lt;a href="https://developers.redhat.com/topics/kubernetes/operators/"&gt;Operator&lt;/a&gt; group.&lt;/li&gt; &lt;li&gt;Create the MultiClusterHub resource.&lt;/li&gt; &lt;li&gt;Verify the ACM installation.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;We will use the OpenShift command line for the first several steps; then, I will show you how to use either the command line or the OpenShift 4 web console.&lt;/p&gt; &lt;h2&gt;Step 1: Prepare the environment for the ACM Installation&lt;/h2&gt; &lt;p&gt;Before starting with the installation process, make sure that you have the correct version of OpenShift and other resources set up in your development environment. Before you start setting up your development environment for ACM, make sure that you have OpenShift 4.3 or higher installed on Linux x86_64 and &lt;a href="https://developers.redhat.com/topics/linux"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL) 7.6 or higher.&lt;/p&gt; &lt;p&gt;There are a number of important details to consider before proceeding. One is the number of pods per node. The number of pods you need depends on the application type and how you configure the worker nodes. The maximum pod per node is 500 and the maximum pod per CPU core is 10.&lt;/p&gt; &lt;p&gt;Another is that the cluster size depends on the number of worker nodes. If your cluster has a few worker nodes, consider increasing the number of worker nodes while decreasing the size of each node for adequate headspace, efficiency, mobility, and resiliency.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: &lt;a target="_blank" rel="nofollow" href="https://www.openshift.com/blog/500_pods_per_node"&gt;Learn more&lt;/a&gt; about minimum and maximum node configuration and pod resource sizing.&lt;/p&gt; &lt;p&gt;You also need to consider the memory that is required for the specific type of workload you will be running, plus for the other application frameworks in your environment. And, you have to be prepared to accommodate workload mobility.&lt;/p&gt; &lt;p&gt;As an example, if your OpenShift installation is running on Amazon Web Services (AWS), it is recommended that you use a node size of m5.2xlarge or above. Figure 1 shows the configuration options for ACM clusters running on AWS.&lt;/p&gt; &lt;div id="attachment_729757" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/1.png"&gt;&lt;img aria-describedby="caption-attachment-729757" class="wp-image-729757 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/1-1024x567.png" alt="A screenshot of a table showing the maximum number of managed clusters running on AWS." width="640" height="354" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/1-1024x567.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/1-300x166.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/1-768x425.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/1.png 1278w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-729757" class="wp-caption-text"&gt;Figure 1: Cluster maximums for running ACM on Amazon Web Services.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;If you are a cluster admin, you can increase the size of worker nodes using &lt;code&gt;machineset&lt;/code&gt; sizing operations. To upgrade to a node size of m5.2xlarge:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;List the machinesets:&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;$ oc get machinesets -n openshift-machine-api&lt;/pre&gt; &lt;ol start="2"&gt; &lt;li&gt;Next, upgrade the instance type of CLUSTER_NAME to m5.2xlarge:&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;$ oc patch machineset CLUSTER_NAME --type='merge' --patch='{&amp;#38;quot;spec&amp;#38;quot;: { &amp;#38;quot;template&amp;#38;quot;: { &amp;#38;quot;spec&amp;#38;quot;: { &amp;#38;quot;providerSpec&amp;#38;quot;: { &amp;#38;quot;value&amp;#38;quot;: { &amp;#38;quot;instanceType&amp;#38;quot;: &amp;#38;quot;m5.2xlarge&amp;#38;quot;}}}}}}' -n openshift-machine-api&amp;#38;lt;/pre&amp;#38;gt;&lt;/pre&gt; &lt;ol start="3"&gt; &lt;li&gt;Scale down CLUSTER_NAME to zero:&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;$ oc scale machineset CLUSTER_NAME --replicas=0 -n openshift-machine-api&lt;/pre&gt; &lt;ol start="4"&gt; &lt;li&gt;Scale back up the CLUSTER_NAME to 1 again:&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;$ oc scale machineset CLUSTER_NAME --replicas=1 -n openshift-machine-api &lt;/pre&gt; &lt;p&gt;In this instance, &lt;code&gt;CLUSTER_NAME&lt;/code&gt; is the name of one of your cluster (or worker) nodes. You can repeat the command for all of your worker nodes. Run the first command (&lt;code&gt;oc get machinesets&lt;/code&gt;) to see a listing of all of your worker nodes, as shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_729787" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-05-25-at-1.11.21-PM.png"&gt;&lt;img aria-describedby="caption-attachment-729787" class="wp-image-729787 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-05-25-at-1.11.21-PM-1024x130.png" alt="A screenshot of the CLI showing a listing of worker nodes." width="640" height="81" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-05-25-at-1.11.21-PM-1024x130.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-05-25-at-1.11.21-PM-300x38.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-05-25-at-1.11.21-PM-768x98.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screen-Shot-2020-05-25-at-1.11.21-PM.png 1256w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-729787" class="wp-caption-text"&gt;Figure 2: View a listing of all of your worker nodes.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Step 2: Create a new OpenShift project namespace&lt;/h2&gt; &lt;p&gt;If you install ACM through the OpenShift OperatorHub, a new OpenShift project will be created automatically. However, I recommended creating the new OpenShift project namespace &lt;i&gt;before&lt;/i&gt; you install ACM. The images required to deploy ACM to OpenShift are hosted in remote registries, so you can still anticipate the additional authentication issue. By providing the authentication you know for sure it works, you can ensure that the image pull error will be avoided and will work successfully. Also, among other things, creating the OpenShift project first will allow you to create an image-pull secret before you install ACM.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: If you are installing ACM in a restricted environment, it is especially important to create a new OpenShift project before installing ACM. Doing so will help you avoid errors in the installation process.&lt;/p&gt; &lt;p&gt;To create a new OpenShift project in the CLI, you need to create a new namespace and then switch to the project. For this example, run the following command to create a new OpenShift namespace named open-cluster-management:&lt;/p&gt; &lt;pre&gt;$ oc new-project open-cluster-management&lt;/pre&gt; &lt;p&gt;Then, run the following command to switch to the project:&lt;/p&gt; &lt;pre&gt;$ oc project open-cluster-management&lt;/pre&gt; &lt;h2&gt;Step 3: Create an image-pull secret&lt;/h2&gt; &lt;p&gt;While the ACM Operator is capable of determining the required credentials to pull images from the Red Hat Registry, I recommend creating the image-pull secret yourself. There are two reasons:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Manually creating the image-pull secret eliminates a potential problem with authenticating the image pull.&lt;/li&gt; &lt;li&gt;If you end up working in a restricted environment, you will have to pull the ACM images from a private image registry instead of the Red Hat Registry.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;To create a new OpenShift secret in the CLI, use the following command to create a new OpenShift secret that will authenticate with the Red Hat Tech Preview Registry, where ACM is hosted:&lt;/p&gt; &lt;pre&gt;$ oc create secret docker-registry &amp;#60;strong&amp;#62;YOUR_SECRET_NAME&amp;#60;/strong&amp;#62; --docker-server=registry.access.redhat.com/rhacm1-tech-preview --docker-username=&amp;#60;strong&amp;#62;YOUR_REDHAT_USERNAME&amp;#60;/strong&amp;#62; --docker-password=&amp;#60;strong&amp;#62;YOUR_REDHAT_PASSWORD&amp;#60;/strong&amp;#62; &lt;/pre&gt; &lt;p&gt;For &lt;code&gt;YOUR_SECRET_NAME&lt;/code&gt;, provide the OpenShift secret name that you will use to pull the images from the Red Hat Registry. This name is used when you create the MultiClusterHub later. For &lt;code&gt;YOUR_REDHAT_USERNAME&lt;/code&gt; and &lt;code&gt;YOUR_REDHAT_PASSWORD&lt;/code&gt;, use the credentials for your Red Hat subscription.&lt;/p&gt; &lt;h2&gt;Step 4: Install ACM and subscribe to the ACM Operator group&lt;/h2&gt; &lt;p&gt;In this section, I will show you how to install ACM and subscribe to the ACM Operator group using both the CLI and the OpenShift web console.&lt;/p&gt; &lt;h2&gt;Install and subscribe using the CLI&lt;/h2&gt; &lt;p&gt;If you are using the CLI, you will need to manually create an ACM Operator group before you can subscribe to it. To start, create a YAML file named &lt;code&gt;acm-operator.yaml&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;apiVersion: operators.coreos.com/v1 kind: OperatorGroup metadata: name: acm-operator spec: targetNamespaces: - open-cluster-management &lt;/pre&gt; &lt;p&gt;In this case, &lt;code&gt;acm-operator&lt;/code&gt; is the name of Operator group that you want to call, and &lt;code&gt;open-cluster-management&lt;/code&gt; is the name of the OpenShift project that you created in Step 2.&lt;/p&gt; &lt;p&gt;You can now run the following command to apply the &lt;code&gt;OperatorGroup&lt;/code&gt; that you have just created:&lt;/p&gt; &lt;pre&gt;$ oc apply -f acm-operator.yaml &lt;/pre&gt; &lt;p&gt;Next, create another YAML file for an ACM subscription. I am calling the subscription file  &lt;code&gt;acm-subscription.yaml&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;apiVersion: operators.coreos.com/v1alpha1 kind: Subscription metadata: name: acm-operator-subscription spec: sourceNamespace: openshift-marketplace source: redhat-operators channel: release-1.0 installPlanApproval: Automatic name: advanced-cluster-management&lt;/pre&gt; &lt;p&gt;Run the following command to install the subscription:&lt;/p&gt; &lt;pre&gt;$ oc apply -f acm-subscription.yaml &lt;/pre&gt; &lt;h3&gt;Install ACM and subscribe using the OpenShift web console&lt;/h3&gt; &lt;p&gt;To install and subscribe to the ACM Operator group from the OpenShift web console, the first thing you need to do is open the web console and select the OperatorHub. Search for &amp;#8220;advanced cluster,&amp;#8221; and Advanced Cluster Management for Kubernetes will pop up. Select it, as shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_729887" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/2.png"&gt;&lt;img aria-describedby="caption-attachment-729887" class="wp-image-729887 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/2-1024x477.png" alt="A screenshot showing Advanced Cluster Management for Kubernetes as a search result." width="640" height="298" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/2-1024x477.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/2-300x140.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/2-768x357.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-729887" class="wp-caption-text"&gt;Figure 2: Searching for &amp;#8216;advanced cluster&amp;#8217; brings up Advanced Cluster Management for Kubernetes.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;You will see a brief description of Advanced Cluster Management for Kubernetes. Click the &lt;b&gt;Install&lt;/b&gt; button, as shown in Figure 3.&lt;/p&gt; &lt;div id="attachment_729897" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/3.png"&gt;&lt;img aria-describedby="caption-attachment-729897" class="wp-image-729897 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/3-1024x485.png" alt="A screenshot of the installation page for Advanced Cluster Management for Kubernetes." width="640" height="303" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/3-1024x485.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/3-300x142.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/3-768x364.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-729897" class="wp-caption-text"&gt;Figure 3: Install Advanced Cluster Management for Kubernetes.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Next, set up the ACM subscription. Choose the &lt;b&gt;open-cluster-management&lt;/b&gt; OpenShift namespace that you created earlier. As shown in Figure 4, ACM will try to install this namespace as the default.&lt;/p&gt; &lt;div id="attachment_729907" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/4.png"&gt;&lt;img aria-describedby="caption-attachment-729907" class="wp-image-729907 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/4-1024x482.png" alt="A screenshot of the Create Operator Subscription page." width="640" height="301" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/4-1024x482.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/4-300x141.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/4-768x361.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-729907" class="wp-caption-text"&gt;Figure 4: Create the Operator subscription with your project namespace as the default.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Once you&amp;#8217;ve selected the namespace, scroll down, and click &lt;b&gt;Subscribe&lt;/b&gt;, as shown in Figure 5.&lt;/p&gt; &lt;div id="attachment_729917" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/5.png"&gt;&lt;img aria-describedby="caption-attachment-729917" class="wp-image-729917 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/5-1024x480.png" alt="A screenshot of the Subscribe button to complete the ACM installation and subscription." width="640" height="300" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/5-1024x480.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/5-300x141.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/5-768x360.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-729917" class="wp-caption-text"&gt;Figure 5: Click Subscribe to complete the installation and subscription.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;If you are still in the web console, you will see the ACM Operator installation taking place. If everything goes well, you will see the status shown in Figure 6.&lt;/p&gt; &lt;div id="attachment_729927" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/6.png"&gt;&lt;img aria-describedby="caption-attachment-729927" class="wp-image-729927 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/6-1024x481.png" alt="A screenshot of installed Operators, including the ACM Operator." width="640" height="301" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/6-1024x481.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/6-300x141.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/6-768x361.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-729927" class="wp-caption-text"&gt;Figure 6: The success page shows your installed Operators, including the ACM Operator.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;If you click &lt;b&gt;Advanced Cluster Management for Kubernetes&lt;/b&gt; in the web console at this point, you will not initially see much of anything. You must proceed with installing the MultiClusterHub to see the running ACM application.&lt;/p&gt; &lt;h2&gt;Step 5: Create the MultiClusterHub resource&lt;/h2&gt; &lt;p&gt;Again, I will walk you through how to create the MultiClusterHub through both the command line and the web console. Adding the &lt;a target="_blank" rel="nofollow" href="https://operatorhub.io/operator/multicluster-operators-subscription"&gt;MultiClusterHub Operator&lt;/a&gt;—which is defined and managed through a Custom Resource Definition (CRD)—lets you manage the cluster type, policy, monitoring, cluster topology, more.&lt;/p&gt; &lt;h3&gt;Create the MultiClusterHub from the CLI&lt;/h3&gt; &lt;p&gt;To install the MultiClusterHub using the command line, start by creating a YAML file called &lt;code&gt;multicluster-acm.yaml&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;apiVersion: operators.open-cluster-management.io/v1beta1 kind: MultiClusterHub metadata: name: multiclusterhub namespace: open-cluster-management spec: imagePullSecret: &lt;b&gt;YOUR_SECRET_NAME&lt;/b&gt; &lt;/pre&gt; &lt;p&gt;In this case, &lt;code&gt;open-cluster-management&lt;/code&gt; is the OpenShift project name and &lt;code&gt;YOUR_SECRET_NAME&lt;/code&gt; is the OpenShift secret that contains the image-pull secret that you created in Step 3.&lt;/p&gt; &lt;p&gt;Run the following command to install the MultiClusterHub:&lt;/p&gt; &lt;pre&gt;$ oc apply -f multicluster-acm.yaml &lt;/pre&gt; &lt;p&gt;Run this command to get the application URL, which you will use to access the application:&lt;/p&gt; &lt;pre&gt;$ oc get route &lt;/pre&gt; &lt;h3&gt;Create the MultiClusterHub using the web console&lt;/h3&gt; &lt;p&gt;Now, let&amp;#8217;s follow the same steps using the web console. To start, open the ACM menu, then click the &lt;b&gt;MultiClusterHub&lt;/b&gt; tab that is shown in Figure 7.&lt;/p&gt; &lt;div id="attachment_729947" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/7.png"&gt;&lt;img aria-describedby="caption-attachment-729947" class="wp-image-729947 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/7-1024x502.png" alt="A screenshot of the ACM page with the unopened MultiClusterHub tab." width="640" height="314" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/7-1024x502.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/7-300x147.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/7-768x377.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-729947" class="wp-caption-text"&gt;Figure 7: Open the MultiClusterHub tab.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;From the &lt;strong&gt;MutiClusterHub&lt;/strong&gt; section, click &lt;b&gt;Create MultiClusterHub&lt;/b&gt;, as shown in Figure 8.&lt;/p&gt; &lt;div id="attachment_729957" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/8.png"&gt;&lt;img aria-describedby="caption-attachment-729957" class="wp-image-729957 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/8-1024x501.png" alt="A screenshot of the option to create the MultiClusterHub." width="640" height="313" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/8-1024x501.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/8-300x147.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/8-768x375.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-729957" class="wp-caption-text"&gt;Figure 8: Create the MultiClusterHub.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Next, you&amp;#8217;ll be asked to provide a value in the &lt;b&gt;imagePullSecret&lt;/b&gt; field. Enter the OpenShift secret name that you created in Step 3, then click &lt;b&gt;Create&lt;/b&gt; (as shown in Figure 9).&lt;/p&gt; &lt;div id="attachment_729967" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/9.png"&gt;&lt;img aria-describedby="caption-attachment-729967" class="wp-image-729967 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/9-1024x533.png" alt="A screenshot of the option to create the OpenShift secret name." width="640" height="333" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/9-1024x533.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/9-300x156.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/9-768x400.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-729967" class="wp-caption-text"&gt;Figure 9: Enter the OpenShift secret name, then click Create.&lt;/p&gt;&lt;/div&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: Some ACM users report that it is possible to leave the &lt;code&gt;spec&lt;/code&gt; field shown in Figure 9 empty (as &lt;code&gt;spec: {}&lt;/code&gt;) and successfully install the MutiClusterHub. I recommend providing the OpenShift secret that you will use to pull the required ACM images, with the correct credentials.&lt;/p&gt; &lt;h2&gt;Step 6: Verify the ACM installation&lt;/h2&gt; &lt;p&gt;As the final step, let&amp;#8217;s make sure that we have successfully installed ACM. First, confirm that the MultiClusterHub events log reports no issues in the web console, as shown in Figure 10.&lt;/p&gt; &lt;div id="attachment_729987" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/10.png"&gt;&lt;img aria-describedby="caption-attachment-729987" class="wp-image-729987 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/10-1024x490.png" alt="A screenshot of the MultiClusterHub events log." width="640" height="306" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/10-1024x490.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/10-300x144.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/10-768x367.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-729987" class="wp-caption-text"&gt;Figure 10: Check the MultiClusterHub events log.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Next, check the pods to ensure that they are all running successfully, as shown in Figure 11.&lt;/p&gt; &lt;div id="attachment_729997" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/11.png"&gt;&lt;img aria-describedby="caption-attachment-729997" class="wp-image-729997 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/11-1024x526.png" alt="A screenshot of the pods running." width="640" height="329" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/11-1024x526.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/11-300x154.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/11-768x394.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-729997" class="wp-caption-text"&gt;Figure 11: Confirm that the pods are all running.&lt;/p&gt;&lt;/div&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: There is a known problem with the &lt;code&gt;mcmapi-server&lt;/code&gt; that occurs due to a &lt;code&gt;cert-manager&lt;/code&gt; error. Execute &lt;code&gt;oc get helmreleases&lt;/code&gt;, and then &lt;code&gt;grep cert-manager&lt;/code&gt; to verify the version of &lt;code&gt;cert-manager&lt;/code&gt; and correct it.&lt;/p&gt; &lt;p&gt;Finally, you can visit the ACM URL (which is exposed through the application route) to confirm the successful installation, as shown in Figure 12.&lt;/p&gt; &lt;div id="attachment_730007" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/12.png"&gt;&lt;img aria-describedby="caption-attachment-730007" class="wp-image-730007 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/12-1024x565.png" alt="A screenshot of the ACM welcome page." width="640" height="353" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/12-1024x565.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/12-300x166.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/12-768x424.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-730007" class="wp-caption-text"&gt;Figure 12: The ACM welcome page confirms the successful installation.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;You can now install Advanced Cluster Management through Red Hat Openshift. Your next step is learning how to use these tools to manage multiple clusters. Next time, I will cover the ACM features and tricks that will get you there.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F23%2Finstalling-red-hat-advanced-cluster-management-acm-for-kubernetes%2F&amp;#38;linkname=Installing%20Red%20Hat%20Advanced%20Cluster%20Management%20%28ACM%29%20for%20Kubernetes" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F23%2Finstalling-red-hat-advanced-cluster-management-acm-for-kubernetes%2F&amp;#38;linkname=Installing%20Red%20Hat%20Advanced%20Cluster%20Management%20%28ACM%29%20for%20Kubernetes" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F23%2Finstalling-red-hat-advanced-cluster-management-acm-for-kubernetes%2F&amp;#38;linkname=Installing%20Red%20Hat%20Advanced%20Cluster%20Management%20%28ACM%29%20for%20Kubernetes" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F23%2Finstalling-red-hat-advanced-cluster-management-acm-for-kubernetes%2F&amp;#38;linkname=Installing%20Red%20Hat%20Advanced%20Cluster%20Management%20%28ACM%29%20for%20Kubernetes" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F23%2Finstalling-red-hat-advanced-cluster-management-acm-for-kubernetes%2F&amp;#38;linkname=Installing%20Red%20Hat%20Advanced%20Cluster%20Management%20%28ACM%29%20for%20Kubernetes" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F23%2Finstalling-red-hat-advanced-cluster-management-acm-for-kubernetes%2F&amp;#38;linkname=Installing%20Red%20Hat%20Advanced%20Cluster%20Management%20%28ACM%29%20for%20Kubernetes" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F23%2Finstalling-red-hat-advanced-cluster-management-acm-for-kubernetes%2F&amp;#38;linkname=Installing%20Red%20Hat%20Advanced%20Cluster%20Management%20%28ACM%29%20for%20Kubernetes" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F23%2Finstalling-red-hat-advanced-cluster-management-acm-for-kubernetes%2F&amp;#038;title=Installing%20Red%20Hat%20Advanced%20Cluster%20Management%20%28ACM%29%20for%20Kubernetes" data-a2a-url="https://developers.redhat.com/blog/2020/07/23/installing-red-hat-advanced-cluster-management-acm-for-kubernetes/" data-a2a-title="Installing Red Hat Advanced Cluster Management (ACM) for Kubernetes"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/07/23/installing-red-hat-advanced-cluster-management-acm-for-kubernetes/"&gt;Installing Red Hat Advanced Cluster Management (ACM) for Kubernetes&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/UOe3AZ4AIes" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Red Hat Advanced Cluster Management (ACM) for Kubernetes offers end-to-end visibility and control for managing your cluster and application lifecycle. Among other features, it ensures security and compliance for your entire Kubernetes domain across multiple data centers and public clouds. This article guides you through setting up your Red Hat OpenShift 4 environment for an [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/07/23/installing-red-hat-advanced-cluster-management-acm-for-kubernetes/"&gt;Installing Red Hat Advanced Cluster Management (ACM) for Kubernetes&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">725337</post-id><dc:creator>Bryant Son</dc:creator><dc:date>2020-07-23T07:00:43Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/07/23/installing-red-hat-advanced-cluster-management-acm-for-kubernetes/</feedburner:origLink></entry></feed>
