<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Operators and Sidecars Are the New Model for Software Delivery</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/dWSEEJpCY4s/operators-and-sidecars-are-new-model.html" /><category term="Cloud Native" scheme="searchisko:content:tags" /><category term="feed_group_name_fusesource" scheme="searchisko:content:tags" /><category term="feed_name_ofbizian" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><author><name>Bilgin Ibryam</name></author><id>searchisko:content:id:jbossorg_blog-operators_and_sidecars_are_the_new_model_for_software_delivery</id><updated>2020-07-03T21:48:30Z</updated><published>2020-07-03T21:48:00Z</published><content type="html">&lt;p&gt;Today’s developers are expected to develop resilient and scalable distributed systems. Systems that are easy to patch in the face of security concerns and easy to do low-risk incremental upgrades. Systems that benefit from software reuse and innovation of the open source model. Achieving all of this for different languages, using a variety of application frameworks with embedded libraries is not possible.&lt;/p&gt;&lt;p&gt;Recently I’ve &lt;a class="ext-link" href="https://www.infoq.com/articles/multi-runtime-microservice-architecture/" rel="external" target="_blank"&gt;blogged&lt;/a&gt; about “Multi-Runtime Microservices Architecture” where I have explored the needs of distributed systems such as lifecycle management, advanced networking, resource binding, state abstraction and how these abstractions have been changing over the years. I also&amp;nbsp;&lt;a class="ext-link" href="https://www.youtube.com/watch?v=CZPEIJFJV9k" rel="external noopener noreferrer" target="_blank"&gt;spoke&lt;/a&gt;&amp;nbsp;about&amp;nbsp;“The Evolution of Distributed Systems on Kubernetes” covering how Kubernetes Operators and the sidecar model are acting as the primary innovation mechanisms for delivering the same distributed system primitives.&lt;/p&gt;&lt;p&gt;On both occasions, the main takeaway is the prediction that the progression of software application architectures on Kubernetes moves towards the sidecar model managed by operators. Sidecars and operators could become a mainstream software distribution and consumption model and in some cases even replace software libraries and frameworks as we are used to.&lt;/p&gt;&lt;p&gt;The sidecar model allows the composition of applications written in different languages to deliver joint value, faster and without the runtime coupling. Let’s see a few concrete examples of sidecars and operators, and then we will explore how this new software composition paradigm could impact us.&lt;/p&gt;&lt;h2&gt;Out-of-Process Smarts on the Rise&lt;/h2&gt;&lt;p&gt;In Kubernetes, a sidecar is one of the &lt;a class="ext-link" href="http://k8spatterns.io/" rel="external" target="_blank"&gt;core design patterns&lt;/a&gt; achieved easily by organizing multiple containers in a single Pod. The Pod construct ensures that the containers are always placed on the same node and can cooperate by interacting over networking, file system or other IPC methods. And &lt;a class="ext-link" href="https://kubernetes.io/docs/concepts/extend-kubernetes/operator/" rel="external" target="_blank"&gt;operators&lt;/a&gt; allow the automation, management and integration of the sidecars with the rest of the platform. The sidecars represent a language-agnostic, scalable data plane offering distributed primitives to custom applications. And the operators represent their centralized management and control plane.&lt;/p&gt;&lt;p&gt;Let’s look at a few popular manifestations of the sidecar model.&lt;/p&gt;&lt;h3&gt;Envoy&lt;/h3&gt;&lt;p&gt;Service Meshes such as Istio, Consul, and others are using transparent service proxies such as &lt;a class="ext-link" href="https://www.envoyproxy.io/" rel="external" target="_blank"&gt;Envoy&lt;/a&gt; for delivering enhanced networking capabilities for distributed systems. Envoy can improve security, it enables advanced traffic management, improves resilience, adds deep monitoring and tracing features. Not only that, it understands more and more Layer 7 protocols such as Redis, MongoDB, MySQL and most recently Kafka. It also added response caching capabilities and even WebAssembly support that will enable all kinds of custom plugins. Envoy is an example of how a transparent service proxy adds advanced networking capabilities to a distributed system without including them into the runtime of the distributed application components.&lt;/p&gt;&lt;h3&gt;Skupper&lt;/h3&gt;&lt;p&gt;In addition to the typical service mesh, there are also projects, such as&lt;a class="ext-link" href="https://skupper.io/" rel="external" target="_blank"&gt; Skupper&lt;/a&gt;, that ship application networking capabilities through an external agent. Skupper solves multicluster Kubernetes communication challenges through a Layer 7 virtual network and offers advanced routing and connectivity capabilities. But rather than embedding Skupper into the business service runtime, it runs an instance per Kubernetes namespace which acts as a shared sidecar.&lt;/p&gt;&lt;h3&gt;Cloudstate&lt;/h3&gt;&lt;p&gt;&lt;a class="ext-link" href="https://cloudstate.io/" rel="external" target="_blank"&gt;Cloudstate&lt;/a&gt; is another example of the sidecar model, but this time for providing stateful abstractions for the serverless development model. It offers stateful primitives over GRPC for EventSourcing, CQRS, Pub/Sub, Key/Value stores and other use cases. Again, it an example of sidecars and operators in action but this time for the serverless programming model.&lt;/p&gt;&lt;h3&gt;Dapr&lt;/h3&gt;&lt;p&gt;&lt;a class="ext-link" href="https://dapr.io/" rel="external" target="_blank"&gt;Dapr&lt;/a&gt; is a relatively young project started by Microsoft, and it is also using the sidecar model for providing developer-focused distributed system primitives. Dapr offers abstractions for state management, service invocation and fault handling, resource bindings, pub/sub, distributed tracing and others. Even though there is some overlap in the capabilities provided by Dapr and Service Mesh, both are very different in nature. Envoy with Istio is injected and runs transparently from the service and represents an operational tool. Dapr, on the other hand, has to be called explicitly from the application runtime over HTTP or gRPC and it is an explicit sidecar targeted for developers. It is a library for distributed primitives that is distributed and consumed as a sidecar, a model that may become very attractive for developers consuming distributed capabilities.&lt;/p&gt;&lt;h3&gt;Camel K&lt;/h3&gt;&lt;p&gt;Apache Camel is a mature integration library that rediscovers itself on Kubernetes. Its subproject &lt;a class="ext-link" href="https://camel.apache.org/camel-k/latest/index.html" rel="external" target="_blank"&gt;Camel K&lt;/a&gt; uses heavily the operator model to improve the developer experience and integrate deeply with the Kubernetes platform. While Camel K does not rely on a sidecar, through its CLI and operator it is able to reuse the same application container and execute any local code modification in a remote Kubernetes cluster in less than a second. This is another example of developer-targeted software consumption through the operator model.&lt;/p&gt;&lt;h2&gt;More to Come&lt;/h2&gt;&lt;p&gt;And these are only some of the pioneer projects exploring various approaches through sidecars and operators. There is more work being done to reduce the networking overhead introduced by container-based distributed architectures such as the data plane development kit (&lt;a class="ext-link" href="https://www.dpdk.org/" rel="external" target="_blank"&gt;DPDK&lt;/a&gt;), which is a userspace application that bypasses the layers of the Linux kernel networking stack and access directly to the network hardware. There is work in the Kubernetes project to create &lt;a class="ext-link" href="https://github.com/kubernetes/enhancements/issues/753" rel="external" target="_blank"&gt;sidecar&lt;/a&gt; containers with more granular lifecycle guarantees. There are new Java projects based on GraalVM implementation such as &lt;a class="ext-link" href="https://quarkus.io/" rel="external" target="_blank"&gt;Quarkus&lt;/a&gt; that reduce the resource consumption and application startup time which makes more workloads attractive for sidecars. All of these innovations will make the side-car model more attractive and enable the creation of even more such projects.&lt;/p&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-ajKfxQnN7Eg/Xs1961D9WzI/AAAAAAAAORs/_hu-KhmUN1wsQ8PfeIaNKaHNVyi8-3iYACK4BGAsYHg/d/multiruntine1.png" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img alt="Sidecars Providing Distributed Systems Primitives" border="0" data-original-height="944" data-original-width="1670" height="226" src="https://1.bp.blogspot.com/-ajKfxQnN7Eg/Xs1961D9WzI/AAAAAAAAORs/_hu-KhmUN1wsQ8PfeIaNKaHNVyi8-3iYACK4BGAsYHg/w400-h226/multiruntine1.png" title="Sidecars Providing Distributed Systems Primitives" width="400" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class="wp-caption aligncenter" id="attachment_11291779" style="width: 1680px;"&gt;Sidecars providing distributed systems primitives&lt;/div&gt;&lt;p&gt;I’d not be surprised to see projects coming up around more specific use cases such as stateful orchestration of long-running processes such as Business Process Model and Notation (BPMN) engines in sidecars. Job schedulers in sidecars. Stateless integration engines i.e. Enterprise Integration Patterns implementations in sidecars. Data abstractions and data &lt;a class="ext-link" href="https://github.com/teiid/teiid-operator" rel="external" target="_blank"&gt;federation&lt;/a&gt; engines in sidecars. OAuth2/&lt;a class="ext-link" href="https://github.com/louketo/louketo-proxy" rel="external" target="_blank"&gt;OpenID&lt;/a&gt; proxy in sidecars. Scalable database connection pools for serverless workloads in sidecars. Application networks as sidecars, etc. But why would software vendors and developers switch to this model? Let’s see a few of the benefits it provides.&lt;/p&gt;&lt;h2&gt;Runtimes with Control Planes over Libraries&lt;/h2&gt;&lt;p&gt;If you are a software vendor today, probably you have already considered offering your software to potential users as an API or a SaaS-based solution. This is the fastest software consumption model and a no-brainer to offer, when possible. Depending on the nature of the software you may be also distributing your software as a library or a runtime framework. Maybe it is time to consider if it can be offered as a container with an operator too. This mechanism of distributing software and the resulting architecture has some very unique benefits that the library mechanism cannot offer.&lt;/p&gt;&lt;h3&gt;Supporting Polyglot Consumers&lt;/h3&gt;&lt;p&gt;By offering libraries to be consumable through open protocols and standards, you open them up for all programming languages. A library that runs as a sidecar and consumable over HTTP, using a text format such as JSON does not require any specific client runtime library. Even when gRPC and Protobuf are used for low-latency and high-performance interactions, it is still easier to generate such clients than including third party custom libraries in the application runtime and implement certain interfaces.&lt;/p&gt;&lt;h3&gt;Application Architecture Agnostic&lt;/h3&gt;&lt;p&gt;The explicit sidecar architecture (as opposed to the transparent one) is a way of software capability consumption as a separate runtime behind a developer-focused API. It is an orthogonal feature that can be added to any application whether that is monolithic, microservices, functions-based, actor-based or anything in between. It can sit next to a monolith in a less dynamic environment, or next to every microservice in a dynamic cloud-based environment. It is trivial to create sidecars on Kubernetes, and doable on many other software orchestration platforms too.&lt;/p&gt;&lt;h3&gt;Tolerant to Release Impedance Mismatch&lt;/h3&gt;&lt;p&gt;Business logic is always custom and developed in house. Distributed system primitives are well-known commodity features, and consumed off-the-shelf as either platform features or runtime libraries. You might be consuming software for state abstractions, messaging clients, networking resiliency and monitoring libraries, etc. from third-party open source projects or companies. And these third party entities have their release cycles, critical fixes, CVE patches that impact your software release cycles too. When third party libraries are consumed as a separate runtime (sidecar), the upgrade process is simpler as it is behind an API and it is not coupled with your application runtime. The release impedance mismatch between your team and the consumed 3rd party libraries vendors becomes easier to manage.&lt;/p&gt;&lt;h3&gt;Control Plane Included Mentality&lt;/h3&gt;&lt;p&gt;When a feature is consumed as a library, it is included in your application runtime and it becomes your responsibility to understand how it works, how to configure, monitor, tune and upgrade. That is because the language runtimes (such as the JVM) and the runtime frameworks (such as Spring Boot or application servers) dictate how a third-party library can be included, configured, monitored and upgraded.&lt;br /&gt;When a software capability is consumed as a separate runtime (such as a sidecar or standalone container) it comes with its own control plane in the form of a &lt;a href="https://thenewstack.io/automating-kubernetes-cluster-operations-operators/" target="_blank"&gt;Kubernetes operator&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;That has a lot of benefits as the control plane understands the software it manages (the operand) and comes with all the necessary management intelligence that otherwise would be distributed as documentation and best practices. What’s more, operators also integrate deeply with Kubernetes and offer a unique blend of platform integration and operand management intelligence out-of-the-box. Operators are created by the same developers who are creating the operands, they understand the internals of the containerized features and know how to operate the best. Operators are executables SREs in containers, and the &lt;a class="ext-link" href="http://operatorhub.io/" rel="external" target="_blank"&gt;number&lt;/a&gt; of operators and their capabilities are increasing steadily with more operators and &lt;a class="ext-link" href="https://marketplace.redhat.com" rel="external" target="_blank"&gt;marketplaces&lt;/a&gt; coming up.&lt;/p&gt;&lt;h2&gt;Software Distribution and Consumption in the Future&lt;/h2&gt;&lt;h3&gt;Software Distributed as Sidecars with Control Planes&lt;/h3&gt;&lt;p&gt;Let’s say you are a software provider of a Java framework. You may distribute it as an archive or a Maven artifact. Maybe you have gone a step further and you distribute a container image. In either case, in today’s cloud-native world, that is not good enough. The users still have to know how to patch and upgrade a running application with zero downtime. They have to know what to backup and restore its state. They have to know how to configure their monitoring and alerting thresholds. They have to know how to detect and recover from complex failures. They have to know how to tune an application based on the current load profile.&lt;/p&gt;&lt;p&gt;In all of these and similar scenarios, intelligent control planes in the form of Kubernetes operators are the answer. An operator encapsulates platform and domain knowledge of an application in a declaratively configured component to manage the workload.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Sidecars and operators could become a mainstream software distribution and consumption model and in some cases even replace software libraries and frameworks as we are used to.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Let’s assume that you are providing a software library that is included in the consumer applications as a dependency. Maybe it is the client-side library of the backend framework described above. If it is in Java, for example, you may have certified it to run it on a JEE server, provided Spring Boot Starters, Builders, Factories, and other implementations that are all hidden behind a clean Java interface. You may have even backported it to .Net too.&lt;/p&gt;&lt;p&gt;With Kubernetes operators and sidecars all of that is hidden from the consumer. The factory classes are replaced by the operator, and the only configuration interface is a YAML file for the custom resource. The operator is then responsible for configuring the software and the platform so that users can consume it as an explicit sidecar, or a transparent proxy. In all cases, your application is available for consumption over remote API and fully integrated with the platform features and even other dependent operators. Let’s see how that happens.&lt;/p&gt;&lt;h3&gt;Software Consumed over Remote APIs Rather than Embedded Libraries&lt;/h3&gt;&lt;p&gt;One way to think about sidecars is similar to the composition over inheritance &lt;a class="ext-link" href="https://en.wikipedia.org/wiki/Composition_over_inheritance" rel="external" target="_blank"&gt;principle&lt;/a&gt; in OOP, but in a polyglot context. It is a different way of organizing the application responsibilities by composing capabilities from different processes rather than including them into a single application runtime as dependencies. When you consume software as a library, you instantiate a class, call its methods by passing some value objects. When you consume it as an out-of-process capability, you access a local process. In this model, methods are replaced with APIs, in-process methods invocation with HTTP or gRPC invocations, and value objects with something like CloudEvents. This is a change from application servers to Kubernetes as the distributed runtime. A change from language-specific interfaces, to remote APIs. From in-memory calls to HTTP, from value objects to CloudEvents, etc.&lt;/p&gt;&lt;p&gt;This requires software providers to distribute containers and controllers to operate them. To create IDEs that are capable of building and debugging multiple runtime services locally. CLIs for quickly deploying code changes into Kubernetes and configuring the control planes. Compilers that can decide what to compile in a custom application runtime, what capabilities to consume from a sidecar and what from the orchestration platform.&lt;/p&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-6gPVOnbLm4A/Xs1-DJ6hg0I/AAAAAAAAOR4/8AhgLVogoIsQBnOQPfXG-nc3MN8KHwgsACK4BGAsYHg/d/softwareconsumers.png" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img alt="Software consumers and providers ecosystem" border="0" data-original-height="1076" data-original-width="2206" height="195" src="https://1.bp.blogspot.com/-6gPVOnbLm4A/Xs1-DJ6hg0I/AAAAAAAAOR4/8AhgLVogoIsQBnOQPfXG-nc3MN8KHwgsACK4BGAsYHg/w400-h195/softwareconsumers.png" title="Software consumers and providers ecosystem" width="400" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class="wp-caption aligncenter" id="attachment_11291801" style="width: 2216px;"&gt;Software consumers and providers ecosystem&lt;/div&gt;&lt;p&gt;In the longer term, this will lead to the consolidation of standardized APIs that are used for the consumption of common primitives in sidecars. Rather than language-specific standards and APIs we will have polyglot APIs. For example, rather than Java Database Connectivity (JDBC) API, caching API for Java (JCache), Java Persistence API (JPA), we will have polyglot APIs over HTTP using something like CloudEvents. Sidecar centric APIs for messaging, caching, reliable networking, cron jobs and timer scheduling, resource bindings (connectors to other APIs, protocols), idempotency, SAGAs, etc. And all of these capabilities will be delivered with the management layer included in the form of operators and even wrapped with self-service UIs. The operators are key enablers here as they will make this even more distributed architecture easy to manage and self-operate on Kubernetes. The management interface of the operator is defined by the CustomResourceDefinition and represents another public-facing API that remains application-specific.&lt;/p&gt;&lt;p&gt;This is a big shift in mentality to a different way of distributing and consuming software, driven by the speed of delivery and operability. It is a shift from a single runtime to multi runtime application architectures. It is a shift similar to what the hardware industry had to go through from single-core to multicore platforms when Moore’s law ended. It is a shift that is slowly happening by building all the elements of the puzzle: we have uniformly adopted and standardized containers, we have a de facto standard for orchestration through Kubernetes, possibly improved sidecars coming soon, rapid operators adoption, CloudEvents as a widely agreed standard, light runtimes such as Quarkus, etc. With the foundation in place, applications, productivity tools, practices, standardized APIs, and ecosystem will come too.&lt;/p&gt;&lt;p&gt;&lt;i&gt;This post was originally published at ​The New Stack &lt;a href="https://thenewstack.io/operators-and-sidecars-are-the-new-model-for-software-delivery/" target="_blank"&gt;here&lt;/a&gt;.&lt;/i&gt;&lt;br /&gt;&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/dWSEEJpCY4s" height="1" width="1" alt=""/&gt;</content><summary>Today’s developers are expected to develop resilient and scalable distributed systems. Systems that are easy to patch in the face of security concerns and easy to do low-risk incremental upgrades. Systems that benefit from software reuse and innovation of the open source model. Achieving all of this for different languages, using a variety of application frameworks with embedded libraries is not p...</summary><dc:creator>Bilgin Ibryam</dc:creator><dc:date>2020-07-03T21:48:00Z</dc:date><feedburner:origLink>http://www.ofbizian.com/2020/07/operators-and-sidecars-are-new-model.html</feedburner:origLink></entry><entry><title>Infinispan 11.0.1.Final</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/iUX525X1AIg/" /><category term="feed_group_name_infinispan" scheme="searchisko:content:tags" /><category term="feed_name_infinispan" scheme="searchisko:content:tags" /><category term="release" scheme="searchisko:content:tags" /><author><name>Tristan Tarrant</name></author><id>searchisko:content:id:jbossorg_blog-infinispan_11_0_1_final</id><updated>2020-07-03T15:20:56Z</updated><published>2020-07-03T12:00:00Z</published><content type="html">&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Dear Infinispan community,&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;we hope you’ve been enjoying all the new goodies included in our latest major release, Infinispan 11. To show that we care about you, we have a brand new micro release for you which addresses a number of issues.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;In particular, if you are using HTTP/2 with TLS/SSL, JCache with persistence, Spring Boot or RocksDB, we have fixes for you.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Additionally, the Infinispan Archetypes have been resurrected and are now being maintained as part of the main repository to ensure they won’t fall out of sync anymore. Read more about how to &lt;a href="//infinispan.org/docs/stable/titles/getting_started/getting_started.html#mvn_archetypes"&gt;get started with a Maven archetype&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The following list shows what we have fixed:&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_component_upgrade"&gt;&lt;a class="anchor" href="#_component_upgrade" /&gt;Component Upgrade&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="literalblock"&gt; &lt;div class="content"&gt; &lt;pre&gt;https://issues.redhat.com/browse/ISPN-11843[ISPN-11843] - Upgrade SB starter to 2.3 https://issues.redhat.com/browse/ISPN-12009[ISPN-12009] - Upgrade Hibernate to latest micro https://issues.redhat.com/browse/ISPN-12013[ISPN-12013] - Upgrade H2 database engine to 1.4.200 https://issues.redhat.com/browse/ISPN-12014[ISPN-12014] - Upgrade mojo-executor&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_enhancement"&gt;&lt;a class="anchor" href="#_enhancement" /&gt;Enhancement&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="literalblock"&gt; &lt;div class="content"&gt; &lt;pre&gt;https://issues.redhat.com/browse/ISPN-11151[ISPN-11151] - Migrating some remote tests from jdg-functional-tests to upstream https://issues.redhat.com/browse/ISPN-11549[ISPN-11549] - Move Infinispan SB starter simple tutorials to simple tutorials repository https://issues.redhat.com/browse/ISPN-11782[ISPN-11782] - Docs: Cross-Site monitoring https://issues.redhat.com/browse/ISPN-11828[ISPN-11828] - Docs: Add stable docs to infinispan.org/documentation https://issues.redhat.com/browse/ISPN-11913[ISPN-11913] - Docs: Add search and improve index pages https://issues.redhat.com/browse/ISPN-11996[ISPN-11996] - Allow customize memory and memory swap for Testcontainers images https://issues.redhat.com/browse/ISPN-12001[ISPN-12001] - Add jboss-parent to upstream projects https://issues.redhat.com/browse/ISPN-12006[ISPN-12006] - Test upload schema with CLI https://issues.redhat.com/browse/ISPN-12007[ISPN-12007] - Elytron 1.12.1.Final https://issues.redhat.com/browse/ISPN-12010[ISPN-12010] - Remove Apache Commons Codec https://issues.redhat.com/browse/ISPN-12012[ISPN-12012] - Force the same Guava version in all transitive dependencies https://issues.redhat.com/browse/ISPN-12021[ISPN-12021] - Docs: Creating Caches Remotely https://issues.redhat.com/browse/ISPN-12039[ISPN-12039] - Docs: Hot Rod Per-Cache Simple Tutorial https://issues.redhat.com/browse/ISPN-12045[ISPN-12045] - Clarify jboss-marshalling deprecation message https://issues.redhat.com/browse/ISPN-12047[ISPN-12047] - Merge Async and Sync Cross-Site attributes https://issues.redhat.com/browse/ISPN-12053[ISPN-12053] - Remove jetty-client from the REST testsuite https://issues.redhat.com/browse/ISPN-12059[ISPN-12059] - CliIT allow external module use https://issues.redhat.com/browse/ISPN-12065[ISPN-12065] - Add the anchored-keys module to the server https://issues.redhat.com/browse/ISPN-12068[ISPN-12068] - HTTP/2 pipeline missing chunked handler&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_bug"&gt;&lt;a class="anchor" href="#_bug" /&gt;Bug&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="literalblock"&gt; &lt;div class="content"&gt; &lt;pre&gt;https://issues.redhat.com/browse/ISPN-11998[ISPN-11998] - Eviction new and legacy attributes should stay in sync https://issues.redhat.com/browse/ISPN-12017[ISPN-12017] - Explicitly disable the java8-test execution defined in the jboss-parent POM https://issues.redhat.com/browse/ISPN-12018[ISPN-12018] - Fix JpaStoreCompatibilityTest failure https://issues.redhat.com/browse/ISPN-12019[ISPN-12019] - Always attempt to initialize openssl https://issues.redhat.com/browse/ISPN-12026[ISPN-12026] - Fetch the correct IP:port when NodePort is used https://issues.redhat.com/browse/ISPN-12027[ISPN-12027] - RemoteCacheContainer missing getCache overrides https://issues.redhat.com/browse/ISPN-12030[ISPN-12030] - BlockHound is not active on JDK 13/14 https://issues.redhat.com/browse/ISPN-12032[ISPN-12032] - JCache cache loader should not require marshalling https://issues.redhat.com/browse/ISPN-12038[ISPN-12038] - RocksDB compression options incomplete and incorrectly applied https://issues.redhat.com/browse/ISPN-12043[ISPN-12043] - Shared stores should not have (add|remove)Segments methods invoked https://issues.redhat.com/browse/ISPN-12046[ISPN-12046] - Out of the box server testing is broken https://issues.redhat.com/browse/ISPN-12056[ISPN-12056] - Some tests are failing on windows when they try to delete the SingleFileStore https://issues.redhat.com/browse/ISPN-12058[ISPN-12058] - wildfly/feature-pack module doesn't build with profile java8-test https://issues.redhat.com/browse/ISPN-12060[ISPN-12060] - WildFly modules integration tests do not work on WildFly 19 https://issues.redhat.com/browse/ISPN-12064[ISPN-12064] - REST server returns 403 (forbidden) for same origin request https://issues.redhat.com/browse/ISPN-12067[ISPN-12067] - HTTP/2 framing error for invalid requests https://issues.redhat.com/browse/ISPN-12069[ISPN-12069] - Unable to override the marshaller in SB starter&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_sub_task"&gt;&lt;a class="anchor" href="#_sub_task" /&gt;Sub-task&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="literalblock"&gt; &lt;div class="content"&gt; &lt;pre&gt;https://issues.redhat.com/browse/ISPN-11953[ISPN-11953] - Create client archetype https://issues.redhat.com/browse/ISPN-11954[ISPN-11954] - Move archetypes to Infinispan repository https://issues.redhat.com/browse/ISPN-11955[ISPN-11955] - Remove testcase-archetype https://issues.redhat.com/browse/ISPN-11956[ISPN-11956] - Rework store-archetype to use the new NonBlockingStore SPI https://issues.redhat.com/browse/ISPN-11957[ISPN-11957] - Upgrade embedded archetype to 11.0 https://issues.redhat.com/browse/ISPN-11958[ISPN-11958] - Document Archetypes&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_get_it_use_it_ask_us"&gt;&lt;a class="anchor" href="#_get_it_use_it_ask_us" /&gt;Get it, Use it, Ask us!&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Please &lt;a href="https://infinispan.org/download/"&gt;download&lt;/a&gt;, &lt;a href="https://issues.jboss.org/projects/ISPN"&gt;report bugs&lt;/a&gt;, &lt;a href="https://infinispan.zulipchat.com/"&gt;chat with us&lt;/a&gt;, ask questions on &lt;a href="https://stackoverflow.com/questions/tagged/?tagnames=infinispan&amp;amp;sort=newest"&gt;StackOverflow&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/iUX525X1AIg" height="1" width="1" alt=""/&gt;</content><summary>Dear Infinispan community, we hope you’ve been enjoying all the new goodies included in our latest major release, Infinispan 11. To show that we care about you, we have a brand new micro release for you which addresses a number of issues. In particular, if you are using HTTP/2 with TLS/SSL, JCache with persistence, Spring Boot or RocksDB, we have fixes for you. Additionally, the Infinispan Archety...</summary><dc:creator>Tristan Tarrant</dc:creator><dc:date>2020-07-03T12:00:00Z</dc:date><feedburner:origLink>http://infinispan.org/blog/2020/07/03/infinispan-11/</feedburner:origLink></entry><entry><title>Automate workshop setup with Ansible playbooks and CodeReady Workspaces</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/7pCq_zQaU9g/" /><category term="ansible" scheme="searchisko:content:tags" /><category term="Ansible playbook" scheme="searchisko:content:tags" /><category term="CodeReady Workspaces" scheme="searchisko:content:tags" /><category term="Developer Tools" scheme="searchisko:content:tags" /><category term="devops" scheme="searchisko:content:tags" /><category term="Eclipse Che" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="keycloak" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="quarkus" scheme="searchisko:content:tags" /><author><name>James Falkner</name></author><id>searchisko:content:id:jbossorg_blog-automate_workshop_setup_with_ansible_playbooks_and_codeready_workspaces</id><updated>2020-07-03T07:00:39Z</updated><published>2020-07-03T07:00:39Z</published><content type="html">&lt;p&gt;At Red Hat, we do many in-person and virtual workshops for customers, partners, and other open source developers. In most cases, the workshops are of the &amp;#8220;bring your own device&amp;#8221; variety, so we face a range of hardware and software setups and corporate endpoint-protection schemes, as well as different levels of system knowledge.&lt;/p&gt; &lt;p&gt;In the past few years, we&amp;#8217;ve made heavy use of &lt;a href="https://developers.redhat.com/products/codeready-workspaces/overview"&gt;Red Hat CodeReady Workspaces&lt;/a&gt; (CRW). Based on &lt;a target="_blank" rel="nofollow" href="https://www.eclipse.org/che/"&gt;Eclipse Che&lt;/a&gt;, CodeReady Workspaces is an in-browser IDE that is familiar to most developers and requires no pre-installation or knowledge of system internals. You only need a browser and your brain to get hands-on with this tech.&lt;/p&gt; &lt;p&gt;We&amp;#8217;ve also built &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible/latest/user_guide/playbooks.html"&gt;a set of playbooks&lt;/a&gt; for &lt;a href="https://developers.redhat.com/courses/ansible/"&gt;Red Hat Ansible&lt;/a&gt; to automate our &lt;a target="_blank" rel="nofollow" href="https://github.com/RedHat-Middleware-Workshops/quarkus-workshop"&gt;Quarkus workshop&lt;/a&gt;. While they are useful, the playbooks are especially helpful for automating at-scale deployments of CodeReady Workspaces for &lt;a target="_blank" rel="nofollow" href="https://quarkus.io"&gt;Quarkus&lt;/a&gt; development on &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt;. In this article, I introduce our playbooks and show you how to use them for your own automation efforts.&lt;/p&gt; &lt;h2&gt;Automating at scale: An overview&lt;/h2&gt; &lt;p&gt;While we use CodeReady Workspaces and the Ansible playbooks introduced in this article to automate our Quarkus workshop, many companies use CodeReady Workspaces to automate the onboarding of new developers at scale. In that case, using CodeReady Workspaces also helps to protect corporate intellectual property (that is, source code) and minimize the &amp;#8220;works on my machine&amp;#8221; excuse for bugs.&lt;/p&gt; &lt;p&gt;Regardless of whether you are running a workshop or an onboarding process, making the experience as smooth as possible requires considerable setup. For a workshop, you need to deploy &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt;, scale it to meet the demands of the number of users expected, and install and configure CodeReady Workspaces for every user. For the best experience, you should also &amp;#8220;pre-warm&amp;#8221; each workspace so that it is already running by the time you are done with your intro slides. You will also need to install any &lt;a href="https://developers.redhat.com/topics/kubernetes/operators/"&gt;Operators&lt;/a&gt; that you will use as part of the workshop.&lt;/p&gt; &lt;p&gt;In the next sections, I&amp;#8217;ll go through each of these steps and the Ansible playbooks that we&amp;#8217;ve built to automate them. Most of the setup can be applied to creating custom stacks that follow both company policy and IT policy, and also meet developers&amp;#8217; needs.&lt;/p&gt; &lt;h2&gt;Installing OpenShift&lt;/h2&gt; &lt;p&gt;OpenShift is used for hybrid &lt;em&gt;cloud&lt;/em&gt; infrastructure, so for at-scale deployments, you aren&amp;#8217;t &amp;#8220;installing&amp;#8221; it in the classic sense of downloading a zip file, unzipping it, and running it on your desktop. You can do that type of install with &lt;a href="https://developers.redhat.com/products/codeready-containers/overview"&gt;CodeReady Containers&lt;/a&gt;, but running locally is just not an option when you are supporting tens or hundreds of developers in a workshop.&lt;/p&gt; &lt;p&gt;You can &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.4/html/installing/index"&gt;easily provision&lt;/a&gt; OpenShift on several different public and private clouds. While &lt;a href="https://developers.redhat.com/courses/openshift/"&gt;deploying OpenShift&lt;/a&gt; is out of scope for this article, we found it useful to deploy an extra OpenShift worker node for every five students, where each node has 64&lt;span style="font-weight: 400;"&gt;GiB&lt;/span&gt; of memory. That setup supports a positive workshop experience for every student.&lt;/p&gt; &lt;p&gt;For the Quarkus Workshop, we have students doing native Quarkus builds, which require extra memory. Each student also deploys their own Kafka clusters and a few other items. So, we just run through the workshop once, leave everything running, and then add everything up to determine the amount of memory needed per user. Keep in mind that for CodeReady Workspaces, we use the &amp;#8220;per-workspace&amp;#8221; persistent volume claims (PVC) strategy, where each workspace (and therefore each user) gets its own storage. If you choose to follow that strategy, you will need to ensure that you have enough storage space. The more CPU you can afford, the better.&lt;/p&gt; &lt;p&gt;Once you have OpenShift installed, you will need to create users. You can use basic Linux shell scripting and the &lt;code&gt;oc&lt;/code&gt; CLI to override the default OpenShift authentication mechanism and supply an &lt;code&gt;htpasswd&lt;/code&gt; file containing your users (including an admin user). You will also need the &lt;a target="_blank" rel="nofollow" href="https://serverfault.com/questions/259505/how-can-i-install-the-htpasswd-utility-in-red-hat-scientific-linux"&gt;&lt;code&gt;htpasswd&lt;/code&gt; utility&lt;/a&gt; and the &lt;a target="_blank" rel="nofollow" href="https://github.com/mikefarah/yq"&gt;&lt;code&gt;yq&lt;/code&gt; utility&lt;/a&gt; (version 3 or higher) for this Bash script:&lt;/p&gt; &lt;pre&gt;#!/bin/bash NUMUSERS=20 TMPHTPASS=$(mktemp) for i in {1..$NUMUSERS} ; do htpasswd -b ${TMPHTPASS} "user$i" 'somepassword' done htpasswd -b ${TMPHTPASS} admin 'adminpassword' $ oc -n openshift-config delete secret workshop-user-secret $ oc -n openshift-config create secret generic workshop-user-secret --from-file=htpasswd=${TMPHTPASS} $ oc -n openshift-config get oauth cluster -o yaml | \ yq d - spec.identityProviders | \ yq w - -s htpass-template.yaml | \ oc apply -f - sleep 20 # don't shoot the messenger, Operators are "eventually consistent" $ oc adm policy add-cluster-role-to-user cluster-admin admin &lt;/pre&gt; &lt;p&gt;The &lt;code&gt;htpass-template.yaml&lt;/code&gt; template used with &lt;code&gt;yq&lt;/code&gt; (version 3) looks like:&lt;/p&gt; &lt;pre&gt;spec.identityProviders[+]: name: htpassidp type: HTPasswd mappingMethod: claim htpasswd: fileData: name: workshop-user-secret &lt;/pre&gt; &lt;p&gt;Running the script with this template merges a new identity provider into the OpenShift auth flow so that users can log in. You could also use Ansible to set up this authorization process, but I haven&amp;#8217;t yet found the time to convert it.&lt;/p&gt; &lt;h2&gt;Deploying CodeReady Workspaces&lt;/h2&gt; &lt;p&gt;We use the &lt;a target="_blank" rel="nofollow" href="https://github.com/redhat-developer/codeready-workspaces-operator"&gt;CodeReady Workspaces Operator&lt;/a&gt; for this installation. To automate the installation, we use a bit of Ansible in an Ansible playbook. If the namespace does not already exist, we use the &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible/latest/modules/k8s_module.html"&gt;k8s module&lt;/a&gt; to create one, along with the OperatorGroup and Subscription (&lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible/latest/reference_appendices/glossary.html#term-idempotency"&gt;idempotency&lt;/a&gt; and all):&lt;/p&gt; &lt;pre&gt;# create codeready namespace - name: create codeready namespace k8s: state: present kind: Project api_version: project.openshift.io/v1 definition: metadata: name: "codeready" annotations: openshift.io/description: "" openshift.io/display-name: "CodeReady Project" # deploy codeready operator - name: Create operator subscription for CodeReady k8s: state: present merge_type: - strategic-merge - merge definition: "{{ lookup('file', item ) | from_yaml }}" loop: - ./files/codeready_operatorgroup.yaml - ./files/codeready_subscription.yaml # wait for CRD to be a thing - name: Wait for CodeReady CRD to be ready k8s_facts: api_version: apiextensions.k8s.io/v1beta1 kind: CustomResourceDefinition name: checlusters.org.eclipse.che register: r_codeready_crd retries: 200 delay: 10 until: r_codeready_crd.resources | list | length == 1 # deploy codeready CR - name: Create CR for CodeReady k8s: state: present merge_type: - strategic-merge - merge definition: "{{ lookup('file', item ) | from_yaml }}" loop: - ./files/codeready_cr.yaml # wait for CodeReady to be up - name: wait for CRW to be running uri: url: https://codeready-codeready.{{ route_subdomain }}/dashboard/ validate_certs: false register: result until: result.status == 200 retries: "120" delay: "15" &lt;/pre&gt; &lt;p&gt;The bits of code that are waiting on the custom resource definition (CRD) are important: If you try to create a custom resource (CR) based on a CRD before the CRD is known to the system, it will fail. Furthermore, it takes non-zero time to gain that knowledge once the Operator is installed.&lt;/p&gt; &lt;p&gt;At the end, we also use the &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible/latest/modules/uri_module.html"&gt;uri module&lt;/a&gt; to wait for CodeReady Workspaces itself, as we do some additional configuration next.&lt;/p&gt; &lt;h3&gt;OperatorGroup&lt;/h3&gt; &lt;p&gt;The OperatorGroup is defined in &lt;code&gt;codeready_operatorgroup.yaml&lt;/code&gt;. It is pretty simple, but it&amp;#8217;s required for Operators to be able to, well, operate:&lt;/p&gt; &lt;pre&gt;apiVersion: operators.coreos.com/v1 kind: OperatorGroup metadata: generateName: codeready- annotations: olm.providedAPIs: CheCluster.v1.org.eclipse.che name: codeready-operator-group namespace: codeready spec: targetNamespaces: - codeready &lt;/pre&gt; &lt;h3&gt;Subscription&lt;/h3&gt; &lt;p&gt;The Subscription in &lt;code&gt;codeready_subscription.yaml&lt;/code&gt; is also basic:&lt;/p&gt; &lt;pre&gt;apiVersion: operators.coreos.com/v1alpha1 kind: Subscription metadata: name: codeready-workspaces namespace: codeready spec: channel: latest installPlanApproval: Automatic name: codeready-workspaces source: redhat-operators sourceNamespace: openshift-marketplace &lt;/pre&gt; &lt;h3&gt;CheCluster object&lt;/h3&gt; &lt;p&gt;Finally, once the Operator registers its CRDs in Kube, we can create the &lt;code&gt;CheCluster&lt;/code&gt; object in &lt;code&gt;codeready_cr.yaml&lt;/code&gt;. Creating the &lt;code&gt;CheCluster&lt;/code&gt; kicks off the install:&lt;/p&gt; &lt;pre&gt;apiVersion: org.eclipse.che/v1 kind: CheCluster metadata: name: codeready-workspaces namespace: codeready spec: server: cheImageTag: '' cheFlavor: codeready devfileRegistryImage: '' pluginRegistryImage: '' tlsSupport: true selfSignedCert: false serverMemoryRequest: '2Gi' serverMemoryLimit: '6Gi' customCheProperties: CHE_LIMITS_WORKSPACE_IDLE_TIMEOUT: "0" database: externalDb: false chePostgresHostName: '' chePostgresPort: '' chePostgresUser: '' chePostgresPassword: '' chePostgresDb: '' auth: openShiftoAuth: false identityProviderImage: '' externalIdentityProvider: false identityProviderURL: '' identityProviderRealm: '' identityProviderClientId: '' storage: pvcStrategy: per-workspace pvcClaimSize: 1Gi preCreateSubPaths: true &lt;/pre&gt; &lt;p&gt;Note the memory limits, which are tuned for the &lt;a href="https://developers.redhat.com/topics/containers/"&gt;containers&lt;/a&gt; in our custom CodeReady Workspaces stack. We also set the &lt;code&gt;CHE_LIMITS_WORKSPACE_IDLE_TIMEOUT&lt;/code&gt; here. It is rather annoying to walk away for a short time and find that your lab has timed out and needs a refresh (or requires you to log in again) when you return. Of course, neither of these settings should be used in production.&lt;/p&gt; &lt;h2&gt;Tuning Keycloak&lt;/h2&gt; &lt;p&gt;It is &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_codeready_workspaces/2.1/html/administration_guide/securing-codeready-workspaces_crw#authenticating-to-the-codeready-workspaces-server_authenticating-users"&gt;not possible&lt;/a&gt; to use OpenShift&amp;#8217;s built-in authentication mechanism to pre-create and pre-start workspaces. Doing that would require each user to log in to OpenShift and link the user&amp;#8217;s account details to &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/products/red-hat-single-sign-on"&gt;Red Hat Single Sign-O&lt;/a&gt;. (That, by the way, is why you see &lt;code&gt;openShiftoAuth: false&lt;/code&gt; in the CheCluster resource.)&lt;/p&gt; &lt;p&gt;The workaround to this issue is to create the same set of users in CodeReady Workspaces, again using Ansible:&lt;/p&gt; &lt;pre&gt;- name: create codeready users include_tasks: add_che_user.yaml vars: user: "{{ item }}" with_list: "{{ users }}" &lt;/pre&gt; &lt;p&gt;In this example, &lt;code&gt;users&lt;/code&gt; is just an array of usernames in Ansible (for instance, &lt;code&gt;[user1, user2, ...]&lt;/code&gt;). We loop through and add the user in &lt;code&gt;add_che_user.yaml&lt;/code&gt;, which uses the CodeReady Workspaces REST API to get credentials for the SSO admin user and create the users:&lt;/p&gt; &lt;pre&gt;- name: Get codeready SSO admin token uri: url: https://keycloak-codeready.{{ route_subdomain }}/auth/realms/master/protocol/openid-connect/token validate_certs: false method: POST body: username: "{{ codeready_sso_admin_username }}" password: "{{ codeready_sso_admin_password }}" grant_type: "password" client_id: "admin-cli" body_format: form-urlencoded status_code: 200,201,204 register: codeready_sso_admin_token - name: Add user {{ user }} to Che uri: url: https://keycloak-codeready.{{ route_subdomain }}/auth/admin/realms/codeready/users validate_certs: false method: POST headers: Content-Type: application/json Authorization: "Bearer {{ codeready_sso_admin_token.json.access_token }}" body: username: "{{ user }}" enabled: true emailVerified: true firstName: "{{ user }}" lastName: Developer email: "{{ user }}@no-reply.com" credentials: - type: password value: "{{ workshop_che_user_password }}" temporary: false body_format: json status_code: 201,409 &lt;/pre&gt; &lt;p&gt;This playbook has a few variables:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;route_subdomain&lt;/code&gt; is the default OpenShift subdomain for your cluster (use &lt;code&gt;oc whoami --show-cluster&lt;/code&gt; to discover the cluster).&lt;/li&gt; &lt;li&gt;&lt;code&gt;workshop_che_user_password&lt;/code&gt; is your user&amp;#8217;s desired password.&lt;/li&gt; &lt;li&gt;&lt;code&gt;codeready_sso_admin_username/codeready_sso_admin_password&lt;/code&gt; is the admin username and password for the Keycloak instance used by CodeReady Workspaces.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;To programmatically discover the Keycloak admin username and password from the deployed Keycloak&amp;#8217;s environment variables, you can use a little more Ansible code and the &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible/latest/modules/k8s_facts_module.html"&gt;k8s_facts module&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;- name: Get codeready keycloak deployment k8s_facts: kind: Deployment namespace: codeready name: keycloak register: r_keycloak_deployment - name: set codeready username fact set_fact: codeready_sso_admin_username: "{{ r_keycloak_deployment.resources[0].spec.template.spec.containers[0].env | selectattr('name','equalto','SSO_ADMIN_USERNAME') |map (attribute='value') | list | first }}" - name: set codeready password fact set_fact: codeready_sso_admin_password: "{{ r_keycloak_deployment.resources[0].spec.template.spec.containers[0].env | selectattr('name','equalto','SSO_ADMIN_PASSWORD') |map (attribute='value') | list | first }}" &lt;/pre&gt; &lt;p&gt;Next up, we increase the &lt;a target="_blank" rel="nofollow" href="https://www.keycloak.org/docs/latest/server_admin/index.html#_timeouts"&gt;SSO token expiration and SSO session timeout&lt;/a&gt; (again, this lets us avoid irritating logouts during a workshop):&lt;/p&gt; &lt;pre&gt;- name: Increase codeready access token lifespans uri: url: https://keycloak-codeready.{{ route_subdomain }}/auth/admin/realms/codeready validate_certs: false method: PUT headers: Content-Type: application/json Authorization: "Bearer {{ codeready_sso_admin_token.json.access_token }}" body: accessTokenLifespan: 28800 accessTokenLifespanForImplicitFlow: 28800 actionTokenGeneratedByUserLifespan: 28800 ssoSessionIdleTimeout: 28800 ssoSessionMaxLifespan: 28800 body_format: json status_code: 204 &lt;/pre&gt; &lt;h2&gt;Pre-warming user workspaces&lt;/h2&gt; &lt;p&gt;Finally, we&amp;#8217;re ready to pre-create and pre-warm the CRW workspaces:&lt;/p&gt; &lt;pre&gt;- name: Pre-create and warm user workspaces include_tasks: create_che_workspace.yaml vars: user: "{{ item }}" with_list: "{{ users }}" &lt;/pre&gt; &lt;p&gt;We will repeat a loop similar to what we did to create the user workspaces. This time, we call &lt;code&gt;create_che_workspace.yaml&lt;/code&gt;, which uses the CodeReady Workspaces REST API:&lt;/p&gt; &lt;pre&gt;- name: "Get Che {{ user }} token" uri: url: https://keycloak-codeready.{{ route_subdomain }}/auth/realms/codeready/protocol/openid-connect/token validate_certs: false method: POST body: username: "{{ user }}" password: "{{ workshop_che_user_password }}" grant_type: "password" client_id: "admin-cli" body_format: form-urlencoded status_code: 200 register: user_token - name: Create workspace for {{ user }} from devfile uri: url: "https://codeready-codeready.{{ route_subdomain }}/api/workspace/devfile?start-after-create=true&amp;#38;namespace={{ user }}" validate_certs: false method: POST headers: Content-Type: application/json Authorization: "Bearer {{ user_token.json.access_token }}" body: "{{ lookup('template', './templates/devfile.json.j2') }}" body_format: json status_code: 201,409 register: workspace_def &lt;/pre&gt; &lt;h3&gt;About the devfile&lt;/h3&gt; &lt;p&gt;If you are wondering about the &lt;code&gt;devfile.json.j2&lt;/code&gt;, it is an &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_templating.html"&gt;Ansible Jinja2 template&lt;/a&gt; of a &lt;a href="https://developers.redhat.com/blog/2019/12/09/codeready-workspaces-devfile-demystified/"&gt;CodeReady devfile&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;You can find &lt;a target="_blank" rel="nofollow" href="https://github.com/redhat-cop/agnosticd/blob/development/ansible/roles/ocp4-workload-quarkus-workshop/templates/devfile.json.j2"&gt;the devfile for this example here&lt;/a&gt;. The interesting parts are:&lt;/p&gt; &lt;pre&gt; "components": [ { "id": "redhat/quarkus-java11/latest", "type": "chePlugin" }, &lt;/pre&gt; &lt;p&gt;Note that the devfile includes the &lt;a target="_blank" rel="nofollow" href="https://marketplace.visualstudio.com/items?itemName=redhat.vscode-quarkus"&gt;Quarkus plugin&lt;/a&gt; for the workspace, which provides IDE features like autocompletion and other tidbits:&lt;/p&gt; &lt;pre&gt; "image": "image-registry.openshift-image-registry.svc:5000/openshift/quarkus-stack:2.1", &lt;/pre&gt; &lt;p&gt;Here, we reference a Che stack that has been pre-generated and deployed into OpenShift as an ImageStream using:&lt;/p&gt; &lt;pre&gt;apiVersion: image.openshift.io/v1 kind: ImageStream metadata: name: quarkus-stack namespace: openshift spec: tags: - annotations: description: Quarkus stack for Java and CodeReady Workspaces iconClass: icon-java supports: java tags: builder,java version: "2.1" from: kind: DockerImage name: quay.io/openshiftlabs/quarkus-workshop-stack:2.1 name: "2.1" &lt;/pre&gt; &lt;p&gt;We built the stack &lt;a target="_blank" rel="nofollow" href="https://github.com/redhat-cop/agnosticd/blob/development/ansible/roles/ocp4-workload-quarkus-workshop/files/stack.Dockerfile"&gt;using a Dockerfile&lt;/a&gt; that also includes utilities (&lt;code&gt;oc&lt;/code&gt;, &lt;code&gt;kn&lt;/code&gt;, &lt;code&gt;tkn&lt;/code&gt;, and &lt;a href="https://developers.redhat.com/blog/tag/graalvm/"&gt;GraalVM&lt;/a&gt;). It runs a couple of test builds to pre-populate the Maven &lt;code&gt;.m2&lt;/code&gt; repository in the image so that users don&amp;#8217;t download the Internet every time they start the workshop. By pre-pulling this image into OpenShift, we significantly reduce workspace startup time. There is also the &lt;a target="_blank" rel="nofollow" href="https://www.eclipse.org/che/docs/che-7/caching-images-for-faster-workspace-start/"&gt;Image Puller&lt;/a&gt;, which I have not yet used. It looks promising for eliminating some of this logic.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In summary, automating CodeReady Workspace deployments at scale can significantly improve how students experience your workshops. Doing as much as possible up front lets students get to the learning, without waiting for installations, warm up, and so on.&lt;/p&gt; &lt;p&gt;This article introduced some of the Ansible playbooks we&amp;#8217;ve created to automate and improve user experiences with our workshops. Additional options include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Deploying other Operators (Strimzi, Jaeger, and so on).&lt;/li&gt; &lt;li&gt;Creating custom Keycloak realms for the workshop.&lt;/li&gt; &lt;li&gt;Verifying other components of the workshop are correctly deployed.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Have a look at the &lt;a target="_blank" rel="nofollow" href="https://github.com/redhat-cop/agnosticd/tree/development/ansible/roles/ocp4-workload-quarkus-workshop"&gt;Deploy Quarkus Workshop into an OpenShift 4 Cluster playbook&lt;/a&gt;. There might be other bits that you can use! Also, if you&amp;#8217;re interested in the onboarding new developers example, check out the article &lt;a target="_blank" rel="nofollow" href="https://thenewstack.io/codeready-workspaces-delivers-kubernetes-native-ide/"&gt;&lt;em&gt;CodeReady Workspaces Delivers Kubernetes-Native IDE&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F03%2Fautomate-workshop-setup-with-ansible-playbooks-and-codeready-workspaces%2F&amp;#38;linkname=Automate%20workshop%20setup%20with%20Ansible%20playbooks%20and%20CodeReady%20Workspaces" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F03%2Fautomate-workshop-setup-with-ansible-playbooks-and-codeready-workspaces%2F&amp;#38;linkname=Automate%20workshop%20setup%20with%20Ansible%20playbooks%20and%20CodeReady%20Workspaces" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F03%2Fautomate-workshop-setup-with-ansible-playbooks-and-codeready-workspaces%2F&amp;#38;linkname=Automate%20workshop%20setup%20with%20Ansible%20playbooks%20and%20CodeReady%20Workspaces" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F03%2Fautomate-workshop-setup-with-ansible-playbooks-and-codeready-workspaces%2F&amp;#38;linkname=Automate%20workshop%20setup%20with%20Ansible%20playbooks%20and%20CodeReady%20Workspaces" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F03%2Fautomate-workshop-setup-with-ansible-playbooks-and-codeready-workspaces%2F&amp;#38;linkname=Automate%20workshop%20setup%20with%20Ansible%20playbooks%20and%20CodeReady%20Workspaces" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F03%2Fautomate-workshop-setup-with-ansible-playbooks-and-codeready-workspaces%2F&amp;#38;linkname=Automate%20workshop%20setup%20with%20Ansible%20playbooks%20and%20CodeReady%20Workspaces" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F03%2Fautomate-workshop-setup-with-ansible-playbooks-and-codeready-workspaces%2F&amp;#38;linkname=Automate%20workshop%20setup%20with%20Ansible%20playbooks%20and%20CodeReady%20Workspaces" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F03%2Fautomate-workshop-setup-with-ansible-playbooks-and-codeready-workspaces%2F&amp;#038;title=Automate%20workshop%20setup%20with%20Ansible%20playbooks%20and%20CodeReady%20Workspaces" data-a2a-url="https://developers.redhat.com/blog/2020/07/03/automate-workshop-setup-with-ansible-playbooks-and-codeready-workspaces/" data-a2a-title="Automate workshop setup with Ansible playbooks and CodeReady Workspaces"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/07/03/automate-workshop-setup-with-ansible-playbooks-and-codeready-workspaces/"&gt;Automate workshop setup with Ansible playbooks and CodeReady Workspaces&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/7pCq_zQaU9g" height="1" width="1" alt=""/&gt;</content><summary>At Red Hat, we do many in-person and virtual workshops for customers, partners, and other open source developers. In most cases, the workshops are of the “bring your own device” variety, so we face a range of hardware and software setups and corporate endpoint-protection schemes, as well as different levels of system knowledge. In the past few years, we’ve made heavy use of Red Hat CodeReady Works...</summary><dc:creator>James Falkner</dc:creator><dc:date>2020-07-03T07:00:39Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/07/03/automate-workshop-setup-with-ansible-playbooks-and-codeready-workspaces/</feedburner:origLink></entry><entry><title>A developer-centered approach to application development</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/pPBDHcKvq4U/" /><category term="angular 8 tutorial" scheme="searchisko:content:tags" /><category term="devops" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="javascript" scheme="searchisko:content:tags" /><category term="mock api" scheme="searchisko:content:tags" /><category term="mock data" scheme="searchisko:content:tags" /><category term="Node.js" scheme="searchisko:content:tags" /><category term="open source" scheme="searchisko:content:tags" /><category term="quality gate" scheme="searchisko:content:tags" /><category term="reverse proxy" scheme="searchisko:content:tags" /><author><name>Valentino Pellegrino</name></author><id>searchisko:content:id:jbossorg_blog-a_developer_centered_approach_to_application_development</id><updated>2020-07-03T07:00:28Z</updated><published>2020-07-03T07:00:28Z</published><content type="html">&lt;p&gt;Do you dream of a local development environment that&amp;#8217;s easy to configure and works independently from the software layers that you are currently &lt;em&gt;not&lt;/em&gt; working on? I do!&lt;/p&gt; &lt;p&gt;As a software engineer, I have suffered the pain of starting projects that were not easy to configure. Reading the technical documentation does not help when much of it is outdated, or even worse, missing many steps. I have lost hours of my life trying to understand why my local development environment was not working.&lt;/p&gt; &lt;h2&gt;An ideal scenario&lt;/h2&gt; &lt;p&gt;As a developer, you have to meet a few prerequisites before contributing to a project. For instance, you must agree to the version-control requirements, and you need to know how to use the project IDE, how to use a package manager, and so on.&lt;/p&gt; &lt;p&gt;But nothing more. You don&amp;#8217;t need to learn a poorly documented, made-in-house framework just to satisfy the ego of an architect who wanted to reinvent the wheel. You don&amp;#8217;t need to run an external virtual machine to emulate the production environment. As a developer, you are free to invest your time in improving the code and adding value to the product.&lt;/p&gt; &lt;h2&gt;A developer-centered approach to application development&lt;/h2&gt; &lt;p&gt;My goal with this article is to describe strategies for building an &lt;a target="_blank" rel="nofollow" href="https://angular.io/guide/build"&gt;Angular 8&lt;/a&gt; application in a way that centers the developer experience.&lt;/p&gt; &lt;p&gt;&lt;span id="more-724407"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;The type of application is incidental. I describe a client application, but we could apply similar techniques to back-end modules. The framework, in this case, is Angular, but we could use similar techniques for practically any framework that you prefer.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; As a brief introduction, Angular is an application design framework and development platform for creating efficient and sophisticated single-page apps. You can learn more on &lt;a target="_blank" rel="nofollow" href="https://angular.io/"&gt;Angular website&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The example application is a simple web app, with authentication, that performs several calls to REST endpoints. I won&amp;#8217;t offer many details about the domain and the business logic, because those factors don&amp;#8217;t matter for my discussion.&lt;/p&gt; &lt;p&gt;The primary requirements for this use case are to enhance the developer experience. The strategies follow from that.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: In cases where my strategies for resolving use-case requirements directly involve Angular and other software libraries, I will share details about those technologies. However, I am confident that similar options exist for other technologies and frameworks.&lt;/p&gt; &lt;h2&gt;Requirement 1: No back-end information in the client application&lt;/h2&gt; &lt;p&gt;Imagine the following scenario: A client-side application must perform a couple of &lt;code&gt;GET&lt;/code&gt; operations, which will fetch data for display on a web page. How do you know which is the host address, the protocol, and the port to call for each REST endpoint?&lt;/p&gt; &lt;p&gt;Typically, I have seen three approaches to resolving this issue:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Add the back-end information to the application at build time.&lt;/li&gt; &lt;li&gt;Pass the back-end information to the web application as parameters, or retrieve it from the environment variables.&lt;/li&gt; &lt;li&gt;Locate the web application and REST service on the same machine. This approach lets the web app call the &lt;code&gt;localhost&lt;/code&gt; at a specific port and path. In that case, we &amp;#8220;only&amp;#8221; need to hard code the port and protocol.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Unfortunately, each of these strategies leads to a black hole when developing your web application:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;You need to modify the runtime status while debugging.&lt;/li&gt; &lt;li&gt;You need to hack the application to simulate the expected startup.&lt;/li&gt; &lt;li&gt;Worst of all, you need to point to a real shared dev or testing environment.&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Strategy: Reverse proxy&lt;/h3&gt; &lt;p&gt;The concept of a &lt;em&gt;reverse proxy&lt;/em&gt; is quite easy. First, let&amp;#8217;s consider it as a black-box feature.&lt;/p&gt; &lt;p&gt;Suppose that someone configures the machine that is hosting your web app so that when you call yourself (via &lt;code&gt;localhost&lt;/code&gt;) on a specific path (for instance, &lt;code&gt;/api&lt;/code&gt;), every call is automatically forwarded to the &lt;a href="https://developers.redhat.com/topics/api-management/"&gt;API&lt;/a&gt; server. With this configuration, it does not matter which is the address, the protocol, or the port in use.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you want to look inside the black box, you can learn more about configuring a reverse proxy on &lt;a target="_blank" rel="nofollow" href="https://www.digitalocean.com/community/tutorials/how-to-use-apache-as-a-reverse-proxy-with-mod_proxy-on-ubuntu-16-04"&gt;Apache HTTPD&lt;/a&gt; or &lt;a target="_blank" rel="nofollow" href="https://linuxize.com/post/nginx-reverse-proxy/"&gt;NGINX&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;&lt;a name="reverse-proxy"&gt;&lt;/a&gt;Reverse proxy in Angular&lt;/h3&gt; &lt;p&gt;Now let&amp;#8217;s consider a reverse proxy in Angular, using a slightly different scenario. Suppose that your static files are served by the Webpack dev server on port 4200, while a &lt;a href="https://developers.redhat.com/blog/category/node-js/"&gt;Node.js&lt;/a&gt; app serves the APIs on port 3000. Figure 1 shows the flow of this architecture (Credit to https://juristr.com/blog/2016/11/configure-proxy-api-angular-cli/.)&lt;/p&gt; &lt;p&gt;You can easily configure the global variable &lt;code&gt;PROXY_CONFIG&lt;/code&gt; as part of the Webpack dev-server lifecycle. You can choose to use &lt;code&gt;proxy.conf.json&lt;/code&gt; or &lt;code&gt;proxy.conf.js&lt;/code&gt;, depending on your &lt;code&gt;angular.json&lt;/code&gt; configuration file. Here&amp;#8217;s an example of a &lt;code&gt;PROXY_CONFIG&lt;/code&gt; file:&lt;/p&gt; &lt;pre&gt;const PROXY_CONFIG = { "/api": { "target": "http://localhost:3000/", "secure": false, "logLevel": "debug", "changeOrigin": true } }; module.exports = PROXY_CONFIG; &lt;/pre&gt; &lt;p&gt;Note that every HTTP call must point to &lt;code&gt;/api&lt;/code&gt;. There is no need to specify any other information. The reverse proxy does the rest for us, like so:&lt;/p&gt; &lt;pre&gt;getPosts(): Observable { return this.http.get('/api/posts/'); } &lt;/pre&gt; &lt;p&gt;As soon as you subscribe to &lt;code&gt;getPosts()&lt;/code&gt;, it calls the target address (in this case, http://localhost:3000/posts).&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: Learn more about setting up an &lt;a target="_blank" rel="nofollow" href="https://github.com/angular/angular-cli/blob/master/docs/documentation/stories/proxy.md"&gt;Angular CLI reverse proxy&lt;/a&gt; or a &lt;a target="_blank" rel="nofollow" href="https://webpack.js.org/configuration/dev-server/#devserver-proxy"&gt;Webpack dev server reverse proxy&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Requirement 2: Offline coding (coding without an Internet connection)&lt;/h2&gt; &lt;p&gt;When coding, you want your dependencies with the outside world to be as minimal as possible. There are many reasons to avoid connecting to a shared remote development machine. The remote machine might be:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Not recently updated.&lt;/li&gt; &lt;li&gt;Slow, because of its load.&lt;/li&gt; &lt;li&gt;Delayed, because there is a VPN.&lt;/li&gt; &lt;li&gt;Unavailable, because someone is updating it.&lt;/li&gt; &lt;li&gt;Unreachable, because your Internet connection is not working.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;You &lt;em&gt;also&lt;/em&gt; don&amp;#8217;t want to launch a real instance of the development machine locally, however. Such an instance might:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Have third-party dependencies that are difficult to mock.&lt;/li&gt; &lt;li&gt;Be heavy to run, for instance, with a minimum requirement of 32GB of RAM.&lt;/li&gt; &lt;li&gt;Be connected to a database, in which case you have to either install the database or connect to a real remote instance.&lt;/li&gt; &lt;li&gt;Be difficult to update because your data are in a historical series, so what is valid today might not be valid tomorrow.&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Strategy: Mocking data&lt;/h3&gt; &lt;p&gt;There are several solutions to make development fast and agile. For example, you could use &lt;a href="https://developers.redhat.com/topics/containers/"&gt;containers&lt;/a&gt; to provide isolated and reproducible computing environments.&lt;/p&gt; &lt;p&gt;When working on a web app, I believe it makes sense to use mocked APIs. If you are working with REST endpoints, I recommend the &lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/typicode/json-server"&gt;&lt;code&gt;json-server&lt;/code&gt;&lt;/a&gt;&lt;/code&gt; package, which you can install both globally and locally. If you install &lt;code&gt;json-server&lt;/code&gt; globally, you can launch it anywhere you like. If you install it locally, you can install it as a dependency for your dev environment, and then create a Node Package Manager (&lt;code&gt;npm&lt;/code&gt;) script to launch a customized mocked server.&lt;/p&gt; &lt;p&gt;The setup is quite intuitive. Say that you have a JSON file as a data source; say, &lt;code&gt;db.json&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;db.json: { "posts": [ { "id": 1, "title": "json-server", "author": "typicode" } ], "comments": [ { "id": 1, "body": "some comment", "postId": 1 } ], "profile": { "name": "typicode" } } &lt;/pre&gt; &lt;p&gt;You can launch the file via the command line:&lt;/p&gt; &lt;pre&gt;$ json-server --watch db.json&lt;/pre&gt; &lt;p&gt;By default, it starts on &lt;code&gt;localhost&lt;/code&gt;, port 3000, so if you &lt;code&gt;GET http://localhost:3000/posts/1&lt;/code&gt;, you will receive the following response:&lt;/p&gt; &lt;pre&gt;{ "id": 1, "title": "json-server", "author": "typicode" } &lt;/pre&gt; &lt;p&gt;The &lt;code&gt;GET&lt;/code&gt; is just an example, you can use other HTTP verbs, as well. You also can choose to save edits in the original file or leave it as it is. Exposed APIs follow the REST standard, and you can sort, filter, paginate, and load remote schemas.&lt;/p&gt; &lt;p&gt;As I mentioned earlier, you can create your own script and run a &lt;code&gt;json-server&lt;/code&gt; instance programmatically:&lt;/p&gt; &lt;pre&gt;const jsonServer = require('json-server') const server = jsonServer.create() const router = jsonServer.router('db.json') const middlewares = jsonServer.defaults() server.use(middlewares) server.use(router) server.listen(3000, () =&amp;#62; { console.log('JSON Server is running') }) &lt;/pre&gt; &lt;h3&gt;Mocked data in Angular&lt;/h3&gt; &lt;p&gt;I can suggest a couple of strategies for making your Angular app work with mocked data. Both are based on the proxy.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Strategy 1&lt;/strong&gt;: Configure the &lt;a href="#reverse-proxy"&gt;reverse proxy&lt;/a&gt;, pointing to &lt;code&gt;http://localhost:3000/&lt;/code&gt; in the target, so that every call points to the &lt;code&gt;json-server&lt;/code&gt; instance.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Strategy 2&lt;/strong&gt;: Add a custom mocking rule to the proxy, so that it uses the &lt;code&gt;bypass&lt;/code&gt; parameter to return data for a specific path:&lt;/p&gt; &lt;pre&gt;const PROXY_CONFIG = { '/api': { 'target': 'http://localhost:5000', 'bypass': function (req, res, proxyOptions) { switch (req.url) { case '/api/json1': const objectToReturn1 = { value1: 1, value2: 'value2', value3: 'value3' }; res.end(JSON.stringify(objectToReturn1)); return true; case '/api/json2': const objectToReturn2 = { value1: 2, value2: 'value3', value3: 'value4' }; res.end(JSON.stringify(objectToReturn2)); return true; } } } } module.exports = PROXY_CONFIG; &lt;/pre&gt; &lt;h2&gt;Requirement 3: Dev code should not affect production code, and vice versa&lt;/h2&gt; &lt;p&gt;How many times have you seen something like this:&lt;/p&gt; &lt;pre&gt;if (devMode) {...} else {...}&lt;/pre&gt; &lt;p&gt;This code is an example of what we call &lt;i&gt;code smell&lt;/i&gt;, meaning that it mixes code for development purposes with code intended for production only. A build targeted for production should not contain code related to development, and vice versa. The solution to code smell is to use different builds for different targets.&lt;/p&gt; &lt;p&gt;Code smell shows up in many different kinds of use cases. For instance, your application could be hosted behind a single sign-on (SSO) authentication system. The first time that a user requests the application in a browser, the request is redirected to an external page, which asks for credentials.&lt;/p&gt; &lt;p&gt;When you are in dev mode, you don&amp;#8217;t want to deal with the redirect. A less complicated authentication service is welcome.&lt;/p&gt; &lt;h3&gt;Strategy: Use a file-replacement policy&lt;/h3&gt; &lt;p&gt;In Angular, based on the current configuration, it is possible to specify a file-replacement policy. You can easily use this feature to replace a simple authentication service used for development purposes with a more robust and complex one required for production:&lt;/p&gt; &lt;pre&gt;"configurations": { "production": { "fileReplacements": [ { "replace": "src/app/core/services/authenticator.ts", "with": "src/app/core/services/authenticator.prod.ts" } ], ... ... } &lt;/pre&gt; &lt;p&gt;The codebase now has two separate authentication services, which are configured for use in two different environments. Most importantly, only one service will be included in the final artifact, based on the specific build parameter:&lt;/p&gt; &lt;pre&gt;$ npm run ng build -c production&lt;/pre&gt; &lt;h2&gt;Requirement 4: Know what version of the application is currently running in production&lt;/h2&gt; &lt;p&gt;Do you know at all times what version of your application is running on a given host? You can use build parameters like build time or the last-commit identifier to determine whether your current environment is updated for a recent update or bug fix.&lt;/p&gt; &lt;h3&gt;Strategy: Use &lt;code&gt;angular-build-info&lt;/code&gt;&lt;/h3&gt; &lt;p&gt;Angular includes a command-line tool, called &lt;a target="_blank" rel="nofollow" href="https://www.npmjs.com/package/angular-build-info"&gt;&lt;code&gt;angular-build-info&lt;/code&gt;&lt;/a&gt;, that produces a &lt;code&gt;build.ts&lt;/code&gt; file inside of your Angular project&amp;#8217;s &lt;code&gt;src/&lt;/code&gt; folder. Using this tool, you can import the &lt;code&gt;build.ts&lt;/code&gt; file inside of your Angular application and use the exported &lt;code&gt;buildInfo&lt;/code&gt; variable:&lt;/p&gt; &lt;pre&gt;import { Component } from '@angular/core'; import { environment } from '../environments/environment'; import { buildInfo } from '../build'; @Component({ selector: 'app-root', templateUrl: './app.component.html', styleUrls: ['./app.component.scss'] }) export class AppComponent { constructor() { console.log( `\nBuild Info:\n` + ` ❯ Environment: ${environment.production ? 'production &amp;#x1f3ed;' : 'development &amp;#x1f6a7;'}\n` + ` ❯ Build Version: ${buildInfo.version}\n` + ` ❯ Build Timestamp: ${buildInfo.timestamp}\n` ); } } &lt;/pre&gt; &lt;p&gt;Note that the &lt;code&gt;build.ts&lt;/code&gt; content must be versioned, so you need to execute the following script at build time:&lt;/p&gt; &lt;pre&gt;$ angular-build-info --no-message --no-user --no-hash &lt;/pre&gt; &lt;p&gt;The parameters are optional so that you can customize the produced &lt;code&gt;buildInfo&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Requirement 5: A fast and effective quality check in the pipeline&lt;/h2&gt; &lt;p&gt;Regardless of whether you are launching a build pipeline locally or if you have sent a pull request, it would be great to have an overview of the overall project quality.&lt;/p&gt; &lt;h3&gt;Strategy: Static code analysis with a quality gate&lt;/h3&gt; &lt;p&gt;When you need to measure the quality of a software, static code analysis might help. It provides several metrics about readability, maintainability, security, etc. without actually execute the software itself.&lt;/p&gt; &lt;p&gt;If you are able to measure quality metrics, then you can configure formal revisions that might help to evaluate the process used to develop and release new parts of the software. Such formal revisions are named &lt;em&gt;quality gates&lt;/em&gt;.&lt;/p&gt; &lt;p&gt;Static code analysis must be fast, with clean results. You don&amp;#8217;t want to scroll through pages of redundant logged results. It matters—the phase, and the order, where you place the quality gate.&lt;/p&gt; &lt;p&gt;For this requirement, I would place the quality gate before test execution and immediately after compilation or transpiling (assuming that is happening). I recommend this placement for two reasons:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;It avoids wasting time checking the static code if it does not compile or transpile.&lt;/li&gt; &lt;li&gt;It avoids wasting time executing a whole suite of tests for code that does not meet the minimum requirements that the team has defined.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;It is important to keep in mind that a pipeline execution requires resources. A good developer should never push a commit without executing a local quality check first. You can also reduce the number of files to be checked by caching the results, or performing static code analysis, only on files that are involved in the change list.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;When you start working on a new project, non-technical requirements should not slow down your productivity curve.&lt;/p&gt; &lt;p&gt;As a developer, you should not have to waste time on configuration issues, or a development machine that sometimes works and sometimes doesn&amp;#8217;t. Take care of these issues up-front. Happy developers spend more time coding than resolving technical impediments.&lt;/p&gt; &lt;p&gt;Improving your developer experience is not a one-time process, but an incremental one. There is always room for automation. There is always room for improvement.&lt;/p&gt; &lt;div id="gtx-trans"&gt; &lt;div class="gtx-trans-icon"&gt;&lt;/div&gt; &lt;/div&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F03%2Fa-developer-centered-approach-to-application-development%2F&amp;#38;linkname=A%20developer-centered%20approach%20to%20application%20development" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F03%2Fa-developer-centered-approach-to-application-development%2F&amp;#38;linkname=A%20developer-centered%20approach%20to%20application%20development" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F03%2Fa-developer-centered-approach-to-application-development%2F&amp;#38;linkname=A%20developer-centered%20approach%20to%20application%20development" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F03%2Fa-developer-centered-approach-to-application-development%2F&amp;#38;linkname=A%20developer-centered%20approach%20to%20application%20development" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F03%2Fa-developer-centered-approach-to-application-development%2F&amp;#38;linkname=A%20developer-centered%20approach%20to%20application%20development" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F03%2Fa-developer-centered-approach-to-application-development%2F&amp;#38;linkname=A%20developer-centered%20approach%20to%20application%20development" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F03%2Fa-developer-centered-approach-to-application-development%2F&amp;#38;linkname=A%20developer-centered%20approach%20to%20application%20development" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F03%2Fa-developer-centered-approach-to-application-development%2F&amp;#038;title=A%20developer-centered%20approach%20to%20application%20development" data-a2a-url="https://developers.redhat.com/blog/2020/07/03/a-developer-centered-approach-to-application-development/" data-a2a-title="A developer-centered approach to application development"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/07/03/a-developer-centered-approach-to-application-development/"&gt;A developer-centered approach to application development&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/pPBDHcKvq4U" height="1" width="1" alt=""/&gt;</content><summary>Do you dream of a local development environment that’s easy to configure and works independently from the software layers that you are currently not working on? I do! As a software engineer, I have suffered the pain of starting projects that were not easy to configure. Reading the technical documentation does not help when much of it is outdated, or even worse, missing many steps. I have lost hour...</summary><dc:creator>Valentino Pellegrino</dc:creator><dc:date>2020-07-03T07:00:28Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/07/03/a-developer-centered-approach-to-application-development/</feedburner:origLink></entry><entry><title>Build a simple cloud-native change data capture pipeline</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/On_tjS024ic/" /><category term="apache camel" scheme="searchisko:content:tags" /><category term="change data capture" scheme="searchisko:content:tags" /><category term="data pipeline" scheme="searchisko:content:tags" /><category term="debezium" scheme="searchisko:content:tags" /><category term="event-driven" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Java" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="OpenShift 4" scheme="searchisko:content:tags" /><category term="Stream Processing" scheme="searchisko:content:tags" /><author><name>Federico Valeri</name></author><id>searchisko:content:id:jbossorg_blog-build_a_simple_cloud_native_change_data_capture_pipeline</id><updated>2020-07-02T07:00:51Z</updated><published>2020-07-02T07:00:51Z</published><content type="html">&lt;p&gt;Change data capture (CDC) is a well-established software design pattern for a system that monitors and captures data changes so that other software can respond to those events. Using KafkaConnect, along with &lt;a href="https://debezium.io" target="_blank" target="_blank" rel="nofollow" noreferrer"&gt;Debezium Connectors&lt;/a&gt; and the &lt;a href="https://camel.apache.org/camel-kafka-connector/latest/index.html" target="_blank" target="_blank" rel="nofollow" noreferrer"&gt;Apache Camel Kafka Connector&lt;/a&gt;, we can build a configuration-driven data pipeline to bridge traditional data stores and new &lt;a href="https://developers.redhat.com/topics/event-driven/"&gt;event-driven architectures&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;This article walks through a simple example.&lt;br /&gt; &lt;span id="more-725217"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Why use change data capture?&lt;/h2&gt; &lt;p&gt;The advantages of CDC compared to a simple poll-based or query-based process are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;All changes are captured&lt;/strong&gt;: Intermediary changes (i.e., updates and deletes) between two runs of the poll loop might otherwise be missed.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Low overhead&lt;/strong&gt;: Near real-time reaction to data changes avoids increased CPU load due to frequent polling.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;No data model impact&lt;/strong&gt;: Timestamp columns are no longer needed to determine the last data update.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;The example&lt;/h2&gt; &lt;p&gt;In this example, we build a simple cloud-native CDC pipeline from scratch. The goal is to send every change from a simple &lt;code&gt;customers&lt;/code&gt; table to a message queue for further processing. Once the infrastructure is provisioned, we will implement the data pipeline using configuration files, without writing any code. This is the high-level overview of the architecture:&lt;/p&gt; &lt;pre&gt;MySQL --&amp;#62; KafkaConnect [Worker0JVM(TaskA0, TaskB0, TaskB1),...] --&amp;#62; AMQ | Kafka (offsets, config, status) &lt;/pre&gt; &lt;p&gt;Even if this is a simple use case, it includes the deployment and setup of different integration products on top of OpenShift 4: AMQ 7.7 (message broker), AMQ Streams 1.5 (Kafka and KafkaConnect) and Debezium (CDC engine). This infrastructure will make sense when expanding this simple example into a group of &lt;a href="https://developers.redhat.com/topics/microservices/"&gt;microservices&lt;/a&gt; communicating with each other by sending events. The nice thing about using Debezium is that you don&amp;#8217;t need to change your application&amp;#8217;s logic.&lt;/p&gt; &lt;p&gt;You can find all of the &lt;a target="_blank" rel="nofollow" href="https://github.com/fvaleri/cdc/tree/blog/ocp"&gt;required configuration files here&lt;/a&gt;.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt;  For the sake of simplicity, we use unsecured components that are not suitable for production use. You might want to add TLS encryption setup and also increase resources for any serious use.&lt;/p&gt; &lt;h3&gt;Setting up&lt;/h3&gt; &lt;p&gt;To provision the infrastructure for our CDC pipeline, we have to set up the OpenShift project, MySQL source system, AMQ sink system, AMQ Streams, and the Debezium connector. You can also use &lt;a href="https://developers.redhat.com/products/codeready-containers/overview"&gt;Red Hat CodeReady Containers (CRC)&lt;/a&gt;, but make sure to reserve eight cores and at least 14 GB of memory.&lt;/p&gt; &lt;p&gt;We will do all of this from the command line, so open your favorite shell. No prompt is added so that you can easily copy and paste the code you find here. First, set your environment variables:&lt;/p&gt; &lt;pre&gt;API_ENDPOINT="https://api.crc.testing:6443" ADMIN_NAME="kubeadmin" ADMIN_PASS="7z6T5-qmTth-oxaoD-p3xQF" USER_NAME="developer" USER_PASS="developer" PROJECT_NAME="cdc" &lt;/pre&gt; &lt;p&gt;Next, create a new project:&lt;/p&gt; &lt;pre&gt;TMP="/tmp/ocp" &amp;#38;&amp;#38; rm -rf $TMP &amp;#38;&amp;#38; mkdir -p $TMP oc login -u $ADMIN_NAME -p $ADMIN_PASS $API_ENDPOINT oc new-project $PROJECT_NAME oc adm policy add-role-to-user admin $USER_NAME &lt;/pre&gt; &lt;p&gt;Then set up Red Hat registry authentication (use your own credentials here):&lt;/p&gt; &lt;pre&gt;REG_SECRET="registry-secret" oc create secret docker-registry $REG_SECRET \ --docker-server="registry.redhat.io" \ --docker-username="my-user" \ --docker-password="my-pass" oc secrets link default $REG_SECRET --for=pull oc secrets link builder $REG_SECRET --for=pull oc secrets link deployer $REG_SECRET --for=pull &lt;/pre&gt; &lt;h3&gt;MySQL setup (source system)&lt;/h3&gt; &lt;p&gt;Our source system is MySQL. Here, we use a custom DeploymentConfig that contains a post lifecycle hook to initialize our database and enable binary log access for the Debezium user. To start, create your ConfigMap and your secret:&lt;/p&gt; &lt;pre&gt;oc create configmap db-config --from-file=./mysql/my.cnf oc create configmap db-init --from-file=./mysql/initdb.sql oc create secret generic db-creds \ --from-literal=database-name=cdcdb \ --from-literal=database-user=cdcadmin \ --from-literal=database-password=cdcadmin \ --from-literal=database-admin-password=cdcadmin &lt;/pre&gt; &lt;p&gt;Next, deploy your resources:&lt;/p&gt; &lt;pre&gt;oc create -f ./mysql/my-mysql.yaml &lt;/pre&gt; &lt;p&gt;Check the status:&lt;/p&gt; &lt;pre&gt;MYSQL_POD=$(oc get pods | grep my-mysql | grep Running | cut -d " " -f1) oc exec -i $MYSQL_POD -- /bin/sh -c 'MYSQL_PWD="cdcadmin" $MYSQL_PREFIX/bin/mysql -u cdcadmin cdcdb -e "SELECT * FROM customers"' &lt;/pre&gt; &lt;p&gt;Make some data changes:&lt;/p&gt; &lt;pre&gt;oc exec -i $MYSQL_POD -- /bin/sh -c 'MYSQL_PWD="cdcadmin" $MYSQL_PREFIX/bin/mysql -u cdcadmin cdcdb -e \ "INSERT INTO customers (first_name, last_name, email) VALUES (\"John\", \"Doe\", \"jdoe@example.com\")"' oc exec -i $MYSQL_POD -- /bin/sh -c 'MYSQL_PWD="cdcadmin" $MYSQL_PREFIX/bin/mysql -u cdcadmin cdcdb -e \ "UPDATE customers SET first_name = \"Jane\" WHERE id = 1"' oc exec -i $MYSQL_POD -- /bin/sh -c 'MYSQL_PWD="cdcadmin" $MYSQL_PREFIX/bin/mysql -u cdcadmin cdcdb -e \ "INSERT INTO customers (first_name, last_name, email) VALUES (\"Chuck\", \"Norris\", \"cnorris@example.com\")"' &lt;/pre&gt; &lt;h3&gt;AMQ Broker setup (sink system)&lt;/h3&gt; &lt;p&gt;Our destination system is the AMQ message broker, and you can &lt;a href="https://developers.redhat.com/products/amq/overview"&gt;download Red Hat AMQ&lt;/a&gt; broker from the developer portal for free. Here, we simply create a single instance broker and our destination queue:&lt;/p&gt; &lt;pre&gt;mkdir $TMP/amq unzip -qq /path/to/amq-broker-operator-7.7.0-ocp-install-examples.zip -d $TMP/amq AMQ_DEPLOY="$(find $TMP/amq -name "deploy" -type d)" &lt;/pre&gt; &lt;p&gt;Deploy the Operator:&lt;/p&gt; &lt;pre&gt;oc create -f $AMQ_DEPLOY/service_account.yaml oc create -f $AMQ_DEPLOY/role.yaml oc create -f $AMQ_DEPLOY/role_binding.yaml sed -i -e "s/v2alpha1/v2alpha2/g" $AMQ_DEPLOY/crds/broker_v2alpha1_activemqartemis_crd.yaml sed -i -e "s/v2alpha1/v2alpha2/g" $AMQ_DEPLOY/crds/broker_v2alpha1_activemqartemisaddress_crd.yaml oc apply -f $AMQ_DEPLOY/crds oc secrets link amq-broker-operator $REG_SECRET --for=pull oc create -f $AMQ_DEPLOY/operator.yaml &lt;/pre&gt; &lt;p&gt;Deploy the resources:&lt;/p&gt; &lt;pre&gt;oc create -f ./amq/my-broker.yaml &lt;/pre&gt; &lt;p&gt;Configure it to create the address only when the broker pod is running:&lt;/p&gt; &lt;pre&gt;oc create -f ./amq/my-address.yaml &lt;/pre&gt; &lt;p&gt;Check the status:&lt;/p&gt; &lt;pre&gt;oc get activemqartemises oc get activemqartemisaddresses &lt;/pre&gt; &lt;h3&gt;AMQ Streams setup (Kafka)&lt;/h3&gt; &lt;p&gt;You can also download Red Hat AMQ Streams on the same portal page, which is required to run KafkaConnect. Here we create a simple cluster with just one node. There is no need to create any topic here because Debezium will take care of this, creating its internal topics and our destination topic with the pattern &lt;code&gt;serverName.databaseName.tableName&lt;/code&gt;.&lt;/p&gt; &lt;pre&gt;mkdir $TMP/streams unzip -qq /path/to/amq-streams-1.5.0-ocp-install-examples.zip -d $TMP/streams STREAMS_DEPLOY="$(find $TMP/streams -name "install" -type d)" &lt;/pre&gt; &lt;p&gt;Deploy the Operator:&lt;/p&gt; &lt;pre&gt;sed -i -e "s/namespace: .*/namespace: $PROJECT_NAME/g" $STREAMS_DEPLOY/cluster-operator/*RoleBinding*.yaml oc apply -f $STREAMS_DEPLOY/cluster-operator oc set env deploy/strimzi-cluster-operator STRIMZI_NAMESPACE=$PROJECT_NAME oc secrets link builder $REG_SECRET --for=pull oc secrets link strimzi-cluster-operator $REG_SECRET --for=pull oc set env deploy/strimzi-cluster-operator STRIMZI_IMAGE_PULL_SECRETS=$REG_SECRET oc apply -f $STREAMS_DEPLOY/strimzi-admin oc adm policy add-cluster-role-to-user strimzi-admin $USER_NAME &lt;/pre&gt; &lt;p&gt;Deploy the resources:&lt;/p&gt; &lt;pre&gt;oc apply -f ./streams/my-kafka.yaml &lt;/pre&gt; &lt;p&gt;Check the status:&lt;/p&gt; &lt;pre&gt;oc get kafkas &lt;/pre&gt; &lt;h3&gt;AMQ Streams setup (KafkaConnect)&lt;/h3&gt; &lt;p&gt;From the same AMQ Streams package, we can also deploy our KafkaConnect custom image. We will build it on top of the official one, adding our specific connector plugins. In this case, we will add Debezium MySQL Connector and Camel Kafka SJMS2 Connector (I&amp;#8217;m using the latest upstream releases for convenience, but you can download Red Hat releases from the portal).&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; The nice thing about this new Camel sub-project is that you can use all 300+ components as Kafka connectors, to integrate with almost any external system.&lt;/p&gt; &lt;p&gt;Once your connectors are up and running (see the status from the &lt;code&gt;describe&lt;/code&gt; command), you can make other changes to the &lt;code&gt;customers&lt;/code&gt; table and see if they are streamed to the queue by using the broker web console:&lt;/p&gt; &lt;pre&gt;KAFKA_CLUSTER="my-kafka-cluster" CONNECTOR_URLS=( "https://repo.maven.apache.org/maven2/io/debezium/debezium-connector-mysql/1.1.2.Final/debezium-connector-mysql-1.1.2.Final-plugin.zip" "https://repository.apache.org/content/groups/public/org/apache/camel/kafkaconnector/camel-sjms2-kafka-connector/0.3.0/camel-sjms2-kafka-connector-0.3.0-package.zip" ) CONNECTORS="$TMP/connectors" &amp;#38;&amp;#38; mkdir -p $CONNECTORS for url in "${CONNECTOR_URLS[@]}"; do curl -sL $url -o $CONNECTORS/file.zip &amp;#38;&amp;#38; unzip -qq $CONNECTORS/file.zip -d $CONNECTORS done sleep 2 rm -rf $CONNECTORS/file.zip &lt;/pre&gt; &lt;p&gt;Deploy the resources:&lt;/p&gt; &lt;pre&gt;oc create secret generic debezium-config --from-file=./streams/connectors/mysql.properties oc create secret generic camel-config --from-file=./streams/connectors/amq.properties oc apply -f ./streams/my-connect-s2i.yaml &lt;/pre&gt; &lt;p&gt;Start the custom image build only when connect cluster is running:&lt;/p&gt; &lt;pre&gt;oc start-build my-connect-cluster-connect --from-dir $CONNECTORS --follow &lt;/pre&gt; &lt;p&gt;Check the status:&lt;/p&gt; &lt;pre&gt;oc get kafkaconnects2i &lt;/pre&gt; &lt;p&gt;These are all running pods up to this point:&lt;/p&gt; &lt;pre&gt;amq-broker-operator-5d4559677-dpzf5 1/1 Running 0 21m my-broker-ss-0 1/1 Running 0 19m my-connect-cluster-connect-2-xr58q 1/1 Running 0 6m28s my-kafka-cluster-entity-operator-56c9868474-kfdx2 3/3 Running 1 14m my-kafka-cluster-kafka-0 2/2 Running 0 14m my-kafka-cluster-zookeeper-0 1/1 Running 0 15m my-mysql-1-vmbbw 1/1 Running 0 25m strimzi-cluster-operator-666fcd8b96-q8thc 1/1 Running 0 15m &lt;/pre&gt; &lt;p&gt;Now that we have our infrastructure ready, we can finally configure the CDC pipeline:&lt;/p&gt; &lt;pre&gt;oc apply -f ./streams/connectors/mysql-source.yaml oc apply -f ./streams/connectors/amq-sink.yaml &lt;/pre&gt; &lt;p&gt;Check the status:&lt;/p&gt; &lt;pre&gt;oc get kafkaconnectors oc describe kafkaconnector mysql-source oc describe kafkaconnector amq-sink CONNECT_POD=$(oc get pods | grep my-connect-cluster | grep Running | cut -d " " -f1) oc logs $CONNECT_POD oc get kafkatopics oc exec -i $KAFKA_CLUSTER-kafka-0 -c kafka -- bin/kafka-console-consumer.sh \ --bootstrap-server my-kafka-cluster-kafka-bootstrap:9092 --topic my-mysql.cdcdb.customers --from-beginning &lt;/pre&gt; &lt;p&gt;Open the AMQ web console route to check the queue&amp;#8217;s contents:&lt;/p&gt; &lt;pre&gt;echo http://$(oc get routes my-broker-wconsj-0-svc-rte -o=jsonpath='{.status.ingress[0].host}{"\n"}')/console &lt;/pre&gt; &lt;h2&gt;Cleanup&lt;/h2&gt; &lt;p&gt;When you have finished experimenting with your new cloud-native CDC pipeline, you can delete the whole project with the following commands and free some resources:&lt;/p&gt; &lt;pre&gt;rm -rf $TMP oc delete project $PROJECT_NAME oc delete crd/activemqartemises.broker.amq.io oc delete crd/activemqartemisaddresses.broker.amq.io oc delete crd/activemqartemisscaledowns.broker.amq.io oc delete crd -l app=strimzi oc delete clusterrolebinding -l app=strimzi oc delete clusterrole -l app=strimzi &lt;/pre&gt; &lt;h2&gt;Considerations&lt;/h2&gt; &lt;p&gt;No matter what technology you use, the change data capture process must run as a single thread to maintain ordering. Since Debezium records the log offset asynchronously, any final consumer of these changes must be &lt;a target="_blank" rel="nofollow" href="https://en.wikipedia.org/wiki/Idempotence"&gt;idempotent&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;A benefit of running on top of KafkaConnect in distributed mode is that you have a fault-tolerant CDC process. Debezium offers great performance because of the access to the data source&amp;#8217;s internal transaction log, but there is no standard for it, so a change to the implementation may require a plug-in rewrite. This also means that every data source has its own procedure for enabling access to the transaction log.&lt;/p&gt; &lt;p&gt;Connectors configuration allows you to transform message payloads by using &lt;a target="_blank" rel="nofollow" href="https://kafka.apache.org/documentation/#connect_transforms"&gt;Single Message Transformations (SMTs)&lt;/a&gt;. These can be chained and extended with custom implementations, but they are actually designed for simple modifications. Long chains of SMTs are hard to maintain and make sense of. Moreover, transformations are synchronous and applied on each message, so you can slow down the streaming pipeline with heavy processing or external service calls.&lt;/p&gt; &lt;p&gt;In cases where you need to do heavy processing, split, enrich, aggregate records, or call external services, you should use a stream processing layer between connectors such as Kafka Streams or just &lt;a href="https://github.com/fvaleri/cdc/tree/blog/camel-cdc" target="_blank" target="_blank" rel="nofollow" noreferrer"&gt;plain Camel&lt;/a&gt;. Just remember that Kafka Streams creates internal topics and you are forced to put transformed data back into Kafka (data duplication), while this approach is just an option when using Camel.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F02%2Fbuild-a-simple-cloud-native-change-data-capture-pipeline%2F&amp;#38;linkname=Build%20a%20simple%20cloud-native%20change%20data%20capture%20pipeline" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F02%2Fbuild-a-simple-cloud-native-change-data-capture-pipeline%2F&amp;#38;linkname=Build%20a%20simple%20cloud-native%20change%20data%20capture%20pipeline" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F02%2Fbuild-a-simple-cloud-native-change-data-capture-pipeline%2F&amp;#38;linkname=Build%20a%20simple%20cloud-native%20change%20data%20capture%20pipeline" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F02%2Fbuild-a-simple-cloud-native-change-data-capture-pipeline%2F&amp;#38;linkname=Build%20a%20simple%20cloud-native%20change%20data%20capture%20pipeline" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F02%2Fbuild-a-simple-cloud-native-change-data-capture-pipeline%2F&amp;#38;linkname=Build%20a%20simple%20cloud-native%20change%20data%20capture%20pipeline" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F02%2Fbuild-a-simple-cloud-native-change-data-capture-pipeline%2F&amp;#38;linkname=Build%20a%20simple%20cloud-native%20change%20data%20capture%20pipeline" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F02%2Fbuild-a-simple-cloud-native-change-data-capture-pipeline%2F&amp;#38;linkname=Build%20a%20simple%20cloud-native%20change%20data%20capture%20pipeline" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F02%2Fbuild-a-simple-cloud-native-change-data-capture-pipeline%2F&amp;#038;title=Build%20a%20simple%20cloud-native%20change%20data%20capture%20pipeline" data-a2a-url="https://developers.redhat.com/blog/2020/07/02/build-a-simple-cloud-native-change-data-capture-pipeline/" data-a2a-title="Build a simple cloud-native change data capture pipeline"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/07/02/build-a-simple-cloud-native-change-data-capture-pipeline/"&gt;Build a simple cloud-native change data capture pipeline&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/On_tjS024ic" height="1" width="1" alt=""/&gt;</content><summary>Change data capture (CDC) is a well-established software design pattern for a system that monitors and captures data changes so that other software can respond to those events. Using KafkaConnect, along with Debezium Connectors and the Apache Camel Kafka Connector, we can build a configuration-driven data pipeline to bridge traditional data stores and new event-driven architectures. This article w...</summary><dc:creator>Federico Valeri</dc:creator><dc:date>2020-07-02T07:00:51Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/07/02/build-a-simple-cloud-native-change-data-capture-pipeline/</feedburner:origLink></entry><entry><title>Improved schema binding and more in Red Hat XML extension for VS Code 0.12.0 and LemMinX</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/M3qhqVYQguo/" /><category term="Developer Tools" scheme="searchisko:content:tags" /><category term="entity validation" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Java" scheme="searchisko:content:tags" /><category term="LemMinX" scheme="searchisko:content:tags" /><category term="VS Code" scheme="searchisko:content:tags" /><category term="xml declaration" scheme="searchisko:content:tags" /><category term="xml vs code" scheme="searchisko:content:tags" /><category term="xsd schema" scheme="searchisko:content:tags" /><author><name>David Thompson</name></author><id>searchisko:content:id:jbossorg_blog-improved_schema_binding_and_more_in_red_hat_xml_extension_for_vs_code_0_12_0_and_lemminx</id><updated>2020-07-02T07:00:25Z</updated><published>2020-07-02T07:00:25Z</published><content type="html">&lt;p&gt;The latest update of the &lt;a href="https://developers.redhat.com/products/vscode-extensions/overview"&gt;Red Hat XML extension for Visual Studio Code&lt;/a&gt; (VS Code), version 0.12.0, is packed with bug fixes and new features. It includes the new version of the underlying &lt;a href="https://developers.redhat.com/blog/2020/03/27/red-hat-xml-language-server-becomes-lemminx-bringing-new-release-and-updated-vs-code-xml-extension/"&gt;Eclipse LemMinX XML language server&lt;/a&gt;. In this update, we streamlined the process of writing XML Schema Definitions (XSD) and Document Type Definitions (DTD). We also added shortcuts to bind XML documents to either of these types of XML grammar.&lt;/p&gt; &lt;p&gt;This article demonstrates the highlights of the 0.12.0 update to XML extension for &lt;a href="https://developers.redhat.com/blog/category/topics/vs-code/"&gt;VS Code&lt;/a&gt;, including new formatting options to reduce visual clutter, support for &lt;code&gt;&amp;#60;?xml-model … ?&amp;#62;&lt;/code&gt;, and context-aware snippets to assist with binding a document to an XML schema. For the full list of more than 50 enhancements and bug fixes, see the &lt;a target="_blank" rel="nofollow" href="https://github.com/redhat-developer/vscode-xml/blob/master/CHANGELOG.md"&gt;XML extension for VS Code changelog&lt;/a&gt;. You can also watch a video demonstration of the new features here:&lt;/p&gt; &lt;p&gt;&lt;iframe class='youtube-player' type='text/html' width='640' height='360' src='https://www.youtube.com/embed/3Gd-cGDRBcw?version=3&amp;#038;rel=1&amp;#038;fs=1&amp;#038;autohide=2&amp;#038;showsearch=0&amp;#038;showinfo=1&amp;#038;iv_load_policy=1&amp;#038;wmode=transparent' allowfullscreen='true' style='border:0;'&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: Both the XML extension for VS Code, version 0.12.0, and the underlying LemMinX XML language server are now available in the &lt;a target="_blank" rel="nofollow" href="https://marketplace.visualstudio.com/items?itemName=redhat.vscode-xml"&gt;Visual Studio Code Marketplace&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Entity validation and completion&lt;/h2&gt; &lt;p&gt;Red Hat&amp;#8217;s XML extension for VS Code now supports entity validation and entity-name completion with hover-over and go-to definitions for locally and externally declared entities.&lt;/p&gt; &lt;p&gt;Hovering over an entity displays the value that it represents and a link to the file where it was defined. Going to the entity definition brings the cursor to the line in the file where the entity was declared, whether that’s in the same file or an external file. If an entity is referenced but hasn’t yet been declared, you can use the new quick fix to define it in the doctype declaration. All of these options are demonstrated in Figure 1.&lt;/p&gt; &lt;div id="attachment_736357" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/DeclareEntity.gif"&gt;&lt;img aria-describedby="caption-attachment-736357" class="wp-image-736357" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/DeclareEntity.gif" alt="A demo of the new new entity validation, completion, hover, and go-to definitions." width="640" height="516" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-736357" class="wp-caption-text"&gt;Figure 1: The new entity validation and completion features with hover-over and go-to definitions.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;XSD documentation settings&lt;/h2&gt; &lt;p&gt;Prior to this release, hovering over an XSD element displayed all of the &lt;code&gt;xs:documentation&lt;/code&gt; and &lt;code&gt;xs:appinfo&lt;/code&gt; available for that element on a single line, along with a link to the XSD schema file. With this release, we introduced a new setting to help remove some of that visual clutter, as shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_736397" style="width: 587px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/element-hover-settings.png"&gt;&lt;img aria-describedby="caption-attachment-736397" class="wp-image-736397 size-full" style="font-size: 16px;" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/element-hover-settings.png" alt="A screenshot of the VS Code Settings menu, displaying the different options available for displaying XSD documentation." width="577" height="246" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/element-hover-settings.png 577w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/element-hover-settings-300x128.png 300w" sizes="(max-width: 577px) 100vw, 577px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-736397" class="wp-caption-text"&gt;Figure 2: New options for displaying the XSD element documentation.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;You can now use the &lt;code&gt;xml.preferences.showSchemaDocumentationType&lt;/code&gt; setting to specify what you would like to see when you hover over an element: &lt;code&gt;xs:documentation&lt;/code&gt;, &lt;code&gt;xs:appinfo&lt;/code&gt;, both of these elements, or nothing at all. Also, as shown in Figure 3, subtitles now separate the &lt;code&gt;xs:documentation&lt;/code&gt; and &lt;code&gt;xs:appinfo&lt;/code&gt; elements when they are both present, making definitions easier to read.&lt;/p&gt; &lt;div id="attachment_736407" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/image2.png"&gt;&lt;img aria-describedby="caption-attachment-736407" class="wp-image-736407 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/image2-1020x1024.png" alt="A screenshot showing the before and after results of hovering over an element with documentation. The hover now uses subtitles to seperate app info and documentation." width="640" height="643" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/image2-1020x1024.png 1020w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/image2-150x150.png 150w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/image2-300x300.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/image2-768x771.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-736407" class="wp-caption-text"&gt;Figure 3: The hover feature now uses subtitles to separate app info and documentation.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Formatting (&lt;code&gt;xml.format)&lt;/code&gt;&lt;/h2&gt; &lt;p&gt;We introduced several new settings to the XML extension&amp;#8217;s formatting feature.&lt;/p&gt; &lt;h3&gt;Enforce quote style: Ignore or preferred&lt;/h3&gt; &lt;p&gt;The &lt;code&gt;xml.format.enforceQuoteStyle&lt;/code&gt; setting indicates that the formatter should replace all quotations with the preferred quotation type (which is set in &lt;code&gt;xml.preferences.quoteStyle&lt;/code&gt;) or ignore the preferred quotation type and leave the quotes as they are (which is the default setting). The demonstration in Figure 4 shows the new quote-style options.&lt;/p&gt; &lt;div id="attachment_744607" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Quotes-Retake-640-v2.gif"&gt;&lt;img aria-describedby="caption-attachment-744607" class="wp-image-744607 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Quotes-Retake-640-v2.gif" alt="A demonstration of the formatter ignoring the preferred format style when enforceQuoteStyle is set to be ignored." width="640" height="412" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-744607" class="wp-caption-text"&gt;Figure 4: The default Enforce Quote Style setting is to ignore the quote style.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Empty elements: Ignore, collapse, or expand&lt;/h3&gt; &lt;p&gt;The &lt;code&gt;xml.format.emptyElements&lt;/code&gt; setting tells the formatter whether to write empty elements using an opening and closing tag (&lt;code&gt;&amp;#60;img&amp;#62;&amp;#60;/img&amp;#62;&lt;/code&gt;), or using the shorthand notation (&lt;code&gt;&amp;#60;img /&amp;#62;&lt;/code&gt;). As a default setting, you can choose to preserve the format that is already in use. The demo in Figure 5 shows these options.&lt;/p&gt; &lt;div id="attachment_744657" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/image3.gif"&gt;&lt;img aria-describedby="caption-attachment-744657" class="wp-image-744657 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/image3-640.gif" alt="Demo of the formatter expanding self-closing elements and turning self closing elements into an open and close tag, depending on the emptyElements setting." width="640" height="329" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-744657" class="wp-caption-text"&gt;Figure 5: The formatter can expand or turn off self-closing elements depending on the Empty Elements setting.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Preserve attribute line breaks: True or false&lt;/h3&gt; &lt;p&gt;If you enable the &lt;code&gt;xml.format.preserveAttributeLineBreaks&lt;/code&gt; setting, the formatter will preserve line breaks before and after attributes. By default, the formatter places each attribute on a single line, so this setting is useful for indicating that attributes should stay on their respective lines. The demo in Figure 6 shows the formatter placing line breaks before and after attributes.&lt;/p&gt; &lt;div id="attachment_744697" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/image6.gif"&gt;&lt;img aria-describedby="caption-attachment-744697" class="size-full wp-image-744697" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/image6-640.gif" alt="A demonstration of the formatter preserving line breaks between attributes." width="640" height="313" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-744697" class="wp-caption-text"&gt;Figure 6: The formatter can preserve line breaks before and after attributes.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Document links&lt;/h2&gt; &lt;p&gt;Navigating between XML documents and their schemas is easier in the new XML extension for VS Code. The extension now provides document links in the &lt;code&gt;schemaLocation&lt;/code&gt; attribute for the &lt;code&gt;xs:include&lt;/code&gt; and &lt;code&gt;xs:import&lt;/code&gt; schema elements, as well as another document link in the &lt;code&gt;href&lt;/code&gt; attribute for the &lt;code&gt;xml-model&lt;/code&gt; processing instruction. Figure 7 shows an &lt;code&gt;xs:schema&lt;/code&gt; with &lt;code&gt;xs:include&lt;/code&gt; and &lt;code&gt;xs:import&lt;/code&gt; elements.&lt;/p&gt; &lt;div id="attachment_736587" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/image4.png"&gt;&lt;img aria-describedby="caption-attachment-736587" class="wp-image-736587 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/image4-1024x525.png" alt="An xs schema showing the underlined document links." width="640" height="328" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/image4-1024x525.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/image4-300x154.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/image4-768x394.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/image4.png 1088w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-736587" class="wp-caption-text"&gt;Figure 7: An &lt;code&gt;xs:schema&lt;/code&gt; with &lt;code&gt;xs:include&lt;/code&gt; and &lt;code&gt;xs:import&lt;/code&gt; elements.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;New XML model support&lt;/h2&gt; &lt;p&gt;The XML extension for VS Code now supports the &lt;code&gt;&amp;#60;?xml-model … ?&amp;#62;&lt;/code&gt; method of binding an XML document to its schema. The XML document will be validated against the schema, providing all the same features that are already supported through existing methods of schema binding. We added a document link that links the &lt;code&gt;href&lt;/code&gt; attribute of the &lt;code&gt;&amp;#60;?xml-model … ?&amp;#62;&lt;/code&gt; instruction to the referenced schema document. As discussed in the next section, we also added snippets to help with writing the XML model schema references.&lt;/p&gt; &lt;p&gt;Figure 8 shows a demonstration of an XML document being bound to an &lt;code&gt;.xsd&lt;/code&gt; document through the &lt;code&gt;&amp;#60;?xml-model … ?&amp;#62;&lt;/code&gt; processing instruction.&lt;/p&gt; &lt;div id="attachment_744717" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/image5.gif"&gt;&lt;img aria-describedby="caption-attachment-744717" class="size-full wp-image-744717" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/image5-640.gif" alt="A demonstration of an XML document being bound to an xs document through the xml-model processing instruction." width="640" height="411" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-744717" class="wp-caption-text"&gt;Figure 8: An XML document is bound to an &lt;code&gt;.xsd&lt;/code&gt; document through the &lt;code&gt;&amp;#60;?xml-model … ?&amp;#62;&lt;/code&gt; processing instruction.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Snippets&lt;/h2&gt; &lt;p&gt;We made several changes to improve snippets. Previously, snippets were a part of the XML extension for VS Code. With this update, we moved them to the server-side of the extension (LemMinX) using the JSON format. Not only does this change allow us to provide snippets to all of the &lt;a target="_blank" rel="nofollow" href="https://code.visualstudio.com/api/language-extensions/language-server-extension-guide"&gt;Language Server Protocol (LSP)&lt;/a&gt; clients (such as Eclipse with Wild Web Developer, Emacs, and so on) but snippets are context-aware. For example, we can provide &lt;i&gt;XML declaration&lt;/i&gt; snippets only if the document does not already have an XML declaration, and only if your cursor is on the first line of the document. We also added new snippets, such as for doctype declarations. The overall goal of adding these snippets is to make it easier to bind documents to schemas.&lt;/p&gt; &lt;h3&gt;Snippet demos&lt;/h3&gt; &lt;p&gt;The demo in Figure 9 shows some of the possible snippet completions.&lt;/p&gt; &lt;div id="attachment_736617" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/image1.png"&gt;&lt;img aria-describedby="caption-attachment-736617" class="wp-image-736617" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/image1.png" alt="An empty file showing many possible snippet completions." width="640" height="382" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/image1.png 745w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/image1-300x179.png 300w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-736617" class="wp-caption-text"&gt;Figure 9: Examples of snippets now available in the new XML extension for Visual Studio Code.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;In Figure 10, we use snippets to quickly create an XML document bound to &lt;code&gt;.xsd&lt;/code&gt; schemas through &lt;code&gt;schemaLocation&lt;/code&gt; and &lt;code&gt;noNamespaceSchemaLocation&lt;/code&gt;. We then use a snippet to write an XML document with a doctype declaration.&lt;/p&gt; &lt;div id="attachment_736637" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/image12.gif"&gt;&lt;img aria-describedby="caption-attachment-736637" class="wp-image-736637" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/image12.gif" alt="A demo that shows snippets that automatically generate schema bindings in blank XML files." width="640" height="313" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-736637" class="wp-caption-text"&gt;Figure 10: Using snippets to create and bind an XML document to &lt;code&gt;.xsd&lt;/code&gt; schemas.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;In Figure 11, we use a snippet to quickly generate a doctype declaration that declares the root element of the XML document.&lt;/p&gt; &lt;div id="attachment_736647" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/image9.gif"&gt;&lt;img aria-describedby="caption-attachment-736647" class="wp-image-736647" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/image9.gif" alt="A demo of using a snippet to generate a doctype declaration for an existing XML file." width="640" height="313" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-736647" class="wp-caption-text"&gt;Figure 11: Using snippets to generate a doctype declaration.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;In a future release, we hope to provide snippets and quick fixes that generate schemas from existing XML documents.&lt;/p&gt; &lt;h2&gt;A new outline limit for symbols&lt;/h2&gt; &lt;p&gt;For performance reasons, we set a default limit of 6,000 symbol-tree items for the &lt;b&gt;Outline&lt;/b&gt; view, which is located within the XML extension&amp;#8217;s &lt;b&gt;Explorer&lt;/b&gt;. You can use the use &lt;code&gt;xml.symbols.maxItemsComputed&lt;/code&gt; setting to manually configure the limit.&lt;/p&gt; &lt;p&gt;When the symbol limit is reached for a particular file, a notification will appear, providing the current limit and a &lt;b&gt;Configure Limit&lt;/b&gt; button, which navigates to the &lt;code&gt;xml.symbols.maxItemsComputed&lt;/code&gt; setting in the VS Code settings UI. Figure 12 shows the error and the new button.&lt;/p&gt; &lt;div id="attachment_736667" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/image11.png"&gt;&lt;img aria-describedby="caption-attachment-736667" class="wp-image-736667 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/image11-1024x540.png" alt="VS Code displays an error message when the document symbol limit is exceeded." width="640" height="338" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/image11-1024x540.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/image11-300x158.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/image11-768x405.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-736667" class="wp-caption-text"&gt;Figure 12: A large file with the symbols tree capped at 6,000 items.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Our goal with the 0.12.0 version of Red Hat&amp;#8217;s XML extension for Visual Studio Code was to improve the workflow of writing XML schemas and binding XML documents to a grammar. For the next release, we aim to improve the schema-writing workflow by providing quick fixes and snippets that make it easier to generate the schema for a particular XML document. If you encounter unexpected behavior in this release, feel free to &lt;a target="_blank" rel="nofollow" href="https://github.com/redhat-developer/vscode-xml"&gt;open a GitHub issue&lt;/a&gt;.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: Special thanks to &lt;a target="_blank" rel="nofollow" href="https://github.com/BalduinLandolt"&gt;Balduin Landolt&lt;/a&gt;, who contributed the &lt;code&gt;&amp;#60;?xml-model … ?&amp;#62;&lt;/code&gt; snippets, as well as a fix that disables snippets if the cursor is before the XML prolog.&lt;/p&gt; &lt;h2&gt;Further information&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Get the &lt;a target="_blank" rel="nofollow" href="https://marketplace.visualstudio.com/items?itemName=redhat.vscode-xml"&gt;vscode-xml extension&lt;/a&gt; on the Visual Studio Marketplace.&lt;/li&gt; &lt;li&gt;Get the &lt;a target="_blank" rel="nofollow" href="https://github.com/redhat-developer/vscode-xml"&gt;vscode-xml extension&lt;/a&gt; on GitHub.&lt;/li&gt; &lt;li&gt;Check out &lt;a target="_blank" rel="nofollow" href="https://github.com/eclipse/lemminx"&gt;LemMinX, the XML Language Server&lt;/a&gt; on GitHub.&lt;/li&gt; &lt;li&gt;Open a new issue on the &lt;a target="_blank" rel="nofollow" href="https://github.com/eclipse/lemminx/issues/new/choose"&gt;LemMinX GitHub page&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;View the &lt;a target="_blank" rel="nofollow" href="https://github.com/eclipse/lemminx/blob/master/CHANGELOG.md"&gt;changelog for LemMinX&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Learn more about &lt;a href="https://developers.redhat.com/blog/2020/03/27/red-hat-xml-language-server-becomes-lemminx-bringing-new-release-and-updated-vs-code-xml-extension/"&gt;LemMinX being migrated to the Eclipse Foundation&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F02%2Fimproved-schema-binding-and-more-in-red-hat-xml-extension-for-vs-code-0-12-0-and-lemminx%2F&amp;#38;linkname=Improved%20schema%20binding%20and%20more%20in%20Red%20Hat%20XML%20extension%20for%20VS%20Code%200.12.0%20and%20LemMinX" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F02%2Fimproved-schema-binding-and-more-in-red-hat-xml-extension-for-vs-code-0-12-0-and-lemminx%2F&amp;#38;linkname=Improved%20schema%20binding%20and%20more%20in%20Red%20Hat%20XML%20extension%20for%20VS%20Code%200.12.0%20and%20LemMinX" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F02%2Fimproved-schema-binding-and-more-in-red-hat-xml-extension-for-vs-code-0-12-0-and-lemminx%2F&amp;#38;linkname=Improved%20schema%20binding%20and%20more%20in%20Red%20Hat%20XML%20extension%20for%20VS%20Code%200.12.0%20and%20LemMinX" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F02%2Fimproved-schema-binding-and-more-in-red-hat-xml-extension-for-vs-code-0-12-0-and-lemminx%2F&amp;#38;linkname=Improved%20schema%20binding%20and%20more%20in%20Red%20Hat%20XML%20extension%20for%20VS%20Code%200.12.0%20and%20LemMinX" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F02%2Fimproved-schema-binding-and-more-in-red-hat-xml-extension-for-vs-code-0-12-0-and-lemminx%2F&amp;#38;linkname=Improved%20schema%20binding%20and%20more%20in%20Red%20Hat%20XML%20extension%20for%20VS%20Code%200.12.0%20and%20LemMinX" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F02%2Fimproved-schema-binding-and-more-in-red-hat-xml-extension-for-vs-code-0-12-0-and-lemminx%2F&amp;#38;linkname=Improved%20schema%20binding%20and%20more%20in%20Red%20Hat%20XML%20extension%20for%20VS%20Code%200.12.0%20and%20LemMinX" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F02%2Fimproved-schema-binding-and-more-in-red-hat-xml-extension-for-vs-code-0-12-0-and-lemminx%2F&amp;#38;linkname=Improved%20schema%20binding%20and%20more%20in%20Red%20Hat%20XML%20extension%20for%20VS%20Code%200.12.0%20and%20LemMinX" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F02%2Fimproved-schema-binding-and-more-in-red-hat-xml-extension-for-vs-code-0-12-0-and-lemminx%2F&amp;#038;title=Improved%20schema%20binding%20and%20more%20in%20Red%20Hat%20XML%20extension%20for%20VS%20Code%200.12.0%20and%20LemMinX" data-a2a-url="https://developers.redhat.com/blog/2020/07/02/improved-schema-binding-and-more-in-red-hat-xml-extension-for-vs-code-0-12-0-and-lemminx/" data-a2a-title="Improved schema binding and more in Red Hat XML extension for VS Code 0.12.0 and LemMinX"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/07/02/improved-schema-binding-and-more-in-red-hat-xml-extension-for-vs-code-0-12-0-and-lemminx/"&gt;Improved schema binding and more in Red Hat XML extension for VS Code 0.12.0 and LemMinX&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/M3qhqVYQguo" height="1" width="1" alt=""/&gt;</content><summary>The latest update of the Red Hat XML extension for Visual Studio Code (VS Code), version 0.12.0, is packed with bug fixes and new features. It includes the new version of the underlying Eclipse LemMinX XML language server. In this update, we streamlined the process of writing XML Schema Definitions (XSD) and Document Type Definitions (DTD). We also added shortcuts to bind XML documents to either o...</summary><dc:creator>David Thompson</dc:creator><dc:date>2020-07-02T07:00:25Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/07/02/improved-schema-binding-and-more-in-red-hat-xml-extension-for-vs-code-0-12-0-and-lemminx/</feedburner:origLink></entry><entry><title>Install Apache Tomcat and deploy a Java web application on Red Hat OpenShift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/FOdIrHGuIrY/" /><category term="Apache Tomcat" scheme="searchisko:content:tags" /><category term="application deployment" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Java" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="tomcat openshift tutorial" scheme="searchisko:content:tags" /><author><name>Pandurang Memane</name></author><id>searchisko:content:id:jbossorg_blog-install_apache_tomcat_and_deploy_a_java_web_application_on_red_hat_openshift</id><updated>2020-07-01T07:00:58Z</updated><published>2020-07-01T07:00:58Z</published><content type="html">&lt;p&gt;If you are new to OpenShift, then you might want to install Apache Tomcat on top of it for simpler experimentation. This article guides you through installing Apache Tomcat from a Docker image and then using it to deploy a Java web app on &lt;a href="https://developers.redhat.com/products/openshift/getting-started"&gt;Red Hat OpenShift&lt;/a&gt;. I also show you how to access the Tomcat management console on OpenShift.&lt;/p&gt; &lt;p&gt;To follow the examples, you must have an &lt;a target="_blank" rel="nofollow" href="https://www.openshift.com/try"&gt;OpenShift account&lt;/a&gt;. We will use the OpenShift command-line interface (CLI) for this demonstration, so be sure to &lt;a href="https://developers.redhat.com/openshift/command-line-tools/"&gt;install the CLI&lt;/a&gt; (&lt;code&gt;oc&lt;/code&gt;) before you begin.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;A note about the sample application&lt;/b&gt;: You will need a Java web application to use for the deployment example. I am using the &lt;a target="_blank" rel="nofollow" href="https://github.com/openshiftdemos/os-sample-java-web.git"&gt;Sample Java Web Application&lt;/a&gt; from the &lt;a target="_blank" rel="nofollow" href="https://github.com/OpenShiftDemos"&gt;OpenShift Demos&lt;/a&gt; GitHub repository. It is a simple application that is useful for understanding basic concepts. You may use the provided sample or choose your own application to work with.&lt;/p&gt; &lt;p&gt;&lt;span id="more-724737"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;About the Tomcat management console&lt;/h2&gt; &lt;p&gt;The Tomcat Manager is for deploying a new web application (or undeploying an existing one) without having to shut down and restart the entire container. In addition, the Tomcat Manager lets you request that an existing application reload itself, even if you have not declared it to be &lt;code&gt;reloadable&lt;/code&gt; in the Tomcat server configuration file.&lt;/p&gt; &lt;p&gt;This manager consists of a web application (installed by default on the context path &lt;code&gt;/manager&lt;/code&gt;) that supports the following functions:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Deploy a new web application from the uploaded contents of a WAR file.&lt;/li&gt; &lt;li&gt;Deploy a new web application, on a specified context path, from the server file system.&lt;/li&gt; &lt;li&gt;List the currently deployed web applications, as well as the sessions that are currently active for those web applications.&lt;/li&gt; &lt;li&gt;Reload an existing web application, to reflect changes in the contents of &lt;code&gt;/WEB-INF/classes&lt;/code&gt; or &lt;code&gt;/WEB-INF/lib&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;List the OS and JVM property values.&lt;/li&gt; &lt;li&gt;List the available global JNDI resources, for use in deployment tools that prepare &lt;code&gt;&amp;#60;ResourceLink&amp;#62;&lt;/code&gt; elements nested in a &lt;code&gt;&amp;#60;Context&amp;#62;&lt;/code&gt; deployment description.&lt;/li&gt; &lt;li&gt;Start a stopped application (thus making it available again).&lt;/li&gt; &lt;li&gt;Stop an existing application (so that it becomes unavailable), but do not undeploy it.&lt;/li&gt; &lt;li&gt;Undeploy a deployed web application and delete its document base directory (unless it was deployed from the file system).&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Step 1: Install Tomcat on OpenShift&lt;/h2&gt; &lt;p&gt;To start, let&amp;#8217;s install &lt;a target="_blank" rel="nofollow" href="http://tomcat.apache.org/tomcat-9.0-doc/introduction.html"&gt;Apache Tomcat 9&lt;/a&gt; from a Docker image. As previously mentioned, we&amp;#8217;ll use the OpenShift command-line tool, &lt;code&gt;oc&lt;/code&gt;, for our installation:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;From the command line, log in to your OpenShift console: &lt;pre&gt;$ oc login --server=https://openshift.testcluster.lab.redhat.com -u user -p password&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Enter your Red Hat registry service account username and password: &lt;pre&gt;sh-4.2# sudo sh - sh-4.2# docker login Username: {REGISTRY-SERVICE-ACCOUNT-USERNAME} Password: {REGISTRY-SERVICE-ACCOUNT-PASSWORD} Login Succeeded &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Here is the command to pull the Docker image from the Red Hat container registry, followed by status output: &lt;pre&gt;sh-4.2# docker pull registry.redhat.io/jboss-webserver-5/webserver53-openjdk8-tomcat9-openshift-rhel7 Using default tag: latest Trying to pull repository registry.redhat.io/jboss-webserver-5/webserver53-openjdk8-tomcat9-openshift-rhel7 ... latest: Pulling from registry.redhat.io/jboss-webserver-5/webserver53-openjdk8-tomcat9-openshift-rhel7 1f1202c893ce: Pull complete 32be9843afa0: Pull complete c927648f9ad0: Pull complete 8ac7bcea2a65: Pull complete Digest: sha256:bd637c88fdc94cd4e4476e00af1baeb3c1f3a6d9a873a73bee646950cdf076fc Status: Downloaded newer image for registry.redhat.io/jboss-webserver-5/webserver53-openjdk8-tomcat9-openshift-rhel7:latest &lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;Step 2: Create a new project&lt;/h2&gt; &lt;p&gt;Next, we&amp;#8217;ll create a new project to deploy the web application using Tomcat.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Enter the following to create a new project: &lt;pre&gt;sh-4.2# oc new-project tomcat Now using project "tomcat" on server "https://openshift.testcluster.lab.redhat.com:443". &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Go to your new &lt;code&gt;tomcat&lt;/code&gt; project: &lt;pre&gt;sh-4.2# oc project tomcat Already on project "tomcat" on server "https://openshift.testcluster.lab.redhat.com:443". &lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;Step 3: Create the Java web application&lt;/h2&gt; &lt;p&gt;Now, we create a Java web application.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Create a &lt;code&gt;new-app&lt;/code&gt; using the sample application that you chose (mine is &lt;code&gt;os-sample-java-web&lt;/code&gt;): &lt;pre&gt;$ oc new-app registry.redhat.io/jboss-webserver-5/webserver53-openjdk8-tomcat9-openshift-rhel7~https://github.com/openshiftdemos/os-sample-java-web.git&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Verify that the application was deployed and the pod was created: &lt;pre&gt;sh-4.2# oc get pods NAME READY STATUS RESTARTS AGE os-sample-java-web-1-build 0/1 Completed 0 2m os-sample-java-web-1-k5sqz 1/1 Running 0 1m&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Verify that the cluster service was created: &lt;pre&gt;sh-4.2# oc get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE os-sample-java-web ClusterIP x.x.x.x &amp;#60;none&amp;#62; 8080/TCP,8443/TCP,8778/TCP 1m sh-4.2# &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Verify whether or not the route was created. If the route is not present (as shown below), then run the following command to expose the service: &lt;pre&gt;sh-4.2# oc get route No resources found.sh-4.2# oc expose svc os-sample-java-web route.route.openshift.io/os-sample-java-web exposedsh-4.2# oc get route NAME HOST/PORT PATH SERVICES PORT TERMINATION WILDCARD os-sample-java-web os-sample-java-web-tomcat.openshift.testcluster.lab.redhat.com os-sample-java-web 8080-tcp None &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Using the route that you have just discovered, confirm that you can access application: &lt;pre&gt;os-sample-java-web-tomcat.openshift.testcluster.lab.redhat.com&lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;Step 4: Access the Tomcat Manager on OpenShift&lt;/h2&gt; &lt;p&gt;For security purposes, you can only access the Tomcat Manager on &lt;code&gt;localhost&lt;/code&gt;. If you tried entering the following, for example, you would receive a &amp;#8220;403 forbidden&amp;#8221; error:&lt;/p&gt; &lt;pre&gt;os-sample-java-web-tomcat.openshift.testcluster.lab.redhat.com/manager&lt;/pre&gt; &lt;p&gt;Here is the command-line procedure to access the management console for Tomcat:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Copy the &lt;code&gt;secure-mgmt-console.sh&lt;/code&gt; and &lt;code&gt;context.xml&lt;/code&gt; file from your pods to your master machine: &lt;pre&gt;sh-4.2# oc cp os-sample-java-web-1-k5sqz:/opt/jws-5.3/tomcat/bin/launch/secure-mgmt-console.sh secure-mgmt-console.sh sh-4.2# oc cp os-sample-java-web-1-k5sqz:/opt/jws-5.3/tomcat/webapps/manager/META-INF/context.xml context.xml sh-4.2# ls ansible.cfg context.xml hosts htpasswd log openshift-ansible secure-mgmt-console.sh &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Back up the main &lt;code&gt;secure-mgmt-console.sh&lt;/code&gt; file: &lt;pre&gt;cp -pr secure-mgmt-console.sh secure-mgmt-console.sh_ORIG &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Make the following changes in the new &lt;code&gt;secure-mgmt-console.sh&lt;/code&gt; file (note that users with the &lt;code&gt;manager-gui&lt;/code&gt; role should &lt;i&gt;not&lt;/i&gt; be granted the &lt;code&gt;manager-script&lt;/code&gt; or &lt;code&gt;manager-jmx&lt;/code&gt; role): &lt;pre&gt;sh-4.2# diff secure-mgmt-console.sh secure-mgmt-console.sh_ORIG 13c13 &amp;#60; sed -i -e"s|&amp;#60;/tomcat-users&amp;#62;|\n&amp;#60;role rolename=\"manager-gui\"/&amp;#62;\n&amp;#60;user username=\"${JWS_ADMIN_USERNAME}\" password=\"${JWS_ADMIN_PASSWORD}\" roles=\"manager-gui\"/&amp;#62;\n&amp;#60;/tomcat-users&amp;#62;|" $JWS_HOME/conf/tomcat-users.xml --- &amp;#62; sed -i -e"s|&amp;#60;/tomcat-users&amp;#62;|\n&amp;#60;user username=\"${JWS_ADMIN_USERNAME}\" password=\"${JWS_ADMIN_PASSWORD}\" roles=\"manager-jmx,manager-script\"/&amp;#62;\n&amp;#60;/tomcat-users&amp;#62;|" $JWS_HOME/conf/tomcat-users.xml &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Now, back up the main &lt;code&gt;context.xml&lt;/code&gt; file: &lt;pre&gt;sh-4.2# cp -pr context.xml context.xml_ORIG sh-4.2# diff context.xml context.xml_ORIG 19,20c19,20 &amp;#60; &amp;#60;!-- &amp;#60;Valve className="org.apache.catalina.valves.RemoteAddrValve" &amp;#60; allow="127\.\d+\.\d+\.\d+|::1|0:0:0:0:0:0:0:1" /&amp;#62; --&amp;#62; --- &amp;#62; &amp;#60;Valve className="org.apache.catalina.valves.RemoteAddrValve" &amp;#62; allow="127\.\d+\.\d+\.\d+|::1|0:0:0:0:0:0:0:1" /&amp;#62; 23c23 &amp;#60; &amp;#60;!-- &amp;#60;Valve className="org.apache.catalina.valves.RemoteAddrValve" allow="127\.\d+\.\d+\.\d+|::1|0:0:0:0:0:0:0:1"/&amp;#62; --&amp;#62; &lt;/pre&gt; &lt;pre&gt;&amp;#62; &amp;#60;Valve className="org.apache.catalina.valves.RemoteAddrValve" allow="127\.\d+\.\d+\.\d+|::1|0:0:0:0:0:0:0:1"/&amp;#62; &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Create config maps for &lt;code&gt;secure-mgmt-console.sh&lt;/code&gt; and &lt;code&gt;context.xml&lt;/code&gt;, respectively: &lt;pre&gt;sh-4.2# oc create configmap mgmtsecure --from-file=secure-mgmt-console.sh configmap/mgmtsecure created sh-4.2# oc create configmap mgmtcontext --from-file=context.xml configmap/mgmtcontext created &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Set the &lt;code&gt;volume&lt;/code&gt; for the &lt;code&gt;mgmtsecure&lt;/code&gt; and &lt;code&gt;mgmtcontext&lt;/code&gt; config maps: &lt;pre&gt;sh-4.2# oc set volume dc/os-sample-java-web --add --name=mgmtsecure --configmap-name=mgmtsecure --default-mode=0777 --mount-path=/opt/jws-5.3/tomcat/bin/launch/secure-mgmt-console.sh --sub-path=secure-mgmt-console.sh deploymentconfig.apps.openshift.io/os-sample-java-web volume updated sh-4.2# oc set volume dc/os-sample-java-web --add --name=mgmtcontext --configmap-name=mgmtcontext --default-mode=0777 --mount-path=/opt/jws-5.3/tomcat/webapps/manager/META-INF/context.xml --sub-path=context.xml deploymentconfig.apps.openshift.io/os-sample-java-web volume updated &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Overwrite &lt;code&gt;JWS_ADMIN_USERNAME&lt;/code&gt; and &lt;code&gt;JWS_ADMIN_PASSWORD&lt;/code&gt; as shown: &lt;pre&gt;sh-4.2# oc set env dc/os-sample-java-web --overwrite JWS_ADMIN_USERNAME=jwsadmin deploymentconfig.apps.openshift.io/os-sample-java-web updated sh-4.2# oc set env dc/os-sample-java-web --overwrite JWS_ADMIN_PASSWORD=jwsadmin deploymentconfig.apps.openshift.io/os-sample-java-web update sh-4.2# oc set env dc/os-sample-java-web --overwrite SCRIPT_DEBUG=true deploymentconfig.apps.openshift.io/os-sample-java-web updated &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Verify that the application was deployed and the pod was created with your changes: &lt;pre&gt;os-sample-java-web-2-build 0/1 Completed 0 27m os-sample-java-web-7-rghgk 1/1 Running 0 26m &lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;Open the Tomcat Manager&lt;/h2&gt; &lt;p&gt;The last step is to open the &lt;code&gt;&lt;strong&gt;/&lt;/strong&gt;manager&lt;/code&gt; page. It will pop up a login console. Enter your user ID (&lt;code&gt;jwsadmin&lt;/code&gt;) and password (&lt;code&gt;jwsadmin&lt;/code&gt;) to access the Tomcat Manager in the OpenShift console.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/managerpage.png"&gt;&lt;img class=" aligncenter wp-image-740667 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/06/managerpage-1024x473.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/managerpage-300x139.png" alt="" width="640" height="296" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/managerpage-300x139.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/managerpage-768x355.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/managerpage-1024x473.png 1024w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;You now know how to install Tomcat on OpenShift, use Tomcat to deploy a web application to OpenShift, and access the Tomcat &lt;code&gt;/manager&lt;/code&gt; page. I hope this tutorial helps you get started with your OpenShift explorations.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F01%2Finstall-apache-tomcat-and-deploy-a-java-web-application-on-red-hat-openshift%2F&amp;#38;linkname=Install%20Apache%20Tomcat%20and%20deploy%20a%20Java%20web%20application%20on%20Red%20Hat%20OpenShift" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F01%2Finstall-apache-tomcat-and-deploy-a-java-web-application-on-red-hat-openshift%2F&amp;#38;linkname=Install%20Apache%20Tomcat%20and%20deploy%20a%20Java%20web%20application%20on%20Red%20Hat%20OpenShift" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F01%2Finstall-apache-tomcat-and-deploy-a-java-web-application-on-red-hat-openshift%2F&amp;#38;linkname=Install%20Apache%20Tomcat%20and%20deploy%20a%20Java%20web%20application%20on%20Red%20Hat%20OpenShift" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F01%2Finstall-apache-tomcat-and-deploy-a-java-web-application-on-red-hat-openshift%2F&amp;#38;linkname=Install%20Apache%20Tomcat%20and%20deploy%20a%20Java%20web%20application%20on%20Red%20Hat%20OpenShift" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F01%2Finstall-apache-tomcat-and-deploy-a-java-web-application-on-red-hat-openshift%2F&amp;#38;linkname=Install%20Apache%20Tomcat%20and%20deploy%20a%20Java%20web%20application%20on%20Red%20Hat%20OpenShift" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F01%2Finstall-apache-tomcat-and-deploy-a-java-web-application-on-red-hat-openshift%2F&amp;#38;linkname=Install%20Apache%20Tomcat%20and%20deploy%20a%20Java%20web%20application%20on%20Red%20Hat%20OpenShift" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F01%2Finstall-apache-tomcat-and-deploy-a-java-web-application-on-red-hat-openshift%2F&amp;#38;linkname=Install%20Apache%20Tomcat%20and%20deploy%20a%20Java%20web%20application%20on%20Red%20Hat%20OpenShift" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F01%2Finstall-apache-tomcat-and-deploy-a-java-web-application-on-red-hat-openshift%2F&amp;#038;title=Install%20Apache%20Tomcat%20and%20deploy%20a%20Java%20web%20application%20on%20Red%20Hat%20OpenShift" data-a2a-url="https://developers.redhat.com/blog/2020/07/01/install-apache-tomcat-and-deploy-a-java-web-application-on-red-hat-openshift/" data-a2a-title="Install Apache Tomcat and deploy a Java web application on Red Hat OpenShift"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/07/01/install-apache-tomcat-and-deploy-a-java-web-application-on-red-hat-openshift/"&gt;Install Apache Tomcat and deploy a Java web application on Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/FOdIrHGuIrY" height="1" width="1" alt=""/&gt;</content><summary>If you are new to OpenShift, then you might want to install Apache Tomcat on top of it for simpler experimentation. This article guides you through installing Apache Tomcat from a Docker image and then using it to deploy a Java web app on Red Hat OpenShift. I also show you how to access the Tomcat management console on OpenShift. To follow the examples, you must have an OpenShift account. We will ...</summary><dc:creator>Pandurang Memane</dc:creator><dc:date>2020-07-01T07:00:58Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/07/01/install-apache-tomcat-and-deploy-a-java-web-application-on-red-hat-openshift/</feedburner:origLink></entry><entry><title>Develop Eclipse MicroProfile applications on Red Hat JBoss Enterprise Application Platform Expansion Pack 1.0 with Red Hat CodeReady Workspaces</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/VD77mZB2sPY/" /><category term="codeready" scheme="searchisko:content:tags" /><category term="Developer Tools" scheme="searchisko:content:tags" /><category term="devops" scheme="searchisko:content:tags" /><category term="Eclipse Che" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Java" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="microprofile" scheme="searchisko:content:tags" /><category term="microservices" scheme="searchisko:content:tags" /><author><name>Emmanuel Hugonnet</name></author><id>searchisko:content:id:jbossorg_blog-develop_eclipse_microprofile_applications_on_red_hat_jboss_enterprise_application_platform_expansion_pack_1_0_with_red_hat_codeready_workspaces</id><updated>2020-07-01T07:00:29Z</updated><published>2020-07-01T07:00:29Z</published><content type="html">&lt;p&gt;This article builds on my previous tutorial, &lt;a href="https://developers.redhat.com/blog/2020/06/16/enable-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-7-3/"&gt;&lt;em&gt;Enable Eclipse MicroProfile applications on Red Hat JBoss Enterprise Application Platform 7.3&lt;/em&gt;&lt;/a&gt;. To follow the examples, you must have &lt;a target="_blank" rel="nofollow" href="https://projects.eclipse.org/projects/technology.microprofile"&gt;Eclipse MicroProfile&lt;/a&gt; enabled in your &lt;a href="https://developers.redhat.com/products/eap/download"&gt;Red Hat JBoss Enterprise Application Platform Expansion Pack (JBoss EAP XP) 1.0.0.GA&lt;/a&gt; installation, via &lt;a href="https://developers.redhat.com/products/codeready-studio/overview"&gt;Red Hat CodeReady Studio&lt;/a&gt;. See the previous article for installation instructions.&lt;/p&gt; &lt;p&gt;In this article, we will use the installed MicroProfile-enabled image to set up a JBoss EAP XP quickstart project in &lt;a href="https://developers.redhat.com/products/codeready-workspaces/overview"&gt;Red Hat CodeReady Workspaces&lt;/a&gt; (CRW). You can also apply what you learn from this article to develop your own applications using CodeReady Workspaces.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; For more examples, be sure to see the video demonstration at the end of the article.&lt;/p&gt; &lt;p&gt;&lt;span id="more-734667"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Step 1: Create a new devfile&lt;/h2&gt; &lt;p&gt;To start, open CodeReady WorkSpaces and create a new &lt;a target="_blank" rel="nofollow" href="https://redhat-developer.github.io/devfile/"&gt;devfile&lt;/a&gt;. In the next sections, I&amp;#8217;ll describe the steps to configure and build this devfile so that you can build and run the quickstarts in CodeReady Workspaces. You can download the sample devfile here.&lt;/p&gt; &lt;h2&gt;Step 2: Define the editor plugins&lt;/h2&gt; &lt;p&gt;Because this is a Java project, we&amp;#8217;re using the &lt;a target="_blank" rel="nofollow" href="https://github.com/eclipse/che-theia-java-plugin"&gt;Java Che plugin:&lt;/a&gt;&lt;/p&gt; &lt;pre&gt;components:  -   type: chePlugin   id: redhat/java11/latest - &lt;/pre&gt; &lt;h2&gt;Step 3: Define the Jaeger Docker image&lt;/h2&gt; &lt;p&gt;This example uses Jaeger for &lt;a target="_blank" rel="nofollow" href="https://github.com/eclipse/microprofile-opentracing"&gt;MicroProfile OpenTracing&lt;/a&gt;, so we include a Docker image to start a Jaeger server instance and expose its UI endpoint on port 16686:&lt;/p&gt; &lt;pre&gt;components:  -    alias: jaeger   type: dockerimage   image: jaegertracing/all-in-one   memoryLimit: 128Mi   endpoints:       - name: 'tracing-ui'         port: 16686 - &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; You can &lt;a target="_blank" rel="nofollow" href="https://github.com/redhat-developer/rhd-article-extras"&gt;find the full eapxp-quickstarts.yaml file here&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Step 4: Define the JBoss EAP XP component&lt;/h2&gt; &lt;p&gt;The last component is the source-to-image (S2I) Docker image for JBoss EAP XP. This image provides instances of both Apache Maven to build the applications and the JBoss EAP XP runtime to run them.&lt;/p&gt; &lt;p&gt;We need to expose the HTTP endpoint to be able to access the running application on port 8080. Later, we&amp;#8217;ll also need to be able to expose the management endpoint on port 9990, because JBoss EAP XP exposes the &lt;a target="_blank" rel="nofollow" href="https://github.com/eclipse/microprofile-health"&gt;MicroProfile Health&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://github.com/eclipse/microprofile-metrics"&gt;MicroProfile Metrics&lt;/a&gt; APIs on this endpoint.&lt;/p&gt; &lt;p&gt;We also define the environment variables for this container. These will configure its various elements, as shown:&lt;/p&gt; &lt;pre&gt;-   type: dockerimage   alias: maven   image: 'registry.redhat.io/jboss-eap-7/eap-xp1-openjdk11-openshift-rhel8@sha256:bebc469f8b21d8132f7b0df62b90107e68e7a77c36d39270f349216557102787'   env: # Enabling Jaeger tracing    - name: WILDFLY_TRACING_ENABLED      value: 'true' # Define the Jaeger service name     - name: JAEGER_SERVICE_NAME      value: 'microprofile-opentracing' # Configure Jaeger traces    - name: JAEGER_REPORTER_LOG_SPANS       value: 'true'    - name: JAEGER_SAMPLER_TYPE      value: 'const'    - name: JAEGER_SAMPLER_PARAM      value: '1'    -     name: MAVEN_OPTS     value: &amp;#62;-      -Xmx200m -XX:MaxRAMPercentage=50.0 -XX:+UseParallelGC -XX:MinHeapFreeRatio=10 -XX:MaxHeapFreeRatio=20 -XX:GCTimeRatio=4      -XX:AdaptiveSizePolicyWeight=90 -Dsun.zip.disableMemoryMapping=true -Xms20m -Djava.security.egd=file:/dev/./urandom -Duser.home=/home/jboss   memoryLimit: 1024Mi   endpoints:    -     name: eap-http     port: 8080    -     name: eap-management     port: 9990   mountSources: true   volumes:    -     name: m2     containerPath: /home/jboss/.m2 &lt;/pre&gt; &lt;p&gt;First, we set the environment variable &lt;code&gt;WILDFLY_TRACING_ENABLED&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt; to enable MicroProfile OpenTracing in JBoss EAP XP.&lt;/p&gt; &lt;p&gt;Second, we configure how Microprofile OpenTracing traces are collected and sent to the Jaeger instance using &lt;code&gt;JAEGER_SERVICE_NAME&lt;/code&gt;, &lt;code&gt;JAEGER_REPORTER_LOG_SPANS&lt;/code&gt;, &lt;code&gt;JAEGER_SAMPLER_TYPE&lt;/code&gt;, and &lt;code&gt;JAEGER_SAMPLER_PARAM&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Last, we need to configure Apache Maven using &lt;code&gt;MAVEN_OPTS&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;As shown in Figure 1, we provide several commands. The most notable is a &lt;code&gt;build&lt;/code&gt; command to build from the Apache Maven &lt;code&gt;pom.xml&lt;/code&gt;. (We&amp;#8217;ll use the &lt;code&gt;copy war&lt;/code&gt; command to deploy the application after it&amp;#8217;s been built.)&lt;/p&gt; &lt;div id="attachment_735557" style="width: 379px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/user_tasks.png"&gt;&lt;img aria-describedby="caption-attachment-735557" class="wp-image-735557 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/user_tasks.png" alt="A screenshot of the build commands available in the quickstart project workspace." width="369" height="375" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/user_tasks.png 369w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/user_tasks-295x300.png 295w" sizes="(max-width: 369px) 100vw, 369px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-735557" class="wp-caption-text"&gt;Figure 1: Build commands for the MicroProfile OpenTracing quickstart project.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Step 5: Build the project&lt;/h2&gt; &lt;p&gt;Finally, we select the &lt;code&gt;pom.xml&lt;/code&gt; for the &lt;code&gt;microprofile-opentracing&lt;/code&gt; quickstart and build the file. Once it is built, you can copy the resulting WAR file. Use the &lt;code&gt;eap-http endpoint&lt;/code&gt; command to produce endpoint traces, then use the &lt;code&gt;tracing-ui&lt;/code&gt; command to see them in the Jaeger instance, as shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_735567" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/building_opentracing_example.png"&gt;&lt;img aria-describedby="caption-attachment-735567" class="wp-image-735567 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/building_opentracing_example-1024x466.png" alt="A screenshot of the build file for the MicroProfile OpenTracing quickstart project." width="640" height="291" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/building_opentracing_example-1024x466.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/building_opentracing_example-300x136.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/building_opentracing_example-768x349.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-735567" class="wp-caption-text"&gt;Figure 2: Build the MicroProfile OpenTracing quickstart project.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Next steps&lt;/h2&gt; &lt;p&gt;You can follow these instructions and the video demonstration at the end of the article to build and install the &lt;code&gt;microprofile-health&lt;/code&gt; and &lt;code&gt;microprofile-metrics&lt;/code&gt; quickstart projects in your workspace. You would use the &lt;code&gt;eap-management endpoint&lt;/code&gt; to access MicroProfile Health content, as shown in Figure 3.&lt;/p&gt; &lt;div id="attachment_735577" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/mp_health_endpoint.png"&gt;&lt;img aria-describedby="caption-attachment-735577" class="wp-image-735577" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/mp_health_endpoint.png" alt="A screenshot of the CRW workspace with the MicroProfile Health endpoint configured." width="640" height="475" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/mp_health_endpoint.png 606w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/mp_health_endpoint-300x223.png 300w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-735577" class="wp-caption-text"&gt;Figure 3: Database connection for a MicroProfile application health check.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Video demo: See more MicroProfile quickstarts in action&lt;/h3&gt; &lt;p&gt;This video demonstrates how to set up CodeReady Workspaces to build and run MicroProfile quickstarts on JBoss EAP XP 1.0. Start the video now to see Eclipse MicroProfile OpenTracing, Eclipse MicroProfile Health, and Eclipse MicroProfile Metrics in action.&lt;/p&gt; &lt;p&gt;&lt;iframe class='youtube-player' type='text/html' width='640' height='360' src='https://www.youtube.com/embed/mG7SY05hvIk?version=3&amp;#038;rel=1&amp;#038;fs=1&amp;#038;autohide=2&amp;#038;showsearch=0&amp;#038;showinfo=1&amp;#038;iv_load_policy=1&amp;#038;wmode=transparent' allowfullscreen='true' style='border:0;'&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In &lt;a href="https://developers.redhat.com/blog/2020/06/16/enable-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-7-3/"&gt;my previous article&lt;/a&gt;, I showed you how to install JBoss EAP XP 1.0 and enable Eclipse MicroProfile support on that platform. In this article, I showed you how to configure and run a MicroProfile quickstart project using CodeReady Workspaces. For more details, be sure to check out the video demonstration that is included in both articles.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F01%2Fdevelop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-expansion-pack-1-0-with-red-hat-codeready-workspaces%2F&amp;#38;linkname=Develop%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%20Expansion%20Pack%201.0%20with%20Red%20Hat%20CodeReady%20Workspaces" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F01%2Fdevelop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-expansion-pack-1-0-with-red-hat-codeready-workspaces%2F&amp;#38;linkname=Develop%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%20Expansion%20Pack%201.0%20with%20Red%20Hat%20CodeReady%20Workspaces" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F01%2Fdevelop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-expansion-pack-1-0-with-red-hat-codeready-workspaces%2F&amp;#38;linkname=Develop%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%20Expansion%20Pack%201.0%20with%20Red%20Hat%20CodeReady%20Workspaces" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F01%2Fdevelop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-expansion-pack-1-0-with-red-hat-codeready-workspaces%2F&amp;#38;linkname=Develop%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%20Expansion%20Pack%201.0%20with%20Red%20Hat%20CodeReady%20Workspaces" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F01%2Fdevelop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-expansion-pack-1-0-with-red-hat-codeready-workspaces%2F&amp;#38;linkname=Develop%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%20Expansion%20Pack%201.0%20with%20Red%20Hat%20CodeReady%20Workspaces" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F01%2Fdevelop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-expansion-pack-1-0-with-red-hat-codeready-workspaces%2F&amp;#38;linkname=Develop%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%20Expansion%20Pack%201.0%20with%20Red%20Hat%20CodeReady%20Workspaces" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F01%2Fdevelop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-expansion-pack-1-0-with-red-hat-codeready-workspaces%2F&amp;#38;linkname=Develop%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%20Expansion%20Pack%201.0%20with%20Red%20Hat%20CodeReady%20Workspaces" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F07%2F01%2Fdevelop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-expansion-pack-1-0-with-red-hat-codeready-workspaces%2F&amp;#038;title=Develop%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%20Expansion%20Pack%201.0%20with%20Red%20Hat%20CodeReady%20Workspaces" data-a2a-url="https://developers.redhat.com/blog/2020/07/01/develop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-expansion-pack-1-0-with-red-hat-codeready-workspaces/" data-a2a-title="Develop Eclipse MicroProfile applications on Red Hat JBoss Enterprise Application Platform Expansion Pack 1.0 with Red Hat CodeReady Workspaces"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/07/01/develop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-expansion-pack-1-0-with-red-hat-codeready-workspaces/"&gt;Develop Eclipse MicroProfile applications on Red Hat JBoss Enterprise Application Platform Expansion Pack 1.0 with Red Hat CodeReady Workspaces&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/VD77mZB2sPY" height="1" width="1" alt=""/&gt;</content><summary>This article builds on my previous tutorial, Enable Eclipse MicroProfile applications on Red Hat JBoss Enterprise Application Platform 7.3. To follow the examples, you must have Eclipse MicroProfile enabled in your Red Hat JBoss Enterprise Application Platform Expansion Pack (JBoss EAP XP) 1.0.0.GA installation, via Red Hat CodeReady Studio. See the previous article for installation instructions. ...</summary><dc:creator>Emmanuel Hugonnet</dc:creator><dc:date>2020-07-01T07:00:29Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/07/01/develop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-expansion-pack-1-0-with-red-hat-codeready-workspaces/</feedburner:origLink></entry><entry><title>New Netty transport</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/KCqMQmtBDfA/new-netty-transport.html" /><category term="feed_group_name_jgroups" scheme="searchisko:content:tags" /><category term="feed_name_belasblog" scheme="searchisko:content:tags" /><author><name>Bela Ban</name></author><id>searchisko:content:id:jbossorg_blog-new_netty_transport</id><updated>2020-06-30T13:50:55Z</updated><published>2020-06-30T13:50:00Z</published><content type="html">I'm happy to announce that Baizel Mathew and Steven Wong have written a new transport protocol using Netty!&lt;br /&gt;&lt;br /&gt;Read Baizel's announcement here: [1]; for the code look here: [2].&lt;br /&gt;&lt;br /&gt;I anticipate that the Netty transport will replace TCP_NIO2 over time.&lt;br /&gt;&lt;br /&gt;The maven coordinates are:&lt;br /&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;Courier New&amp;quot;, Courier, monospace;"&gt;&amp;lt;dependency&amp;gt;&lt;br /&gt;&amp;nbsp; &amp;lt;groupId&amp;gt;org.jgroups&amp;lt;/groupId&amp;gt;&lt;br /&gt;&amp;nbsp; &amp;lt;artifactId&amp;gt;jgroups-netty&amp;lt;/artifactId&amp;gt;&lt;br /&gt;&amp;nbsp; &amp;lt;version&amp;gt;1.0.0.Alpha2&amp;lt;/version&amp;gt;&lt;br /&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt; &lt;br /&gt;&lt;br /&gt;Thanks, Baizel and Steven, for your contribution!&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;[1] &lt;a href="https://groups.google.com/forum/?utm_medium=email&amp;amp;utm_source=footer#!msg/jgroups-dev/R3yxmfhcqMk/ugked7zaAgAJ"&gt;https://groups.google.com/forum/?utm_medium=email&amp;amp;utm_source=footer#!msg/jgroups-dev/R3yxmfhcqMk/ugked7zaAgAJ&lt;/a&gt;&lt;br /&gt;[2] &lt;a href="https://github.com/jgroups-extras/jgroups-netty"&gt;https://github.com/jgroups-extras/jgroups-netty&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/KCqMQmtBDfA" height="1" width="1" alt=""/&gt;</content><summary>I'm happy to announce that Baizel Mathew and Steven Wong have written a new transport protocol using Netty! Read Baizel's announcement here: [1]; for the code look here: [2]. I anticipate that the Netty transport will replace TCP_NIO2 over time. The maven coordinates are:   org.jgroups   jgroups-netty   1.0.0.Alpha2 Thanks, Baizel and Steven, for your contribution! [1] https://groups.google.com/fo...</summary><dc:creator>Bela Ban</dc:creator><dc:date>2020-06-30T13:50:00Z</dc:date><feedburner:origLink>http://belaban.blogspot.com/2020/06/new-netty-transport.html</feedburner:origLink></entry><entry><title>Kourier: A lightweight Knative Serving ingress</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/A_cn54uCWdY/" /><category term="control plane" scheme="searchisko:content:tags" /><category term="Envoy gateway" scheme="searchisko:content:tags" /><category term="event-driven" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="istio" scheme="searchisko:content:tags" /><category term="Knative" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="operator" scheme="searchisko:content:tags" /><category term="serverless" scheme="searchisko:content:tags" /><author><name>Joaquim Prusi</name></author><id>searchisko:content:id:jbossorg_blog-kourier_a_lightweight_knative_serving_ingress</id><updated>2020-06-30T07:00:19Z</updated><published>2020-06-30T07:00:19Z</published><content type="html">&lt;p&gt;Until recently, &lt;a target="_blank" rel="nofollow" href="https://knative.dev/docs/serving/"&gt;Knative Serving&lt;/a&gt; used &lt;a href="https://developers.redhat.com/topics/service-mesh/"&gt;Istio&lt;/a&gt; as its default networking component for handling external cluster traffic and service-to-service communication. Istio is a &lt;a target="_blank" rel="nofollow" href="https://redhat-developer-demos.github.io/istio-tutorial/istio-tutorial/1.4.x/index.html"&gt;great service mesh solution&lt;/a&gt;, but it can add unwanted complexity and resource use to your cluster if you don&amp;#8217;t need it.&lt;/p&gt; &lt;p&gt;That&amp;#8217;s why we created &lt;a target="_blank" rel="nofollow" href="https://github.com/knative/net-kourier"&gt;Kourier&lt;/a&gt;: To simplify the ingress side of Knative Serving. Knative recently adopted Kourier, so it is now a part of the Knative family! This article introduces Kourier and gets you started with using it as a simpler, more lightweight way to expose Knative applications to an external network.&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s begin with a brief overview of Knative and Knative Serving.&lt;/p&gt; &lt;p&gt;&lt;span id="more-732567"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;What is Knative?&lt;/h2&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/topics/serverless-architecture/"&gt;Knative&lt;/a&gt; is a &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt;-based platform for deploying and managing serverless workloads. It is split into two projects:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://knative.dev/docs/serving/"&gt;Knative Serving&lt;/a&gt; focuses on triggering containers using HTTP traffic.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://knative.dev/docs/eventing/"&gt;Knative Eventing&lt;/a&gt; focuses on triggering containers using events.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;This article addresses how Kourier works with Knative Serving.&lt;/p&gt; &lt;h3&gt;Knative Serving&lt;/h3&gt; &lt;p&gt;Knative Serving provides the following features: deployment, autoscaling, and resource conservation. When it comes to deployment, Knative Serving simplifies how we deploy applications to Kubernetes and adds the concept of &lt;em&gt;revisions&lt;/em&gt;. Revisions are &lt;span style="font-weight: 400;"&gt;an immutable service configuration taken when a service is created or modified. This feature lets you quickly roll back changes and gives Knative advanced traffic management, like blue-green deployments and mirror traffic.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;For &lt;em&gt;autoscaling&lt;/em&gt;, &lt;span data-preserver-spaces="true"&gt;Knative Serving automatically scales your containers based on the defined max concurrent requests for that service. For example, if the desired max concurrency is set to one, a Kubernetes pod is spun for each new request.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;When it comes to &lt;em&gt;resource conservation&lt;/em&gt;, Knative Serving ensures that dormant applications are scaled to zero and ready for the next request.&lt;/p&gt; &lt;p&gt;Here is an example of a simple application deployment using Knative Serving:&lt;/p&gt; &lt;pre&gt;apiVersion: serving.knative.dev/v1 kind: Service metadata: name: helloworld-go namespace: default spec: template: spec: containers: - image: docker.io/jmprusi/helloworld-go env: - name: TARGET value: "Go Sample v1" &lt;/pre&gt; &lt;p&gt;As you can see, this is a &amp;#8220;Hello, world&amp;#8221; application. We only need to define the container image and the required environment variables. We do not need to define the service, deployment, or selectors. See the &lt;a target="_blank" rel="nofollow" href="https://github.com/knative/docs/blob/master/docs/serving/spec/knative-api-specification-1.0.md"&gt;Knative API specification&lt;/a&gt; for more details.&lt;/p&gt; &lt;h2&gt;What is Kourier?&lt;/h2&gt; &lt;p&gt;Like Istio, &lt;a target="_blank" rel="nofollow" href="https://knative.dev/v0.12-docs/install/knative-with-kourier/"&gt;Kourier&lt;/a&gt; is a lightweight ingress based on the Envoy gateway with no additional custom resource definitions (CRDs). It is composed of two parts:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;b&gt;The Kourier gateway&lt;/b&gt; is Envoy running with a base bootstrap configuration that connects back to the Kourier control plane.&lt;/li&gt; &lt;li&gt;&lt;b&gt;The Kourier control plane&lt;/b&gt; handles Knative ingress objects and keeps the Envoy configuration up to date.&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;How Kourier works&lt;/h3&gt; &lt;p&gt;Kourier does the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Reads the ingress objects created by Knative Serving.&lt;/li&gt; &lt;li&gt;Transforms these objects into an Envoy configuration.&lt;/li&gt; &lt;li&gt;Exposes the configuration to the Envoys that it manages.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Figure 1 shows in more detail how Kourier works with Knative Serving to expose Knative applications to the network.&lt;/p&gt; &lt;div id="attachment_732577" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Kourier_diagram.png"&gt;&lt;img aria-describedby="caption-attachment-732577" class="wp-image-732577" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Kourier_diagram-300x182.png" alt="A flow diagram of Kourier in the Knative Serving workflow." width="640" height="388" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Kourier_diagram-300x182.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Kourier_diagram-768x466.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Kourier_diagram.png 958w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-732577" class="wp-caption-text"&gt;Figure 1. Kourier in the Knative Serving workflow.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;When a new service is deployed in Knative Serving, it creates an &lt;code&gt;Ingress&lt;/code&gt; object that contains information about how the service should be exposed. An ingress object includes the following elements:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;b&gt;Hosts, paths, and headers&lt;/b&gt;: These elements are matched against the same elements included in incoming requests. When there&amp;#8217;s a match, we know that the request should be proxied to the Knative service associated with the ingress object.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Splits&lt;/b&gt;: We use &lt;em&gt;splits&lt;/em&gt; to divide incoming traffic between different revisions of a deployed service.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Visibility&lt;/b&gt;: Defines whether the service should be accessible from within the cluster or from outside.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Transport Layer Security (TLS)&lt;/b&gt;: Specifies the &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt; secret that contains the certificate and the key needed to expose the service with HTTPS.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Kourier subscribes to changes in ingresses that are managed by Knative Serving. Kourier is notified every time an ingress is created, deleted, or modified. When that happens, Kourier analyzes the information in the ingress and transforms the information into objects in an Envoy configuration. Envoy configurations can be complicated, but clusters and routes are two of the objects that they include. A &lt;i&gt;cluster&lt;/i&gt; is a collection of Internet Protocol addresses (IPs) that belong to the same service. &lt;i&gt;Routes&lt;/i&gt; contain all of the information used to match a given request: the host, path, headers, and so on. A route can also specify which cluster proxy the request should go to when there is a match.&lt;/p&gt; &lt;p&gt;After an ingress has been transformed into objects in an Envoy configuration, we can use the &lt;a target="_blank" rel="nofollow" href="https://www.envoyproxy.io/docs/envoy/v1.14.1/api-docs/xds_protocol#"&gt;Envoy xDS APIs&lt;/a&gt; to expose that configuration to the Envoys in the cluster. Kourier manages the cluster.&lt;/p&gt; &lt;p&gt;When Knative scales up the number of pods in a service, Kourier automatically selects the IP of the newest pod and starts proxying traffic to it. Similarly, when the number of pods is reduced, Kourier is notified and stops sending requests to pods that are scheduled to be deleted.&lt;/p&gt; &lt;p&gt;It is important to note that in all of this process, Kourier does not create any custom resources that only it can understand. Instead, Kourier only works with objects managed by Knative Serving (the ingresses), and objects managed by Kubernetes—like endpoints, secrets (the ones that include the TLS configuration), and so on. This is why we say that Knative is a &amp;#8220;Knative-native&amp;#8221; ingress.&lt;/p&gt; &lt;h2&gt;Kourier&amp;#8217;s integration with Knative&lt;/h2&gt; &lt;p&gt;As well as being Knative-native, Kourier is a &lt;i&gt;Knative-conformant &lt;/i&gt;ingress. By that, we mean that all of the features of Knative Serving work well when using Kourier. These include traffic splitting between different revisions of a service, TLS, timeouts, retries, automatic endpoint discovery when a service is scaled, and more.&lt;/p&gt; &lt;p&gt;To ensure that Kourier is conformant and that it supports every new feature added to Knative Serving, we have configured a &lt;a href="https://developers.redhat.com/topics/ci-cd/"&gt;continuous integration (CI)&lt;/a&gt; system that runs the &lt;a target="_blank" rel="nofollow" href="https://testgrid.knative.dev/net-kourier"&gt;Knative Serving conformance test suite&lt;/a&gt;. As you can see from the &lt;a target="_blank" rel="nofollow" href="https://testgrid.knative.dev/net-kourier#continuous"&gt;test grid&lt;/a&gt;, Kourier is one of the few Knative ingress implementations that consistently passes all of the tests in the suite.&lt;/p&gt; &lt;h3&gt;Using the Envoy external authorization filter with Kourier&lt;/h3&gt; &lt;p&gt;It is possible to configure Kourier to use the &lt;a target="_blank" rel="nofollow" href="https://www.envoyproxy.io/docs/envoy/v1.14.1/intro/arch_overview/security/ext_authz_filter.html"&gt;Envoy external authorization filter&lt;/a&gt; for traffic authorization. For every incoming request, Kourier will contact an external service to check whether the request should be authorized. If it is authorized, Kourier will proxy the request to the appropriate service. If it is not, it will return an error to the caller. One way to use this feature would be to build a service based on the &lt;a target="_blank" rel="nofollow" href="https://www.openpolicyagent.org/"&gt;Open Policy Agent (OPA) framework&lt;/a&gt;. OPA supports Envoy&amp;#8217;s external authorization protocol and allows us to define authorization rules using a high-level language designed specifically for writing authorization policies.&lt;/p&gt; &lt;h2&gt;Get started with Kourier&lt;/h2&gt; &lt;p&gt;If you are using OpenShift, you can find the Red Hat OpenShift Serverless Operator in your Operator catalog. The Serverless Operator automatically installs Kourier. (For installation details, see &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.4/serverless/installing_serverless/installing-openshift-serverless.html"&gt;Installing the OpenShift Serverless Operator&lt;/a&gt;.)&lt;/p&gt; &lt;p&gt;Alternatively, you can install Kourier in a cluster that is already running Knative Serving. In this case, just enter:&lt;/p&gt; &lt;pre&gt;$ kubectl apply --filename https://github.com/knative/net-kourier/releases/download/v0.15.0/kourier.yaml&lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: Replace the version number (in this case, v0.15.0) with the version that you want to install.&lt;/p&gt; &lt;p&gt;Here is the code that configures Knative to use Kourier:&lt;/p&gt; &lt;pre&gt;kubectl patch configmap/config-network \ --namespace knative-serving \ --type merge \ --patch '{"data":{"ingress.class":"kourier.ingress.networking.knative.dev"}}' &lt;/pre&gt; &lt;p&gt;That should be enough to get started. For more complex installations, see the &lt;a target="_blank" rel="nofollow" href="https://knative.dev/docs/install/any-kubernetes-cluster/"&gt;installation instructions&lt;/a&gt; in the Knative documents.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;As we mentioned at the beginning of this article, Knative was recently adopted by Kourier, so it&amp;#8217;s one of the currently supported implementations for Knative Serving. Check out &lt;a target="_blank" rel="nofollow" href="http://github.com/knative/net-kourier/"&gt;Kourier&amp;#8217;s GitHub repository&lt;/a&gt; under the Knative project.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F30%2Fkourier-a-lightweight-knative-serving-ingress%2F&amp;#38;linkname=Kourier%3A%20A%20lightweight%20Knative%20Serving%20ingress" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F30%2Fkourier-a-lightweight-knative-serving-ingress%2F&amp;#38;linkname=Kourier%3A%20A%20lightweight%20Knative%20Serving%20ingress" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F30%2Fkourier-a-lightweight-knative-serving-ingress%2F&amp;#38;linkname=Kourier%3A%20A%20lightweight%20Knative%20Serving%20ingress" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F30%2Fkourier-a-lightweight-knative-serving-ingress%2F&amp;#38;linkname=Kourier%3A%20A%20lightweight%20Knative%20Serving%20ingress" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F30%2Fkourier-a-lightweight-knative-serving-ingress%2F&amp;#38;linkname=Kourier%3A%20A%20lightweight%20Knative%20Serving%20ingress" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F30%2Fkourier-a-lightweight-knative-serving-ingress%2F&amp;#38;linkname=Kourier%3A%20A%20lightweight%20Knative%20Serving%20ingress" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F30%2Fkourier-a-lightweight-knative-serving-ingress%2F&amp;#38;linkname=Kourier%3A%20A%20lightweight%20Knative%20Serving%20ingress" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F06%2F30%2Fkourier-a-lightweight-knative-serving-ingress%2F&amp;#038;title=Kourier%3A%20A%20lightweight%20Knative%20Serving%20ingress" data-a2a-url="https://developers.redhat.com/blog/2020/06/30/kourier-a-lightweight-knative-serving-ingress/" data-a2a-title="Kourier: A lightweight Knative Serving ingress"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/06/30/kourier-a-lightweight-knative-serving-ingress/"&gt;Kourier: A lightweight Knative Serving ingress&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/A_cn54uCWdY" height="1" width="1" alt=""/&gt;</content><summary>Until recently, Knative Serving used Istio as its default networking component for handling external cluster traffic and service-to-service communication. Istio is a great service mesh solution, but it can add unwanted complexity and resource use to your cluster if you don’t need it. That’s why we created Kourier: To simplify the ingress side of Knative Serving. Knative recently adopted Kourier, s...</summary><dc:creator>Joaquim Prusi</dc:creator><dc:date>2020-06-30T07:00:19Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/06/30/kourier-a-lightweight-knative-serving-ingress/</feedburner:origLink></entry></feed>
